[{"title":"MIT-6.S081-Lab0：实验环境配置","url":"/2025/02/27/MIT-6-S081-Lab0%EF%BC%9A%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","content":"想学学操作系统，准备开坑6.s081。\n准备工作换源下载软件有点慢，所以我们换一个源，操作方法如下：1.备份源列表        # 首先备份源列表sudo cp /etc/apt/sources.list /etc/apt/sources.list_backup\n2.打开sources.list文件修改        # 打开sources.list文件sudo gedit /etc/apt/sources.list    然后在文件最前面添加阿里云镜像源：    # 这是阿里源deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse\n3.最后记得刷新列表    sudo apt-get updatesudo apt-get upgradesudo apt-get install build-essential\n配置环境环境这里环境使用wsl2 + ubuntu20.04，据说18.04会比较麻烦。\n安装指令使用官网的指令即可    sudo apt-get install git build-essential gdb-multiarch qemu-system-misc gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu sudo apt-get remove qemu-system-miscsudo apt-get install qemu-system-misc=1:4.2-3ubuntu6\n至此环境配置完毕。\n","categories":["6.s081"],"tags":["操作系统","环境配置","Linux","6.s081"]},{"title":"MIT-6-S081-Lab3: Page tables","url":"/2025/03/07/MIT-6-S081-Lab3%EF%BC%9APage-tables/","content":"知识点到 Lab3 啦，这个 Lab 涉及到对页表的理解分析，我们需要探索页表并对其进行修改。\n分页硬件的结构正如在 Lab2 之中我们提到的，页表负责将虚拟地址映射到真实地址。在我们基于 Sv39 RISC-V 的 XV6 中，我们只使用 64 位地址的低 39 位。\n页表实际上是一个由（$2^{27}$）个页表条目（Page Table Entries/PTE）组成的数组，每个PTE包含一个 44 位的物理页码（Physical Page Number/PPN）和 10 位的标志。分页硬件通过利用虚拟地址的前 39 位中的 27 位来索引页表，从而找到与该虚拟地址对应的 PTE。接着，它生成一个 56 位的物理地址，其中前 44 位取自 PTE 中的 PPN，后 12 位则直接来自原始虚拟地址。页表使操作系统能够以 4096（$2^{12}$）字节的对齐块的粒度控制虚拟地址到物理地址的转换，这样的块称为页（page）。\n在Sv39 RISC-V中，前 25 位不用于转换，纯粹是用于符号扩展，保证地址的正确性，因为 39 位已经足够多（但我们设计操作系统的时候实际只使用 38 位，单纯是为了简单）。如果需要更多，RISC-V 设计人员也定义了具有 48 位虚拟地址的 Sv48。\n实际的页表索引分三个步骤进行。页表以三级的树型结构存储在物理内存中。该树的根是一个 4096 字节的页表页，其中包含 512 个 PTE，每个 PTE 中包含该树下一级页表页的物理地址。每一级页表页都包含 512 个 PTE。分页硬件使用虚拟地址的 27 位进行三级索引：前 9 位选择根页表中的 PTE，中间 9 位选择下一级页表中的 PTE，最后 9 位选择最终的 PTE。如果转换地址所需的三个 PTE 中的任何一个不存在，页式硬件就会引发缺页异常（page-fault exception），并让内核来处理该异常。\n三级结构对储存结构做了优化。当进程被实际访问的虚拟内存比较少时（可能是在虚拟地址空间中分配的地址范围比较小，也可能是分配的多但实际使用的虚拟内存较少），只有一部分虚拟地址会被实际映射到物理内存。事实上，只有实际使用的 PTE 所在的页才会被分配。\n因为 CPU 在执行转换时会在硬件中遍历三级结构，所以 CPU 必须从内存中加载三个 PTE 以将虚拟地址转换为物理地址，这无疑是非常耗时的。为了减少从物理内存加载 PTE 的开销，RISC-V CPU 将页表条目缓存在 Translation Look-aside Buffer (TLB) 中，它是一个专门存储页表项的高速缓存。TLB 被用来缓存最近使用的页表项，使得 CPU 在大多数情况下能够快速完成地址转换。\n每个 PTE 包含若干标志位，这些标志位用于告知分页硬件如何处理与该 PTE 关联的虚拟地址。PTE_V 表示 PTE 是否有效：如果未设置此位，对页面的访问将引发异常（即禁止访问）。PTE_R 控制是否允许读取页面内容。PTE_W 决定是否允许写入页面。PTE_X 指示 CPU 是否可以将页面内容当作指令来执行。PTE_U 决定用户模式下是否允许访问该页面；如果未设置 PTE_U，页面只能在管理模式下访问。标志和所有其他与页面硬件相关的结构在（kernel/riscv.h）中定义。\n我们自然会好奇根页表页如何确定。事实上，内核会将根页表页的物理地址写入到 satp 寄存器中。satp 寄存器用于指示当前进程的页表位置，当 CPU 访问虚拟地址时，硬件自动以 satp 指向的页表为根进行转换。又因为每个 CPU 都有自己的 satp 寄存器，所以不同的 CPU 可以运行不同的进程，且地址空间存在隔离。\n在 XV6 中，每个进程的用户页表仅管理用户地址空间（0x0 到 PLIC），而内核页表（kernel_pagetable）是全局唯一的，独立于所有用户页表。内核页表在系统启动时初始化，并通过恒等映射直接访问物理内存和硬件设备。当进程通过系统调用或中断陷入内核态时，硬件执行位于共享的 trampoline 页中的代码（uservec），该代码会显式修改 satp 寄存器以切换到内核页表，而非继续使用用户页表。内核栈作为进程私有的数据结构，通过内核页表映射到内核地址空间的高端区域，用户页表中不存在内核栈的映射，从而完全隔离用户与内核的地址访问。这一设计通过强制页表切换和地址空间隔离，确保内核代码始终运行在受保护的环境中，即使用户程序存在内存错误或恶意行为，也不会影响内核的稳定性。\n进程陷入内核态后，CPU 通过 satp 寄存器使用内核页表访问物理内存，此时用户页表已被完全替换。内核栈的独立性和内核页表的全局性使得所有进程在内核态共享同一份内核代码和数据结构，但各自维护独立的内核栈以防止数据冲突。用户页表从未包含内核地址空间的映射，所有内核资源的访问均依赖显式的页表切换机制，而非通过用户页表直接访问。这种严格的隔离机制是 XV6 实现特权级保护和系统安全的核心基础。\n内核地址空间内核通过独立的全局页表（kernel_pagetable）管理所有内核资源，该页表在系统启动时初始化，采用恒等映射（虚拟地址 KERNBASE = 0x80000000 起直接对应物理地址，刚好对应顶级页目录的条目2）。当进程通过陷阱（如系统调用或中断）进入内核态时，硬件执行 trampoline 页中的代码（uservec），显式将 satp 寄存器切换到内核页表，使 CPU 能够访问内核代码、设备和进程独立的内核栈。内核通过内核页表直接读写物理内存和硬件寄存器，例如设备接口（UART、磁盘）被映射到固定的内核虚拟地址，而每个进程的内核栈则通过内核页表映射到独立的高端地址，用户页表无法访问这些区域。这种设计通过硬件级页表切换和严格的内核/用户地址空间隔离，确保内核始终在受控环境中执行，用户程序的错误或恶意行为不会影响内核稳定性。\n\n  \n  图一：映射示意图\n\n\n\n在QEMU中，0~0x80000000用于映射设备接口，而0x80000000(KERNBASE) ~ 0x86400000(PHYSTOP)为RAM。对0~0x80000000内的物理地址进行读写可以与设备交互，具体内容将在后面的课程中介绍。\n内核中有很多地址是“直接映射”，比如内核本身在内核虚拟地址空间和物理内存中都位于 KERNBASE=0x80000000，这种设计使得在内核读取或写入物理内存非常方便。\n但要注意，也存在几个内核虚拟地址不是直接映射：\n\n蹦床页面（trampoline page）：它映射在虚拟地址空间的顶部，用户页表也具有相同的映射，用于特权级切换。\n内核栈页面：在 XV6 中，每个进程的内核栈通过内核页表映射到虚拟地址空间的高端区域（如 KSTACK 宏计算的位置），其下方设有未映射的保护页（PTE 不存在）。这种保护页仅占据虚拟地址空间而不消耗物理内存，确保内核栈溢出时触发页错误并引发 panic，避免破坏相邻内核数据。内核栈的物理内存通过kalloc独立分配，并借助内核页表的恒等映射特性实现双重地址访问：既可通过进程专属的高端虚拟地址访问，也可通过物理地址直接操作。这种设计既保证了内核栈的隔离性与安全性，又为内核提供了灵活的内存管理手段，展现了页表机制在地址空间抽象与硬件交互中的巧妙平衡。\n\n内核初始化代码与地址空间和页表有关的 XV6 代码主要在 vm.c (kernel/vm.c) 中，最核心的数据结构是 pagetable_t ，它实际上是指向 RISC-V 根页表页的指针。一个 pagetable_t 可以是内核页表，也可以是进程页表。XV6 页表管理的核心函数是 mappages 和 walk，其中：\n\n     mappages 用于在页表中为新的映射装载 PTE，确保虚拟地址与物理地址之间的映射关系得到正确建立。\n     walk 通过虚拟地址操作内存，配置页表内容。\n\n\n命名上，以 kvm 开头的函数操作内核页表，以 uvm 开头的函数操作用户页表，其他函数则用于操作这两者。例如，copyout 和 copyin 分别用于将数据复制到用户虚拟地址或从用户虚拟地址复制数据，这些虚拟地址通常作为系统调用的参数提供。由于需要显式翻译这些虚拟地址来找到相应的物理内存，因此相关代码也位于 vm.c 中。\n在系统启动时，main 调用 kvminit，其中 kvminit 通过调用 kvmmake 来创建内核页表。kvmmake 首先分配一页物理内存来存放根页表，然后调用 kvmmap 装载内核所需的地址映射，这些映射包括内核指令和数据、物理内存上限（PHYSTOP）以及设备内存。最后，它将 trampoline 映射到内核虚拟地址空间的最顶端。\n下面来看两个核心函数。\nmappages 的输入是一个页表，用于建立虚拟地址 va 和物理地址 pa 之间的映射关系。这个映射包括指定映射的大小 size 以及 PTE 的权限 perm。PGROUNDDOWN 负责将给定的地址向下对齐到页边界，确保地址符合页对齐的要求。\nmappages 函数会调用 walk 为虚拟地址 va 查找最后一级页表的 PTE 的指针，如果该 PTE 有效，意味着该虚拟地址已经被使用，因而需要重新建立映射。映射的过程包括将物理地址 pa、权限 perm 以及 PTE 的有效位写入相应的页表条目。其中 PA2PTE 负责将物理地址转化为页表项格式。这里的 PA2PTE(pa) 是一个宏，用于将物理地址 pa 转换为 pte_t 的格式。\n// Create PTEs for virtual addresses starting at va that refer to// physical addresses starting at pa. va and size might not// be page-aligned. Returns 0 on success, -1 if walk() couldn&#x27;t// allocate a needed page-table page.intmappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)&#123;    uint64 a, last;    pte_t *pte;    a = PGROUNDDOWN(va);    last = PGROUNDDOWN(va + size - 1);    for(;;)&#123;        if((pte = walk(pagetable, a, 1)) == 0)            return -1;        if(*pte &amp; PTE_V)            panic(&quot;remap&quot;);        *pte = PA2PTE(pa) | perm | PTE_V;        if(a == last)            break;        a += PGSIZE;        pa += PGSIZE;    &#125;    return 0;&#125;\nwalk 函数在每一级页表查找时，首先通过当前级别的 9 位索引找到对应的 PTE（页表项）。如果该 PTE 有效，则从 PTE 的高 44 位提取出下一级页表的物理地址，并更新 pagetable 指针指向该地址；如果 PTE 无效且允许分配页表（即 alloc = 1），则调用 kalloc 分配一个新的页表（kalloc 返回一个虚拟地址，但其实跟物理地址是一样的，毕竟这里是直接映射），并将该虚拟地址更新到当前 PTE 中。其中，PTE2PA 是一个宏，用于从页表项 pte_t 中提取存储的物理地址，PX 则是用于从虚拟地址中计算在多级页表中的索引（例如三级页表中的某一级的索引）。\npte_t *walk(pagetable_t pagetable, uint64 va, int alloc)&#123;if(va &gt;= MAXVA)    panic(&quot;walk&quot;);for(int level = 2; level &gt; 0; level--) &#123;    pte_t *pte = &amp;pagetable[PX(level, va)];    if(*pte &amp; PTE_V) &#123;    pagetable = (pagetable_t)PTE2PA(*pte);    &#125; else &#123;    if(!alloc || (pagetable = (pde_t*)kalloc()) == 0)        return 0;    memset(pagetable, 0, PGSIZE);    *pte = PA2PTE(pagetable) | PTE_V;    &#125;&#125;return &amp;pagetable[PX(0, va)];&#125;\nwalk 函数通过虚拟地址操作内存，负责配置页表的内容，它实现了内存管理单元（Memory Management Unit, MMU）相同的功能。当分页未启用时，虚拟地址通常直接映射为物理地址，硬件不进行地址转换。启用分页后，虚拟地址必须通过硬件的 MMU 通过页表转换为物理地址。不过，启用分页后的内核虚拟地址空间中，部分地址（比如内核代码和数据）内核虚拟地址与物理地址是恒等映射，这样内核仍然可以方便地访问物理内存。pagetable[] 是内核为虚拟地址管理而构建的结构，它不仅是内核的数据结构，也在一定程度上充当硬件接口，符合 RISC-V 规范，硬件依赖它来完成地址转换。\n在 kvminit 调用完成后，内核页表初始化完毕。接着，在 main 函数中，会调用 kvminithart 来加载内核页表。该函数通过 w_satp 将内核根页表 pagetable 的物理地址写入 satp 寄存器中并清除所有的 TLB 条目，之后 CPU 将使用该内核页表来完成虚拟地址到物理地址的转换。\n接着，main 函数调用 procinit，为每个用户进程分配一个内核栈。该内核栈被映射到内核虚拟地址空间的高地址部分，位于 trampoline 下方，并被保护页包围。通过调用 KSTACK 宏，可以获得每个进程的内核栈虚拟地址 va。接着，调用 kvmmap 将虚拟地址 va 和 kalloc 返回的物理地址 pa 进行映射，最后通过 kvminithart 更新 satp 寄存器。\n// initialize the proc table at boot time.voidprocinit(void)&#123;struct proc *p;initlock(&amp;pid_lock, &quot;nextpid&quot;);for(p = proc; p &lt; &amp;proc[NPROC]; p++) &#123;    initlock(&amp;p-&gt;lock, &quot;proc&quot;);    // Allocate a page for the process&#x27;s kernel stack.    // Map it high in memory, followed by an invalid    // guard page.    char *pa = kalloc();    if(pa == 0)        panic(&quot;kalloc&quot;);    uint64 va = KSTACK((int) (p - proc));    kvmmap(va, (uint64)pa, PGSIZE, PTE_R | PTE_W);    p-&gt;kstack = va;&#125;kvminithart();&#125;\n每个RISC-V CPU将页表条目缓存在 TLB 中。当 XV6 更改页表时，它必须通知 CPU 使相应的 TLB 条目失效。如果没有及时失效，那么在后续操作中，TLB 可能会使用旧的缓存映射，这些映射可能指向已经被重新分配给其他进程的物理页面。这将导致一个进程能够在另一个进程的内存区域进行非法写操作，从而引发安全问题。\n为了解决这个问题，RISC-V提供了一条指令 sfence.vma，用于刷新当前 CPU 的 TLB 。在 XV6 中，当重新加载 satp 寄存器后，会在 kvminithart 中执行 sfence.vma 。同样，在切换到用户页表并返回用户空间之前，sfence.vma 也会在 trampoline 代码中执行。\n接下来，main 会调用 userinit 函数创建初始进程。initproc 是一个指向初始进程（通常是 init 进程）的指针，用于在内核中追踪这个进程。初始进程负责创建其他用户进程并提供基础系统服务。对于孤立进程（即失去父进程的进程），会重新分配其父进程为 initproc。由于在 procinit 函数中已经为每个进程分配了内核栈，因此只需找到对应的内核栈并建立映射，无需重新分配新的内核栈。代码如下：\n// Set up first user process.voiduserinit(void)&#123;    struct proc *p;    p = allocproc();    initproc = p;        // allocate one user page and copy init&#x27;s instructions    // and data into it.    uvminit(p-&gt;pagetable, initcode, sizeof(initcode));    p-&gt;sz = PGSIZE;    // prepare for the very first &quot;return&quot; from kernel to user.    p-&gt;trapframe-&gt;epc = 0;      // user program counter    p-&gt;trapframe-&gt;sp = PGSIZE;  // user stack pointer    safestrcpy(p-&gt;name, &quot;initcode&quot;, sizeof(p-&gt;name));    p-&gt;cwd = namei(&quot;/&quot;);    p-&gt;state = RUNNABLE;    release(&amp;p-&gt;lock);&#125;\n这里我们调用了 allocproc 函数，首先通过 allocpid 为当前进程分配了一个唯一的 pid，接着调用 proc_pagetable 为该进程创建了一个空的页表。在这个页表中，只有顶部的 trampoline 和 trapframe 区域被映射。proc_pagetable 内部调用了 uvmcreate，而 uvmcreate 则通过 kalloc 分配页表所需的内存。\nstatic struct proc*allocproc(void)&#123;    struct proc *p;    for(p = proc; p &lt; &amp;proc[NPROC]; p++) &#123;        acquire(&amp;p-&gt;lock);        if(p-&gt;state == UNUSED) &#123;        goto found;        &#125; else &#123;        release(&amp;p-&gt;lock);        &#125;    &#125;    return 0;    found:    p-&gt;pid = allocpid();    // Allocate a trapframe page.    if((p-&gt;trapframe = (struct trapframe *)kalloc()) == 0)&#123;        release(&amp;p-&gt;lock);        return 0;    &#125;    // An empty user page table.    p-&gt;pagetable = proc_pagetable(p);    if(p-&gt;pagetable == 0)&#123;        freeproc(p);        release(&amp;p-&gt;lock);        return 0;    &#125;    // Set up new context to start executing at forkret,    // which returns to user space.    memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));    p-&gt;context.ra = (uint64)forkret;    p-&gt;context.sp = p-&gt;kstack + PGSIZE;    return p;&#125;\n物理内存分配内核在运行时需要为页表、用户内存、内核栈和管道缓冲区等分配和释放物理内存。XV6 将内核末尾到 PHYSTOP 之间的物理内存用于这些运行时分配，这一部分称为free memory，每次分配或释放的内存单位是整个 4096 字节的页面。为了管理这些页面，XV6 使用链表数据结构记录空闲页面。当内核分配页面时，会从链表中移除相应的页面；释放页面时，会将释放的页面重新添加到链表中。\n分配器的代码位于 kalloc.c 文件中，其整体结构非常简单，采用单链表将所有内存页块串联起来。在 kinit 函数中，内存分配器完成了初始化，内存范围从内核数据段结束处开始，到 PHYSTOP 为止，并调用 freerange 函数。随后，freerange 函数逐页调用 kfree 来初始化每个内存页。kfree 函数回收物理地址 pa 处的内存页块，首先使用 memset 填入垃圾值，然后采用头插法将该页块挂载到空闲链表（freelist）中。\n当需要分配物理页块时，kalloc 函数会被调用，并返回一个页的物理地址。它的逻辑非常简单：从 freelist 链表的头部取出一页并返回，即通过头部删除法完成分配。因此可以看到，kalloc 在分配物理页时，是从高地址的物理内存开始向低地址逐步分配的。\n进程地址空间每个进程都有一个单独的页表。进程的用户内存从虚拟地址零开始，可以增长到 MAXVA。当进程要求 XV6 提供更多的用户内存时，XV6 首先使用 kalloc 来分配物理页面。然后，它将新的 PTE 添加到指向新物理页面的进程的页面表中，XV6 在这些 PTE 中设置 PTE_W、PTE_X、PTE_R、PTE_U 和 PTE_V 标志。大多数进程不使用整个用户地址空间，XV6 在未使用的 PTE 中清除 PTE_V。\n下图更详细地显示了 XV6 中执行进程的用户内存布局。堆栈是一个单独的页面，显示的是 exec 创建的初始内容，包含命令行参数的字符串以及指向它们的指针数组位于堆栈的最顶端。\n\n  \n  图二：用户地址空间结构图\n\n\n和内核栈一样，XV6 会在堆栈正下方放置一个无效的保护页（guard page）。如果用户堆栈溢出，并且进程试图使用堆栈下方的地址，则硬件将生成页面错误异常，因为映射无效。实际操作系统可能会在用户堆栈溢出时自动为其分配更多内存。\nsbrksbrk 是一个用于扩展或收缩进程内存的系统调用，具体由 kernel/proc.c 文件中的 growproc 函数实现，并返回扩展或收缩之前的堆顶地址。通过 sbrk，用户程序可以调整其堆内存的大小。应用程序启动时，sbrk 指向堆的最底端，这一地址通过 proc 结构体中的 sz 字段表示。growproc 根据参数 n 的正负来决定调用 uvmalloc 或 uvmdealloc。当 n 为正时，uvmalloc 通过 kalloc 分配物理内存，并使用 mappages 将相应的页表项添加到用户页表中；而当 n 为负时，uvmdealloc 会调用 uvmunmap，通过 walk 查找相关的页表项，并使用 kfree 释放对应的物理内存。\n由于 sbrk 采用即时分配策略，用户程序通常会申请比实际需求更多的内存，这可能导致内存浪费。此外，如果进程申请很大的内存空间，耗时也会变得不可忽视。为了解决这些问题，我们可以引入懒惰分配（lazy allocation）策略（Lab5）。\nuint64sys_sbrk(void)&#123;    int addr;    int n;    if(argint(0, &amp;n) &lt; 0)        return -1;    addr = myproc()-&gt;sz;    if(growproc(n) &lt; 0)        return -1;    return addr;&#125;\ngrowproc 函数如下：// Grow or shrink user memory by n bytes.// Return 0 on success, -1 on failure.intgrowproc(int n)&#123;    uint sz;    struct proc *p = myproc();    sz = p-&gt;sz;    if(n &gt; 0)&#123;        if((sz = uvmalloc(p-&gt;pagetable, sz, sz + n)) == 0) &#123;        return -1;        &#125;    &#125; else if(n &lt; 0)&#123;        sz = uvmdealloc(p-&gt;pagetable, sz, sz + n);    &#125;    p-&gt;sz = sz;    return 0;&#125;\nexecexec 系统调用通过指定的路径名打开文件，并读取该文件的 ELF 头部信息。XV6 的所有应用程序都使用通用的 ELF 格式，该格式由一个 ELF 头部和一系列的程序段头部组成。每个程序段头部描述需要加载到内存中的一段程序。在 XV6 中，应用程序通常只有一个程序段头部，而在其他操作系统中可能有多个。\n当 exec 读取文件系统中的文件时，首先检查该文件是否是 ELF 格式的二进制文件，即确认它的开头是否为四字节的幻数 &#39;0x7F&#39;、&#39;E&#39;、&#39;L&#39;、&#39;F&#39;。\n随后，exec 为用户进程调用 proc_pagetable，通过 uvmcreate 创建一个空的用户页表，并且仅为该页表添加 trampoline 和 trapframe 的映射，其他的虚拟地址空间暂时为空。\n对于每个程序段，exec 通过调用 uvmalloc 分配足够的物理页面并更新用户页表，接着使用 loadseg 将程序段和数据加载到这些物理页面中（然而在真实的操作系统中我们并不会这么做，程序和数据是分开的，这样对权限的设置可以更加精细）。此时，用户程序的各个段已经加载完成，接下来分配用户堆栈。\nexec 会调用 uvmalloc 分配两页物理帧：\n\n    第一页作为保护页，使用uvmclear设为无效，防止用户进程访问它；\n    第二页用于用户栈，从栈顶开始将命令行参数字符串和指向这些参数的指针数组argv[]推入栈中。\n\n\n当所有程序段加载完成并且用户栈设置完毕后，内核确定这次 exec 可以成功执行，此时，exec 清除进程的旧内存映像，释放旧页表占用的物理内存，并准备切换到新的页表。\n实验任务Print a page table (easy)第一个实验还是很简单的，关键是理解页表。类比 freewalk 函数，我们知道 pte &amp; (PTE_R|PTE_W|PTE_X) != 0 只会在页表最后一层发生，因为最后一层页表中页表项中W位，R位，X位起码有一位会被设置为1。每个页都有512个页表项，每个页表项占4个字节，我们递归一下就行。\nvoid vmprint(pagetable_t pagetable, int level)&#123;  if(!level)  &#123;    printf(&quot;page table %p\\n&quot;, pagetable);     level++;  &#125;  for(int i = 0; i &lt; 512; i++)&#123;    pte_t pte = pagetable[i];    if(pte &amp; PTE_V)    &#123;      if(level == 1) printf(&quot;..%d&quot;, i);      if(level == 2) printf(&quot;.. ..%d&quot;, i);      if(level == 3) printf(&quot;.. .. ..%d&quot;, i);      printf(&quot;: pte %p pa %p\\n&quot;,pte, PTE2PA(pte));      if((pte &amp; (PTE_R|PTE_W|PTE_X)) == 0)        vmprint((pagetable_t)PTE2PA(pte), level + 1);    &#125;  &#125;&#125;\n观察输出，我们可以注意到仅仅有5个界面被分配：代码页、保护页、用户栈、trapframe、trampoline。trampoline 的页表从255开始，因为我们有1个bit位不使用。\nA kernel page table per process (hard)通过第二个实验和第三个实验，我们要允许内核直接解引用用户提供的指针而不需要先转成物理地址。在第二个实验中，我们要修改内核来为每个进程分配一个独立的内核页表，而不是使用全局的内核页表。\n我们先修改 kvminit，用类似的方法在初始化进程的时候给进程创建一个内核页表。\npagetable_tproc_kpagetable()&#123;  pagetable_t pagetable;  pagetable = (pagetable_t) kalloc();  if(pagetable == 0)    return 0;    memset(pagetable, 0, PGSIZE);  uvmmap(pagetable, UART0, UART0, PGSIZE, PTE_R | PTE_W);  uvmmap(pagetable, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);  uvmmap(pagetable, CLINT, CLINT, 0x10000, PTE_R | PTE_W);  uvmmap(pagetable, PLIC, PLIC, 0x400000, PTE_R | PTE_W);  uvmmap(pagetable, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);  uvmmap(pagetable, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);  uvmmap(pagetable, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);  return pagetable;&#125;voiduvmmap(pagetable_t pagetable, uint64 va, uint64 pa, uint64 sz, int perm)&#123;  if(mappages(pagetable, va, sz, pa, perm) != 0)    panic(&quot;uvmmap&quot;);&#125;\n然后在 kernel/proc.c 里面的 allocproc 调用，还要把 procinit 里面进行的内核栈初始化过程移到 allocproc 里面。这样我们就将原本唯一的内核页表和预先分配好的内核栈变成了伴随进程创建的内核页表和内核栈。\n...// An empty user page table.p-&gt;pagetable = proc_pagetable(p);if(p-&gt;pagetable == 0)&#123;  freeproc(p);  release(&amp;p-&gt;lock);  return 0;&#125;// Init the kernal page tablep-&gt;kpagetable = proc_kpagetable();if(p-&gt;kpagetable == 0)&#123;    freeproc(p);    release(&amp;p-&gt;lock);    return 0;&#125;...\n接下来修改 scheduler 函数，在切换进程的时候，因为内核页表跟进程绑定，所以也要切换内核页表。当进程运行完毕，我们又需要切换回最初的内核页表，防止没有进程运行时内核页表为空。\n...p-&gt;state = RUNNING;c-&gt;proc = p;proc_inithart(p-&gt;kpagetable);swtch(&amp;c-&gt;context, &amp;p-&gt;context);c-&gt;proc = 0;kvminithart();...\n其中 proc_inithart 函数跟 kvminithart 一致，负责在调度进程的时候切换内核页表。\nvoidproc_inithart(pagetable_t kpt)&#123;  w_satp(MAKE_SATP(kpt));  sfence_vma();&#125;\n接下来就是进程的释放，此时我们需要把之前的内核页表和内核栈全部释放。内核栈就是普通的页面，用 kfree 释放即可，但要注意内核页表的底层的物理页面不能释放，我们可以效仿 vmprint 来处理，在 freeproc 加上下面的语句。\n...proc_freekstack(p-&gt;kpagetable, p-&gt;kstack);p-&gt;kstack = 0;                                    if(p-&gt;kpagetable)    proc_freekpagetable(p-&gt;kpagetable);p-&gt;kpagetable = 0;...\n用到的函数封装如下：\nvoidproc_freekstack(pagetable_t kpt,uint64 kst)&#123;  pte_t *pte = walk(kpt, kst, 0);  if(pte == 0)    panic(&quot;freeproc:free stack&quot;);  kfree((void*)PTE2PA(*pte));&#125;voidproc_freekpagetable(pagetable_t kpagetable)&#123;  for(int i = 0; i &lt; 512; i++)&#123;    pte_t pte = kpagetable[i];    if(pte &amp; PTE_V)    &#123;      kpagetable[i] = 0;      if((pte &amp; (PTE_R|PTE_W|PTE_X)) == 0)      &#123;        proc_freekpagetable((pagetable_t)(PTE2PA(pte)));      &#125;    &#125;  &#125;  kfree((void *)kpagetable);&#125;\n至此你可能快乐地认为做完了，然后发现直接报错 kvmpa，我就是碰到这个心态小崩了三个小时。事实上，我们在内核态的时候还要改变地址转换用的页表，选择进程的内核页表。注意有些函数 vm.c 里面没有，所以我们还得声明 proc.h 和 spinlock.h 两个库。#include &quot;spinlock.h&quot; #include &quot;proc.h&quot;uint64kvmpa(uint64 va)&#123;  uint64 off = va % PGSIZE;  pte_t *pte;  uint64 pa;  pte = walk(myproc()-&gt;kpagetable, va, 0); // 修改这里  if(pte == 0)    panic(&quot;kvmpa&quot;);  if((*pte &amp; PTE_V) == 0)    panic(&quot;kvmpa&quot;);  pa = PTE2PA(*pte);  return pa+off;&#125;\n至此第二个实验完成了，在 qemu 里面运行 usertests，出现下面的结果说明成功：\n\n  \n  图三：实验2结果图\n\n\n另外，我之前对此时的系统调用流程有些疑问。当进行系统调用的时候， trampoline.S 会将页表切换到内核页表，我之前在纠结是不是也要修改这一部分。但实际上并不需要，因为查看汇编代码可以发现，它实际上是交换了用户页表和内核页表，或者说将 satp 里的地址与 myproc()-&gt;trapframe-&gt;kernel_atp 里的交换了。那么，只需要在调度进程的时候切换内核页表就行了，无需考虑系统调用的问题。\nSimplify copyin/copyinstr（hard）这个实验不是很难，但有挺多细节的，我也卡了一段时间，然后发现是写挂了一些奇怪的地方……主要就是要实现每次用户页表改变的时候都将用户页表的内容复制到内核页表里，复制的函数如下：voidukvmcopy(pagetable_t old, pagetable_t new, uint64 oldsz, uint64 newsz)&#123;  pte_t *pte_from, *pte_to;  if(oldsz &gt; newsz)    return;    oldsz = PGROUNDUP(oldsz);  for(uint64 i = oldsz; i &lt; newsz; i += PGSIZE)  &#123;    if((pte_from = walk(old, i, 0)) == 0)      panic(&quot;ukvmcopy:src pte does not exist&quot;);    if((pte_to = walk(new, i, 1)) == 0)      panic(&quot;ukvmcopy:dst pte can not alloc&quot;);    uint64 pa = PTE2PA(*pte_from);    uint flags = (PTE_FLAGS(*pte_from) &amp; (~PTE_U));    *pte_to = PA2PTE(pa) | flags;  &#125;&#125;\n然后就是在四个需要改变的地方进行改动，先是 fork...np-&gt;sz = p-&gt;sz;np-&gt;parent = p;ukvmcopy(np-&gt;pagetable, np-&gt;kpagetable, 0, np-&gt;sz);// copy saved user registers.*(np-&gt;trapframe) = *(p-&gt;trapframe);...再是 exec...p-&gt;trapframe-&gt;epc = elf.entry;  // initial program counter = mainp-&gt;trapframe-&gt;sp = sp; // initial stack pointerukvmcopy(p-&gt;pagetable, p-&gt;kpagetable, 0, p-&gt;sz);proc_freepagetable(oldpagetable, oldsz);...sbrk稍有不同，我们需要修改它调用的 growproc，还要判断是否超过 PLIC 的范围。不过听答疑课发现好像应该是 CLINT，这很合理，因为 CLINT 地址比 PLIC 要低。\n如果要让它增长上限达到 KERNBASE，我们可以把 CLINT 啥的映射到 PHYSTOP 后面，也就是内核栈比较下面的位置。因为栈是从高往低增长的所以下面会有比较多的空闲位置。intgrowproc(int n)&#123;  uint sz;  struct proc *p = myproc();  sz = p-&gt;sz;  if(n &gt; 0)&#123;    if(PGROUNDUP(sz + n) &gt;= PLIC)      return -1;    if((sz = uvmalloc(p-&gt;pagetable, sz, sz + n)) == 0)      return -1;    ukvmcopy(p-&gt;pagetable, p-&gt;kpagetable, sz - n, sz);  &#125; else if(n &lt; 0)  &#123;    sz = uvmdealloc(p-&gt;pagetable, sz, sz + n);  &#125;  p-&gt;sz = sz;  return 0;&#125;最后是userinit...uvminit(p-&gt;pagetable, initcode, sizeof(initcode));p-&gt;sz = PGSIZE;ukvmcopy(p-&gt;pagetable, p-&gt;kpagetable, 0, p-&gt;sz);// prepare for the very first &quot;return&quot; from kernel to user.p-&gt;trapframe-&gt;epc = 0;      // user program counter...\n至此差不多就解决了，但还要记得把 copyin 和 copyinstr 换成 copyin_new 和 copyinstr_new，并且在 defs.h 中进行声明。\n不过说起来……这玩意过不了 make grade，因为电脑太卡会超时……\n老师的方法跟讲义的不同，采取的方式是共享内核页表中不用修改的部分，只修改Kernel顶级目录的底部条目（刚好1GB），这会让内存的分配和回收复杂一些，但大致上的思路是一样的。不过这确实对性能有很大的提升。而且老师对权限的控制更加精确，通过禁用 PTE_U 和 PTE_W，让开发者在进行不恰当的操作时内核能及时报错，这显然是有利于开发的。\n调试指南做第二个实验的时候破防了，调gdb的时候又破防了，写一下调试方法。\n大概是以下几步：\n\n启动 QEMU 调试模式：在项目目录下运行：\nmake qemu-gdb\n\n启动 GDB：在另一个终端中，进入同样的目录，运行：\ngdb-multiarch\n\n载入符号表：在 GDB 中载入要调试的程序（例如 ls）的符号表：\nfile user/_ls\n\n设置断点：在主函数或指定行号处设置断点：\nb main\n\n开始调试：运行命令继续执行：\ncontinue\n\n调试交互：在 GDB 终端中查看变量，继续执行，或在源代码中打更多断点，之后就跟正常gdb一样了。\n\n\n注意，.gdbinit文件会有安全问题，所以要在文件里面加上add-auto-load-safe-path YOUR_PATH/XV6-labs-2020/.gdbinit，否则程序无法正常运行。\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","页表"]},{"title":"MIT-6-S081-Lab2: System call","url":"/2025/03/03/MIT-6-S081-Lab2%EF%BC%9ASystem-call/","content":"知识点我们从操作系统的具体行为出发，先分析操作系统的硬件支持和进程的实现机制，再通过实例加深印象，最后简略地了解内核的编译过程和QEMU的仿真原理。\n操作系统的硬件支持操作系统必须满足三个要求：多路复用、隔离和交互。\n尽管我们可以将系统调用实现为一个库，以此来让应用程序直接与硬件交互并且以最佳方式使用资源，但这要求所有应用程序相互信任并且没有错误，这很难做到。因此我们需要禁止应用程序直接访问硬件资源，而是将资源抽象为服务。文件系统抽象磁盘，进程调度抽象 CPU，exec 构建的内存映像抽象物理内存，文件描述符抽象数据交互。这样既简化了应用程序的开发，也保护了系统安全。\n这就要求处理器可以实现两个功能：支持不同模式、支持虚拟内存\nRISC-V有三种 CPU 可以执行指令的模式：机器模式(Machine Mode)、用户模式(User Mode)和管理模式(Supervisor Mode)。机器模式用于配置计算机，程序在用户模式下只能执行有限的指令，某些特权指令必须在管理模式下进行。\n不过管理模式拥有的特权也并不多，一是可以读写控制寄存器（Lab4），一是可以使用 PTE_U 标志位为0的PTE（Lab3），仅此而已。它也没办法直接读写任意物理地址。\n想要调动内核函数的应用程序必须过渡到内核，通过 CPU 提供的 ecall 指令可以从指定的入口点切换到管理模式，经过参数验证后就能决定是否执行应用程序请求的操作。\n所以一个关键问题就在于操作系统的哪些部分以管理模式运行。操作系统全部在内核中的组织称作宏内核，大部分操作系统在用户模式下执行的组织称作微内核。\n宏内核不同部分之间的接口通常很复杂，因此开发人员容易犯错误，微内核减少了这一点。但宏内核不必考虑硬件权限的问题，操作系统的不同部分也更加容易合作，性能也更好，这也是大多数Unix（如 XV6）操作系统采用宏内核的原因。\n进程自己看到的地址被称作虚拟地址，而实际内存芯片上的位置被称作物理地址，通过三级页表结构（Sv39）完成虚拟地址到物理地址的转换。物理地址空间都在 0x80000000 到 0x86400000 之间（实际储存在物理内存 DRAM 中），但是虚拟地址范围有所不同，这使得内核和用户进程可以使用同一块物理内存而保持虚拟地址隔离。\nXV6 为每个进程维护两个独立的页表：\n\n  \n    用户页表（p->pagetable）：\n    \n      用户地址空间：0x0 到 PLIC（0x0C000000），结构如图所示：\n        \n0x3FFFFFF000 (MAXVA)\n┌─────────────┐ ← trampoline（用户和内核共享）\n├─────────────┤ ← trapframe（用户页表映射）\n├─────────────┤ ← 堆区域（通过 malloc 向上扩展）\n├─────────────┤ ← 栈区域（向下扩展）\n├─────────────┤ ← 全局变量\n├─────────────┤ ← 程序代码（指令）\n0x0\n      \n      保护区域：PLIC 到 TRAMPOLINE（0x3FFFFFFF000），禁止用户访问。\n      无内核映射：用户页表不包含内核代码或设备地址。\n    \n  \n  \n    内核页表（kernel_pagetable）：\n    \n      全局唯一：所有进程在内核态共享此页表。\n      内核地址空间：KERNBASE（0x80000000）到 PHYSTOP（0x86400000），包含：\n        \n0xFFFFFFFFFF (MAXVA)\n┌─────────────┐ ← trampoline（共享）\n├─────────────┤ ← 内核栈（每个进程独立）\n├─────────────┤ ← 设备内存（如 UART、磁盘）\n├─────────────┤ ← 内核代码与数据（恒等映射）\n0x80000000 (KERNBASE)\n      \n    \n  \n\n\n\n在 XV6 操作系统中，trampoline 页被同时映射到了用户地址空间和内核地址空间的顶端。当从用户态切换到内核态时，它执行 uservec 保存用户寄存器并切换至内核页表；当从内核态返回到用户态时，它执行 userret 恢复用户页表和环境。具体内容见Lab4笔记。还要注意进程地址空间有最大范围，RISC-V上的指针有64位，硬件在页表中查找虚拟地址时只使用39位，而 XV6 只使用其中的38位。\n实现进程的具体机制内核用proc结构体记录进程的所有信息，其中最为重要的信息是进程的用户页表，内核栈，当前运行状态：struct proc&#123;    enum proc_state state;   // 状态：新建/就绪/运行/阻塞/退出等    struct proc *parent;     // 父进程指针    // ...其他字段    int pid;                 // 进程ID    void *kstack;            // 内核栈地址    uint64 sz;               // 进程的虚拟地址空间的大小    pagetable_t pagetable;   // 用户页表指针    struct trapframe *trapframe; // 用户态上下文保存区域    struct context context;  // 用于保存进程的内核寄存器状态     // ...其他字段&#125;;\n在 XV6 中，每个进程拥有独立的用户页表和专属的内核栈。用户页表仅映射用户地址空间（从 0x0 到 PLIC），负责管理进程的用户态内存隔离与安全；内核态执行时则使用全局共享的内核页表（kernel_pagetable），通过硬件页表切换机制（由 trampoline 代码实现）从用户页表切换到内核页表。每个进程在内核态运行时使用独立的内核栈，该栈位于内核地址空间的高端区域，通过内核页表映射且带有保护页，用户代码无法直接访问。当进程通过陷阱进入内核时，CPU 自动切换到内核页表和内核栈，确保即使用户栈损坏，内核仍能安全执行系统调用或处理中断。这种设计通过物理隔离用户与内核地址空间，实现了权限分离和操作系统的稳定性。\n当进行系统调用时，它并不是直接调用操作系统中对应的函数，而是先通过调用 ecall 指令（要调用的系统调用的编号作为参数）从指定的入口点进入管理模式，保存用户态上下文到陷阱帧后切换到内核态，syscall 函数对参数进行检查后进行调用，最后通过 sret 指令恢复用户态上下文并返回用户态。整个切换过程如图：\n用户代码 → ecall → 保存用户态上下文到陷阱帧 → syscall函数分发系统调用 → 使用内核栈执行系统调用（包括对参数进行检查） → sret → 返回用户栈\n下面我们一步步进行分析：\n\n参数准备\n 用户程序根据用户态的头文件user/user.h找到跳板函数（如fork()，在usys.pl文件中被定义），并通过寄存器传递参数：\n\na0-a6：存放系统调用参数\n\na7：存放系统调用编号（如SYS_exec）\n\n\n\n触发内核入口\n 跳板函数调用 ecall 指令，硬件会自动触发一个陷阱，此时，硬件会：\n\n切换特权级\n将 PC 的值保存在 sepc 寄存器中\n跳转到预设的内核入口地址\n注意硬件不负责上下文保存，进入内核后上下文保存由内核处理程序负责\n\n\n内核态处理流程\n\n上下文保存\n 将用户程序的当前状态保存到陷阱帧中。其中陷阱帧（trapframe）是保存用户寄存器等的内存区域。保存的内容包括用户寄存器（如a0-a7）等，以便后续恢复用户态时能够正确继续执行。\n\n系统调用分发 内核通过syscall()函数分发系统调用：\n void syscall(void) &#123;    int num = p-&gt;trapframe-&gt;a7; // 从陷阱帧获取系统调用号    if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls)) &#123;        p-&gt;trapframe-&gt;a0 = syscalls[num](); // 调用对应函数并保存返回值    &#125; else &#123;        p-&gt;trapframe-&gt;a0 = -1; // 错误处理    &#125;&#125;\n\n注：syscalls数组：函数指针表，通过系统调用号索引（如syscalls[SYS_exec] = sys_exec）\n\n\n系统调用参数的安全处理 内核通过专用函数argint、argaddr和argfd从陷阱帧中检索第n个系统调用参数并以整数、指针或文件描述符的形式保存获取用户参数。他们都调用argraw来检索相应的保存的用户寄存器：\n // 示例：从陷阱帧获取第n个整数参数int argint(int n, int *ip) &#123;    *ip = p-&gt;trapframe-&gt;a0 + n*4; // 假设参数为32位整型    return 0;&#125;\n 有些系统调用传递指针作为参数，内核必须使用这些指针来读取或写入用户内存。然而，这会有两个问题，一是用户程序可能并不完善或者有恶意，二是因为内核和用户态程序的页表是不同的，所以内核无法直接通过普通指令从用户提供的地址读取或写入。\n 因此内核实现了安全地将数据传输到用户提供的地址和从用户提供的地址传输数据的功能。\n\n安全访问函数族\n\n\n 函数\n 方向\n 作用\n 底层实现\n\n\n copyin(pg, dst, srcva, len)\n 用户 → 内核\n 从用户空间复制数据到内核缓冲区\n 调用 walkaddr 验证地址\n\n\n copyout(pg, dstva, src, len)\n 内核 → 用户\n 从内核复制数据到用户空间\n 同上\n\n\n fetchstr(addr, buf, max)\n 用户 → 内核\n 从地址 addr 中安全提取用户空间字符串\n 封装 copyinstr\n\n\n\n页表遍历验证 (walkaddr)\n// kernel/vm.cuint64 walkaddr(pagetable_t pagetable, uint64 va) &#123;    pte_t *pte = walk(pagetable, va, 0);  // 遍历页表获取页表项    if(!pte || !(*pte &amp; PTE_V)) return 0;  // 检查有效位    if(!(*pte &amp; PTE_U)) return 0;          // 检查用户权限位    return PTE2PA(*pte);                   // 返回物理地址&#125;\n\n字符串安全提取示例 (copyinstr)\n// kernel/vm.cint copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max) &#123;    uint64 n, va0, pa0;    while(got_null == 0 &amp;&amp; max &gt; 0) &#123;        va0 = PGROUNDDOWN(srcva);        pa0 = walkaddr(pagetable, va0);    // 安全验证        if(pa0 == 0) return -1;            // 非法地址        // 从pa0复制数据到dst...        srcva++;        max--;    &#125;    return 0;&#125;\n\n返回值储存系统调用结果存入p-&gt;trapframe-&gt;a0陷阱帧中。\n\n恢复寄存器\n将存储在 trapframe 里的内容恢复。\n\n\n\n\n\n返回用户态 运行sret指令：\n\n恢复S状态寄存器和程序计数器\n切换回用户特权级\n跳转到陷阱帧中的epc（异常程序计数器）指向的下一条指令，继续用户态程序的运行\n\n\n\n每个进程都有一个执行线程（或简称线程）来执行进程的指令。一个线程可以挂起并且稍后再恢复。为了透明地在进程之间切换，内核会挂起当前运行的线程，并恢复另一个进程的线程。线程的大部分状态（本地变量、函数调用返回地址）存储在栈区域上。\n切换过程：挂起当前线程 → 保存当前状态到陷阱帧 → 选择下一个就绪线程 → 加载新线程的陷阱帧 → 恢复执行\n实例：内核的启动与第一个进程的运行\n上电与引导加载\n RISC-V上电后，引导加载程序从只读内存启动，将 XV6 内核载入物理地址 0x80000000（避开I/O设备地址0x0:0x80000000）。\n\n机器模式初始化\n 入口函数 _entry 设置初始栈 stack0，调用C代码 start()，完成仅机器模式允许的配置：\n\n时钟芯片编程：初始化计时器中断。\n\n模式切换：通过 mret 指令切换到管理模式（设置 mstatus 寄存器，main 函数地址写入 mepc）。\n\n\n\n内核主初始化\n main() 函数初始化设备及子系统（如内存管理、进程控制），调用 userinit() 创建首个进程。具体实现见Lab3笔记。\n\n首个进程启动\n\n进程执行汇编程序 initcode.S\n\n触发 exec 系统调用加载 /init 程序。\n\n\n/init完成用户环境搭建：\n\n创建控制台设备\n打开标准文件描述符（0/1/2）\n启动shell，完成系统启动。\n\n\n\n\n\n内核的编译过程\n源码编译\n\nMakefile 调用 GCC 将C文件（如proc.c）编译为 RISC-V 汇编文件（proc.S）。\n\n汇编器生成二进制目标文件（proc.o）。\n\n\n\n链接与生成内核\n\n系统加载器（Loader）收集所有 .o 文件，生成内核可执行文件。\n\n生成调试文件 kernel.asm，包含完整汇编代码（用于定位指令级Bug）。\n\n示例指令格式：\n  0000000080000000 &lt;_entry&gt;:    80000000:   0000a117            auipc   sp,0xa  // 指令机器码与汇编对应\n\n\n\n编译参数\n\n-m 参数：指定RISC-V虚拟机的内存容量（如 -m 128M 表示128MB内存）。\n\n\n\n通过QEMU运行内核\nQEMU仿真原理\n\nQEMU模拟RISC-V硬件平台（“虚拟主板”）。\n\n指令执行流程：\n\n每个虚拟CPU核循环读取指令（4/8字节）。\n\n解析RISC-V指令，转换为宿主机指令执行。\n\n维护虚拟寄存器和内存状态。\n\n\n\n\n\n权限指令仿真\n\n普通权限指令：用户态指令（如加法、跳转）。\n\n特殊权限指令：内核态指令（如mret、ecall），由QEMU严格模拟权限检查。\n\n\n\n调试支持\n\n结合 kernel.asm 可追踪指令执行路径，定位异常行为。\n\n\n\n实验任务XV6 System Calls实际上要修改的部分就是按之前系统调用的切换过程的流程来的。\n添加系统调用步骤如下：\n\n在 user/user.h 中添加声明 在该头文件中定义新系统调用函数的原型。\n\n在 user/usys.pl 中添加入口 在出口列表中添加新条目。\n\n在 kernel/syscall.h 中定义系统调用号 添加新的系统调用号定义。\n\n在 kernel/syscall.c 中添加处理函数\n\n用 extern 全局声明新的内核调用函数。\n\n将对应的处理函数添加到 syscalls 函数指针数组中。\n\n\n\n在合适的位置写好新调用函数具体实现\n\n\nSystem call tracing（moderate）这个Lab选题简直神了，愣是带着你把所有流程过了一遍，写完这个题感觉学到了很多。\n要求我们实现对某些系统调用的追踪，因为我们在整个进程中都要进行追踪，所以追踪名单要写进进程的 proc 结构体。\nstruct proc &#123;  struct spinlock lock;  // p-&gt;lock must be held when using these:  enum procstate state;        // Process state  struct proc *parent;         // Parent process  void *chan;                  // If non-zero, sleeping on chan  int killed;                  // If non-zero, have been killed  int xstate;                  // Exit status to be returned to parent&#x27;s wait  int pid;                     // Process ID  uint64 trace_mask;           // Instructions need to be monitored  // these are private to the process, so p-&gt;lock need not be held.  uint64 kstack;               // Virtual address of kernel stack  uint64 sz;                   // Size of process memory (bytes)  pagetable_t pagetable;       // User page table  struct trapframe *trapframe; // data page for trampoline.S  struct context context;      // swtch() here to run process  struct file *ofile[NOFILE];  // Open files  struct inode *cwd;           // Current directory  char name[16];               // Process name (debugging)&#125;;\n创建进程的时候需要清空追踪名单，我们修改 proc.c 中的 allocproc 函数\nstatic struct proc*allocproc(void)&#123;  ······  // Set up new context to start executing at forkret,  // which returns to user space.  memset(&amp;p-&gt;context, 0, sizeof(p-&gt;context));  p-&gt;context.ra = (uint64)forkret;  p-&gt;context.sp = p-&gt;kstack + PGSIZE;  p-&gt;trace_mask = 0;  return p;&#125;\n然后就是在 sysproc.c 里面实现更新追踪名单的具体代码，argint 接受寄存器的参数。uint64sys_trace(void)&#123;  int mask;  if(argint(0, &amp;mask) &lt; 0)     return -1;  myproc()-&gt;trace_mask = mask;  return 0;&#125;\n接下来实现追踪，在参数检查通过后判断该系统调用是否被追踪，如果被追踪就输出信息。\nvoidsyscall(void)&#123;  int num;  struct proc *p = myproc();  num = p-&gt;trapframe-&gt;a7;  if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) &#123;    p-&gt;trapframe-&gt;a0 = syscalls[num]();    if(p-&gt;trace_mask &amp; (1&lt;&lt;num))    &#123;      printf(&quot;%d: syscall %s -&gt; %d\\n&quot;, p-&gt;pid, syscall_names[num], p-&gt;trapframe-&gt;a0);    &#125;  &#125; else &#123;    printf(&quot;%d %s: unknown sys call %d\\n&quot;,            p-&gt;pid, p-&gt;name, num);    p-&gt;trapframe-&gt;a0 = -1;  &#125;&#125;\n注意输出的名称需要自己定义。\nconst char *syscall_names[] = &#123;[SYS_fork]   &quot;fork&quot;,[SYS_exit]   &quot;exit&quot;,[SYS_wait]   &quot;wait&quot;,[SYS_pipe]   &quot;pipe&quot;,[SYS_read]   &quot;read&quot;,[SYS_kill]   &quot;kill&quot;,[SYS_exec]   &quot;exec&quot;,[SYS_fstat]  &quot;fstat&quot;,[SYS_chdir]  &quot;chdir&quot;,[SYS_dup]    &quot;dup&quot;,[SYS_getpid] &quot;getpid&quot;,[SYS_sbrk]   &quot;sbrk&quot;,[SYS_sleep]  &quot;sleep&quot;,[SYS_uptime] &quot;uptime&quot;,[SYS_open]   &quot;open&quot;,[SYS_write]  &quot;write&quot;,[SYS_mknod]  &quot;mknod&quot;,[SYS_unlink] &quot;unlink&quot;,[SYS_link]   &quot;link&quot;,[SYS_mkdir]  &quot;mkdir&quot;,[SYS_close]  &quot;close&quot;,[SYS_trace]  &quot;trace&quot;,&#125;;\n至此trace系统调用已经基本实现，还有常规的添加声明、添加入口什么的不再赘述。\nSysinfo（moderate）这一个系统调用主要就是要实现 count_free_mem 和 count_process 两个函数来统计内存和进程，注意新添加的函数要在 defs.h 里声明。uint64sys_sysinfo(void)&#123;  uint64 addr;  if(argaddr(0, &amp;addr) &lt; 0)  &#123;    return -1;  &#125;  struct sysinfo sinfo;  sinfo.freemem = count_free_mem();  sinfo.nproc = count_process();  if(copyout(myproc()-&gt;pagetable, addr, (char *)&amp;sinfo, sizeof(sinfo)) &lt; 0)  &#123;    return -1;  &#125;  return 0;&#125; 主要困扰我的点在于自旋锁(spinlock)的理解，稍微整理一点锁的机制，具体细节后面的课应该会讨论。\n\n锁的核心作用 在多核 CPU 环境下，锁用于保护共享数据的原子性访问。XV6 中主要使用自旋锁（Spinlock），其核心规则为：\n\n互斥访问：同一时间只有一个 CPU 能持有锁\n\n临界区保护：任何访问共享资源的代码必须持有对应的锁\n\n避免死锁：按固定顺序获取锁，禁止在持有锁时触发调度\n\n\n\n内存管理（kalloc.c）中的锁\n\n共享资源：空闲内存链表\n// kernel/kalloc.cstruct &#123;    struct spinlock lock;    struct run *freelist;&#125; kmem;\n\n锁的使用场景\n| 操作         | 加锁必要性                                               | 代码示例                           ||———————|—————————————————————————————|——————————————————|| 分配内存     | 防止多核同时修改空闲链表，导致链表断裂或重复分配         | kalloc() 中的 acquire(&amp;kmem.lock) || 释放内存     | 同上，保证链表插入操作的原子性                           | kfree() 中的 acquire(&amp;kmem.lock)  || 统计空闲内存 | 遍历链表时若不加锁，可能读到其他 CPU 正在修改的中间状态，导致计数错误/崩溃 | count_free_mem() 中的锁保护        |\n\n\n\n\n回到程序的实现，关于记录空闲页的方法，XV6 采用的是空闲链表法，直接遍历即可。uint64count_free_mem(void)&#123;  uint64 num = 0;  struct run *r;  acquire(&amp;kmem.lock);  r = kmem.freelist;  while(r)  &#123;    r = r-&gt;next;    num++;  &#125;  release(&amp;kmem.lock);  return num * PGSIZE;&#125;通过阅读 procdump 及相关代码可以发现，XV6 的进程结构体被保存在 proc[NPROC] 数组中。proc-&gt;state 字段记录了进程控制块(PCB)的当前状态，因此我们只需遍历该数组，统计状态不是 UNUSED 的条目即可。uint64count_process(void)&#123;  uint64 num = 0;  struct proc *p;  for(p = proc; p &lt; &amp;proc[NPROC]; p++)&#123;    if(p-&gt;state != UNUSED)      num++;  &#125;  return num;&#125;\n小结至此Lab2宣告结束，我们理解了实现多路复用和隔离的硬件要求，对系统调用的全流程有了比较清晰的了解。同时，我们简略地了解了 XV6 系统的启动、内核的编译过程以及QEMU仿真的原理，对更底层的部分进行了初步探索。在实现Lab的时候，大致思路也是根据系统调用的流程，但具体实现则需要对需要实现的功能有一定的了解，比如 sysinfo 程序中我们需要知道记录空闲页的方法，还需要知道进程储存的位置，以及自旋锁的使用方法，这些需要通过阅读源码去寻找，也颇具挑战性。总之，至此我们已经大致熟悉了系统调用的流程，继续加油吧。\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","系统调用"]},{"title":"MIT-6-S081-Lab10：Mmap","url":"/2025/05/06/MIT-6-S081-Lab10%EF%BC%9AMmap/","content":"实验内容mmap(hard)最后的实验要求我们实现最基础的 mmap 功能，也就是将一个文件直接映射到内存中，之后通过直接读写内存来读写文件，可以大大提升需要频繁读写的文件的处理效率。\n首先照例注册 mmap 和 munmap 系统调用，接下来定义用于保存内存映射信息的结构体 struct vma，每个进程分配 NVMA 个结构体。struct vma&#123;  uint64 addr;  uint64 length;  int prot;  int flags;  int fd;  int offset;  struct file *file;&#125;;struct proc&#123;    ···    struct vma vmas[NVMA];         // Virtual memory areas&#125;\n接下来处理 mmap 函数，对于权限要求不合法的情况进行拒绝。在我的 vma 中默认 length = 0 代表 vma 无效，找到一个空位后就可以进行初始化了。在这里我们并不会分配内存，而是在触发缺页异常的时候才进行分配。我们给用户程序提供用户空间中的虚拟地址 v-&gt;addr 作为文件的起始位置，记得要增长 p-&gt;sz 和对文件进行引用，而且 length, addr 和 p-&gt;sz 都要对齐。uint64sys_mmap(void)&#123;  uint64 addr;  int length, prot, flags, fd, offset;  struct file* f;  if (argaddr(0, &amp;addr) &lt; 0 || argint(1, &amp;length) &lt; 0 || argint(2, &amp;prot) &lt; 0      || argint(3, &amp;flags) &lt; 0 || argfd(4, &amp;fd, &amp;f) &lt; 0 || argint(5, &amp;offset) &lt; 0)    return -1;    if(addr != 0)    panic(&quot;mmap: addr not 0&quot;);  if(offset != 0)    panic(&quot;mmap: offset not 0&quot;); // required by xv6  struct proc *p = myproc();  struct file *file = p-&gt;ofile[fd];  if ((prot &amp; PROT_READ) &amp;&amp; !f-&gt;readable)    return -1; // can&#x27;t read from write-only file  if ((prot &amp; PROT_WRITE) &amp;&amp; !f-&gt;writable &amp;&amp; flags == MAP_SHARED)    return -1; // can&#x27;t write to read-only file  for(int i = 0; i &lt; NVMA; i++)  &#123;    if (p-&gt;vmas[i].length == 0)    &#123;      struct vma *v = &amp;p-&gt;vmas[i];      v-&gt;addr = p-&gt;sz;      v-&gt;length = PGROUNDUP(length);      v-&gt;prot = prot;      v-&gt;flags = flags;      v-&gt;fd = fd;      v-&gt;offset = offset;      v-&gt;file = file;      filedup(file);      p-&gt;sz += v-&gt;length;      return v-&gt;addr;    &#125;  &#125;  return -1;&#125;\n然后在触发缺页异常时进行页面分配，这里的处理逻辑一定要严谨，不然就算过了 mmaptest 也有可能在 usertest 里面遇到访问非法地址导致缺页但不需要分配页面的情况，这时候会卡死。大致思路是先判掉本身就不可能触发缺页异常的地址，然后搜索 vmas，如果找不到同样得判掉。找到了就进行常规的页面分配，然后用 readi 从文件中读入一页。这里我们处理了偏移量非零的情况，实际上因为实验要求也可以不管。···  else if(r_scause() == 13 || r_scause() == 15)  &#123;    //panic(&quot;here&quot;);    uint64 va = r_stval();    struct proc *p = myproc();    if(va &gt;= MAXVA || va &gt; p-&gt;sz)      p-&gt;killed = 1;    else    &#123;      va = PGROUNDDOWN(va);      int found = 0;      for(int i = 0; i &lt; NVMA; i++)      &#123;        struct vma *vma = &amp;p-&gt;vmas[i];        if (vma-&gt;length == 0)          continue;        if (va &gt;= vma-&gt;addr &amp;&amp; va &lt; vma-&gt;addr + vma-&gt;length)        &#123;          found = 1;          uint64 pa = (uint64)kalloc();          if (pa == 0)          &#123;            p-&gt;killed = 1;            break;          &#125;          memset((void*)pa, 0, PGSIZE);          int flag = (vma-&gt;prot &lt;&lt; 1) | PTE_U | PTE_V;          if (mappages(p-&gt;pagetable, va, PGSIZE, pa, flag) != 0)          &#123;            //printf(&quot;???&quot;);            kfree((void*)pa);            p-&gt;killed = 1;            break;          &#125;          struct inode *ip = vma-&gt;file-&gt;ip;          ilock(ip);          readi(ip, 0, pa, vma-&gt;offset + (va - vma-&gt;addr), PGSIZE);          iunlock(ip);          break;        &#125;      &#125;      if (!found)        p-&gt;killed = 1;    &#125;  &#125;···\n接下来实现 munmap，这也是整个实验中最复杂的一部分。我们分三种情况进行处理，只删除一部分的情况是简单的，只需要修改 v-&gt;addr 和 v-&gt;length 即可，全部删除的话还需要关闭文件。然后我们用 uvmunmap 解除映射关系并且释放物理内存。如果有共享标签，那么就还要对文件进行修改，这一部分比较复杂，我们单独用 vmafilewrite 函数来处理。uint64sys_munmap(void)&#123;  uint64 addr;  int length, offset;  if (argaddr(0, &amp;addr) &lt; 0 || argint(1, &amp;length) &lt; 0) &#123;    return -1;  &#125;  struct proc *p = myproc();  int close = 0;  for(int i = 0; i &lt; NVMA; i++)  &#123;    struct vma *v = &amp;p-&gt;vmas[i];    if (v-&gt;length == 0)      continue;    if (addr &gt;= v-&gt;addr &amp;&amp; addr &lt; v-&gt;addr + v-&gt;length)    &#123;      offset = addr - v-&gt;addr;      addr = PGROUNDDOWN(addr);      // printf(&quot;addr: %p, v-&gt;addr: %p,length: %d, v-&gt;length: %d\\n&quot;, addr, v-&gt;addr, length,v-&gt;length);      if(addr == v-&gt;addr)      &#123;        if(length &gt;= v-&gt;length)        &#123;          close = 1;          length = v-&gt;length;          v-&gt;length = 0;        &#125;        else        &#123;          v-&gt;addr += length;          v-&gt;length -= length;        &#125;      &#125;      else      &#123;        length = v-&gt;length - (addr - v-&gt;addr);        v-&gt;length -= length;      &#125;      if(v-&gt;flags == MAP_SHARED)      &#123;        struct file *ip = v-&gt;file;        if(vmafilewrite(ip, addr, length, offset) &lt; 0)          return -1;      &#125;      // printf(&quot;addr: %p, v-&gt;addr: %p,length: %d, v-&gt;length: %d\\n&quot;, addr, v-&gt;addr, length,v-&gt;length);      uvmunmap(p-&gt;pagetable, addr, PGROUNDUP(length)/PGSIZE, 1);      // printf(&quot;here2\\n&quot;);      if(close)      &#123;        fileclose(v-&gt;file);        v-&gt;file = 0;      &#125;      break;    &#125;  &#125;  return 0;&#125;\nvmawrite 是要我们对文件进行写入，我们不难发现这个功能跟 filewrite 的功能是很像的。但 filewrite 不支持从给定偏移量修改，所以我们把写入文件的部分抄过来，再做一点小小的改动。这里其实可以根据页面是否被写入过做一些优化，但我们这里并没有实现这个功能。intvmafilewrite(struct file *f, uint64 addr, int n, int offset)&#123;  int r;  if(f-&gt;writable == 0)    return -1;  int max = ((MAXOPBLOCKS-1-1-2) / 2) * BSIZE;  // printf(&quot;max: %d\\n&quot;, max);  int i = 0;  while(i &lt; n)  &#123;    int n1 = n - i;    if(n1 &gt; max)      n1 = max;    begin_op();    ilock(f-&gt;ip);    if ((r = writei(f-&gt;ip, 1, addr + i, offset, n1)) &gt; 0)      offset += r;    iunlock(f-&gt;ip);    end_op();    if(r != n1)    &#123;      // error from writei      break;    &#125;    i += r;  &#125;  return 0;&#125;\n还有一个小的注意点：有缺页异常的时候 uvmunmap 和 uvmcopy 的逻辑要修改。跟之前写时复制分支的处理一样，在遇到无效页面时不能报错。···if((*pte &amp; PTE_V) == 0)    continue;···\n接着修改 exit，当进程退出时我们也要对 vma 进行回收。···for(int i = 0; i &lt; NVMA; i++)&#123;    struct vma *v = &amp;p-&gt;vmas[i];    if (v-&gt;length == 0)        continue;    if(v-&gt;flags == MAP_SHARED)    &#123;        struct file *ip = v-&gt;file;        if(vmafilewrite(ip, v-&gt;addr, v-&gt;length, v-&gt;offset) &lt; 0)        continue;    &#125;    uvmunmap(p-&gt;pagetable, v-&gt;addr, PGROUNDUP(v-&gt;length)/PGSIZE, 1);    fileclose(v-&gt;file);    v-&gt;file = 0;&#125;begin_op();iput(p-&gt;cwd);end_op();p-&gt;cwd = 0;\n最后修改 fork，将 vma 的内容复制过来。···for(i = 0; i &lt; NVMA; i++)&#123;    np-&gt;vmas[i].length = 0;    if(p-&gt;vmas[i].length)    &#123;        memmove(&amp;np-&gt;vmas[i], &amp;p-&gt;vmas[i], sizeof(struct vma));        filedup(np-&gt;vmas[i].file);    &#125;&#125;safestrcpy(np-&gt;name, p-&gt;name, sizeof(p-&gt;name));···\n至此 mmap 和 munmap 得以实现，我们实现了简单的内存映射文件。\n小结完结撒花！操作系统之旅大概暂时就到这里，花了大概两个月的时间……其实看中间的其他博客你就知道为什么拖了这么久了……这是进大学以来完整（大概）自学的第一门公开课，之前试图学 MIT-Missing-Semester 不知道为啥就咕咕咕了，总之学完了还是相当开心的啦。通过 XV6 这个简单的操作系统，我对操作系统的大致结构有了基本的了解，也学到了一些常见的处理技巧，收获算是相当不错。感觉最方便的调试方式还是直接输出），gdb 什么的真不熟吧（笑）。接下来大概是 cs143？希望自己还能坚持下去，又义无反顾地投向下一个坑了呢。\n照例扔一张通关截图在这里。\n\n  \n  图一：通关截图\n\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","文件系统","陷阱指令","缺页异常"]},{"title":"MIT-6-S081-Lab4: Traps","url":"/2025/03/19/MIT-6-S081-Lab4%EF%BC%9ATraps/","content":"知识点陷入机制有三类事件会迫使 CPU 中断指令的正常执行，并将控制权转交给处理该事件的特定代码。\n\n第一类是系统调用：当用户程序执行 ecall 指令，向内核请求某些服务时，CPU 便会中断当前执行的程序。\n第二类是异常：当指令（无论是用户还是内核态）出现非法操作，例如除以零或访问无效虚拟地址时，会触发异常。\n第三类是设备中断：当设备发出信号需要处理，例如磁盘硬件完成读写操作时，CPU 会响应设备中断。\n\n\n我们将这三种情况统称为“陷阱”，一般而言，发生陷阱时，我们希望后续代码能恢复执行，而不必让人察觉到特殊情况，即保持陷阱的透明性。典型处理流程为：陷阱强制将控制权移交内核，内核保存寄存器与状态后执行处理程序（如系统调用实现或设备驱动），处理完成后恢复状态并返回到中断点继续执行。在 XV6 中，这一流程细化为四步：CPU 硬件操作完成初步上下文切换，汇编代码设置陷阱向量入口，C语言陷阱处理程序根据类型（用户态陷阱、内核态陷阱、定时器中断）分发逻辑，最终由系统调用或设备驱动完成具体操作。其中，系统调用由内核直接提供服务，设备中断由内核统一处理以隔离硬件细节，而异常（如非法指令）则通过终止用户进程确保系统安全，三者共同体现了内核作为资源管控者的核心角色。\n每个RISC-V CPU都有一组控制寄存器，内核写入这些寄存器来告诉 CPU 如何处理陷阱，内核也可以读取这些寄存器来了解已经发生的陷阱。riscv.h 里包含了所有的寄存器作用，以下是一些常用的寄存器：\n\n  stvec：内核在此寄存器中写入其陷阱处理程序的地址；RISC-V 遇到陷阱时会跳转到这个地址进行处理。\n  sepc：当陷阱发生时，RISC-V 会在该寄存器中保存程序计数器（PC）的内容，因为处理陷阱时要将 stvec 中储存的地址加载到 PC 中。sret（从陷阱返回）指令会将 sepc 的值复制回 PC，内核还可以通过写入 sepc 来控制 sret 的返回位置。\n  scause：RISC-V 会在此寄存器中存放一个描述陷阱原因的数字。\n  sscratch：用作内核的临时存储，在陷阱处理程序中最初阶段被使用。\n  sstatus：用于控制并反映当前管理模式下的状态信息，如中断使能（SIE）以及模式信息（SPP）等。SIE 控制设备中断的启用状态。如果内核清除 SIE，RISC-V 将延迟设备中断，直到内核重新设置 SIE。SPP 指示陷阱源于用户模式还是管理模式，并控制 sret 返回时的模式。\n  sie：用于控制管理模式（S态）下中断的使能，决定具体哪些S态中断（软件、定时器、外部）可以触发异常处理。sip：管理内核态中断状态的寄存器，实时反映哪些中断事件已触发但尚未被 CPU 处理。  \n\n\n上述寄存器都用于在管理模式下处理陷阱，在用户模式下不能读取或写入。在机器模式下处理陷阱有一组等效的控制寄存器，XV6 仅在定时器中断的特殊情况下使用它们。\n多核芯片上的每个 CPU 都拥有独立的一组这些寄存器，并且在任何时间点上，多个 CPU 可能同时处理陷阱。\n当 RISC-V 硬件需要强制执行陷阱时，除了定时器中断以外，它对所有类型的陷阱执行以下操作：\n\n  如果陷阱是设备中断且状态寄存器中的 SIE 位被清除，就不响应。\n  清除 SIE 以禁用中断。\n  将 PC 的值复制到 sepc。\n  将当前运行模式（用户或管理模式）保存到 sstatus 的 SPP 位中。\n  设置 scause 以反映触发陷阱的原因。\n  将运行模式切换为管理模式。\n  将 stvec 的值复制到 PC。\n  开始在新的 PC 上执行。\n\n\n需要注意的是，CPU 硬件不会自动切换内核页表和内核栈，也不会保存除 PC 以外的寄存器，处理程序必须完成上述工作。这样设计可以给软件更好的灵活性。而设置 PC 的工作必须由硬件完成，因为当切换到内核态时，用户指令可能会破坏隔离性。\n从用户空间陷入如果用户程序发出系统调用（ecall 指令），或者做了一些非法的事情，或者设备中断，那么在用户空间中执行时就可能会产生陷阱。用户态陷阱处理流程如下：\necall -&gt; uservec -&gt; usertrap -&gt; syscall等中间处理 -&gt; usertrapret -&gt; userret\nuservec由于 CPU 不会进行页表切换，因此用户页表必须包含 uservec 函数（stvec 所指向的函数）的映射。该函数要将 satp 切换为内核页表，为了切换后的指令能继续执行，该函数必须在用户页表和内核页表中有相同的地址。为了满足上述要求，XV6 使用包含 uservec 的蹦床页面（trampoline page）来满足这些约束。它将一个叫 trampoline 的页映射到内核页表和每个用户页表中相同的虚拟地址 TRAMPOLINE ，其中包含了 trampoline.S 的指令，并设置 stvec 为 uservec。不过尽管 TRAMPOLINE 在用户页表中，但他们的 PTE_U 未设置，因此用户程序无法修改，保证了隔离性。\n当 uservec 启动时，CPU 的所有 32 个通用寄存器中的值仍保留着中断发生时用户代码的状态。但是，uservec 函数作为内核的陷阱处理程序，需要使用这些寄存器来执行指令。为了不丢失这些寄存器中保存的用户程序的状态， uservec 必须直接用汇编语言操作寄存器，而不能使用高级语言。内核需要先保存其中一些寄存器的内容。RISC-V 提供了 sscratch 寄存器来存储这些临时数据。通过 csrrw a0, sscratch, a0 指令，保存 a0，之后就可以使用 a0 寄存器了。\n接下来，函数将所有用户寄存器保存到 trapframe 结构体中，该结构体的地址在进入用户模式之前，被保存在 sscratch 寄存器中，因此经过之前的 csrrw 操作后，就被保存在 a0 中。每当创建一个进程时，XV6 都会为该进程的陷阱帧分配一个页面，并安排它始终映射在用户虚拟地址 TRAPFRAME ，该地址就在 TRAMPOLINE 下面，进程的 p-&gt;trapframe 也指向该页面。\n最后，函数从 trapframe 中取出之前存储在蹦床页面上的、陷阱处理期间需要使用的内核栈指针（kernel_sp）、kernel_hartid、usertrap 的地址以及内核页表地址，切换页表后跳转到 usertrap。\nusertrapusertrap 函数的主要任务是判断陷阱类型并进行处理，然后返回。首先，函数将 stvec 设置为 kernelvec 的地址，以确保在内核态发生中断时 kernelvec 函数处理。接着，函数将 sepc 寄存器的内容保存到 trapframe 中，以防在处理过程中被覆盖。根据不同的陷阱类型，函数采取相应的操作：如果是系统调用，则将 trapframe 中储存的 PC 更新为 ecall 指令后的下一条（即当前 PC+4），然后由 syscall 函数处理系统调用；如果是设备中断，则交由 devintr 处理；如果是异常，则会终止该进程。最后，usertrap 会检查进程状态，决定是否终止进程或在定时器中断时将控制权交还给 CPU。\nusertrapret返回用户空间的第一步是调用 usertrapret。该函数首先将 stvec 设置为 uservec 的地址，然后设置 trapframe 中的一些关键字段（如 kernel_satp、kernel_sp、kernel_trap 和 kernel_hartid），这些将在下一次 uservec 的调用中被使用。接着，将 trapframe 中保存的用户态程序计数器值赋给 sepc 寄存器。最后，调用 userret 函数，完成从内核态返回用户态的准备工作。\nuserret反向操作 uservec 即可，最后用 sret 返回。\n从内核空间陷入内核态陷阱的处理路径为：kernelvec -&gt; kerneltrap -&gt; kernelvec\nkernelvec由于此时已经处于内核空间，因此即使发生陷阱，我们也不需要修改 satp 和栈指针。内核页表和内核堆栈可以继续使用，只需保存所有的通用寄存器即可。kernelvec 会将寄存器保存在被中断的内核线程的栈上，因为这些寄存器属于该线程。保存寄存器后，程序会跳转到 kerneltrap 进行后续处理。\nkerneltrapkerneltrap 只处理两种陷阱：设备中断和异常。它通过调用 devintr 判断是否为设备中断，如果不是设备中断，则视为异常，且该异常发生在内核态，内核会调用 panic 函数终止执行。如果是定时器中断，则调用 yield 函数让出 CPU。由于 yield 会修改 sepc 和 sstatus 寄存器，因此在 kerneltrap 中需要保存和恢复这两个寄存器的值。\n缺页异常的利用在 XV6 中，并没有对异常进行处理，仅仅是简单地终止故障程序或内核崩溃。而在真实操作系统中，我们会对异常进行具体的处理，来达到许多目的。\n在 RISC-V 中，有三种不同的缺页异常，说明了执行何种操作时虚拟地址转换失败：加载页异常（load page fault，当 load 指令转换虚拟地址时发生）、存储页异常（store page fault，当 store 指令转换虚拟地址时发生）和指令页异常（instruction page fault，当指令地址转换时发生）。在 scause 寄存器中保存异常原因，stval 寄存器中保存转换失败的地址。\n一种技术是延迟分配（lazy allocation）（Lab5）。当应用调用 sbrk 增加地址空间时，新的地址在页表中被标记为无效。只有当访问新地址时发生缺页异常，操作系统才会为进程分配物理页面。\nCOW（Copy-On-Write）fork 技术（Lab6）使子进程和父进程共享相同的物理页面，但将页面标记为只读。当子进程或父进程执行 store 指令时，会触发异常，此时操作系统会将页面进行拷贝，并以读写模式同时映射到父子进程的地址空间。我们通过 PTE 中为操作系统内核保留的位（RSW, Reserved for Supervisor）来区分是 COW 导致的只读还是单纯的只读。\n此外，按需调页（Demand Paging）技术也利用了缺页异常。操作系统将部分内存数据保存在磁盘上，并在页表中将相应页面标记为无效。当应用程序试图访问已被换出的页面时，CPU 会触发缺页异常。此时，内核会检查故障地址，若该地址对应于磁盘上的页面，内核会分配一个物理内存页，将数据从磁盘加载到内存中，并更新 PTE，使其标记为有效并指向该内存页。随后，内核恢复应用程序的执行。为了腾出空间，内核可能还需要将另一个页面换出到磁盘，通常根据 PTE_A 位来判断页面的访问情况，并结合最近最少使用（LRU）策略选择要换出的页面。这个过程对应用程序是透明的，无需对其进行任何修改。如果应用程序在任何时刻只使用部分内存（即仅访问部分地址），按需调页可以显著提高效率。\n自动扩展堆栈（automatically extending stacks）和内存映射文件（memory-mapped files）等技术也利用缺页异常。\n从C到汇编RISC-V 是一种能够执行 RISC-V 指令集的 CPU 架构。每个处理器都关联着一个特定的指令集架构（ISA, Instruction Set Architecture），该架构定义了处理器可以执行的指令和支持的功能。每条指令都对应一个二进制编码或操作码。\nRISC（精简指令集）与 CISC（复杂指令集）是处理器架构的两大设计范式，前者以 RISC-V 为代表，强调简单、固定的指令格式与高效流水线设计，而后者如 x86 架构则通过复杂指令直接支持高级操作。\n汇编语言作为底层编程接口，仅提供基础指令（如 add、mult）和标签跳转机制，通过标签模拟函数调用逻辑，缺乏C语言中的结构化控制流（如 if-else、for 循环），其本质是对硬件指令集的直接映射。\n高级语言（如C语言）的编译流程需经历多阶段转换：源代码首先被编译为汇编语言（生成 .s 或 .S 文件），汇编器进一步将其转化为机器码目标文件（.o），最终链接器整合多个目标文件及库函数生成可执行的二进制文件。\n通用寄存器以下是 XV6 的所有通用寄存器：\n\n  \n  图一：XV6 的通用寄存器\n\n\n寄存器是 CPU 内部预定义的超高速存储单元，直接参与执行运算（如加减乘除和逻辑操作）。寄存器的重要性在于，汇编代码的操作不是直接在内存中执行，而是在寄存器上进行。寄存器中的数据可以来自内存，也可以来自其他寄存器。运算完成后，结果可以存储在内存或另一个寄存器中。由于寄存器非常快速，我们往往倾向于用寄存器去运算，只有数据量超过寄存器容量或者需要长期存储数据的时候才会使用内存。\n寄存器有两种储存规则：Caller Saved 和 Callee Saved。\n\n  Caller Saved（调用者保存）：调用函数前，由调用者（Caller）负责保存这些寄存器的值，因为被调用函数（Callee）可能覆盖它们。\n\n  Callee Saved（被调用者保存）：被调用函数若需修改这些寄存器，必须先保存原值，返回前恢复，确保调用者看到的值不变。\n\n\n一般而言，Caller Saved 寄存器（如 ra, t0-t6）用于临时数据，允许快速使用而无需保存；Callee Saved 寄存器（如 s0-s11, sp）用于长期变量，减少频繁保存开销。\n函数栈帧栈的基本结构图如下：\n\n  \n  图二：栈的基本结构图\n\n\n（25.9.19更新）更详细的栈帧内存分布如下：\n\n\n\n\n区域\n说明\n\n\n\n\n调用者的栈帧\n邻接在高地址方向，上一个函数的栈帧\n\n\n实参区\n超过 $a_0–a_3$ 的参数由调用者压栈\n\n\n返回地址 (RA)\n保存调用点的返回地址\n\n\n前一帧指针 (FP)\n保存旧的 $fp，便于返回时恢复\n\n\n保存的寄存器\n存放 Callee-saved 寄存器（如 $s_0–s_7$）\n\n\n局部变量区\n编译器分配的局部变量、数组、临时变量\n\n\n临时栈空间\n表达式求值时 push/pop 的区域\n\n\n向下生长的栈空间\n栈继续扩展的区域，SP 指向这里\n\n\n\n\n每个函数调用都会创建一个栈帧（stack frame），每个区域对应一个栈帧。栈帧的分配通过移动堆栈指针（stack pointer, 即 SP）完成。\n两个重要的通用寄存器：\n\nSP (Stack Pointer)：指向当前栈帧的栈底，表示栈的当前位置。\nFP (Frame Pointer)：指向当前栈帧的顶部，用于寻址返回地址和前一个栈帧的指针（这两者在栈帧中的位置是固定的）。 \n\n前一个栈帧的指针用于返回调用方，当需要跳转回去时，将其存储在 FP 中以恢复先前的栈帧。\n实验任务Backtrace(moderate)这个实验很简单，关键在于理解栈帧。只要注意到返回地址在-8偏移位置，前一个栈指针保存在-16偏移位置，用 fp 指针往前跳就行。注意 PGROUNDUP 可以用来判断栈页面的顶部位置。voidbacktrace(void)&#123;  uint64 fp = r_fp();  uint64 over = PGROUNDUP(fp);  while (fp &lt; over)  &#123;    printf(&quot;%p\\n&quot;, *((uint64 *)(fp - 8)));    fp = *((uint64 *)(fp - 16));  &#125;&#125;\nAlarm(Hard)理解了第四章的内容和讲座的内容之后整个实验并没有什么难点，整个实验只用到了 XV6 精妙的陷阱系统的很小一部分。我们的目的是实现一个定期报警程序，为此我们需要实现两个系统调用：设定报警程序、返回原函数。\n我们需要修改 proc 结构体，添加报警间隔、当前间隔时间、报警程序是否正在运行、报警程序地址以及为返回原地址保存的页表。添加系统调用及函数过程不再赘述。struct proc &#123;  struct spinlock lock;  // p-&gt;lock must be held when using these:  enum procstate state;        // Process state  struct proc *parent;         // Parent process  void *chan;                  // If non-zero, sleeping on chan  int killed;                  // If non-zero, have been killed  int xstate;                  // Exit status to be returned to parent&#x27;s wait  int pid;                     // Process ID  int duaration;               // Alarm duartion  int alarm_num;               // Times of alarm  int is_alarming;             // If non-zero, the process is alarming  uint64 handler;              // Function need to handle  struct trapframe * alarm_trapframe; // Alarm trapframe  // these are private to the process, so p-&gt;lock need not be held.  uint64 kstack;               // Virtual address of kernel stack  uint64 sz;                   // Size of process memory (bytes)  pagetable_t pagetable;       // User page table  struct trapframe *trapframe; // data page for trampoline.S  struct context context;      // swtch() here to run process  struct file *ofile[NOFILE];  // Open files  struct inode *cwd;           // Current directory  char name[16];               // Process name (debugging)&#125;;\n然后我们实现设定报警程序的系统调用：uint64sys_sigalarm(void)&#123;  int ticks;  uint64 handler;  if((argint(0, &amp;ticks)) &lt; 0)    return -1;  if((argaddr(1, &amp;handler)) &lt; 0)    return -1;  struct proc * p = myproc();  p-&gt;duaration = ticks;  p-&gt;handler = handler;  p-&gt;alarm_num = 0;  p-&gt;is_alarming = 0;  return 0;&#125;\n然后修改 usertrap 函数，在定时器中断的时候增加间隔时间计数器。时间到了就清空计数器并触发报警程序。需要注意的是，我们要将保存了原本的返回地址的 trapframe 保存到 alarm_trapframe 里面，因为我们中途可能还有别的系统调用。...  // give up the CPU if this is a timer interrupt.  if(which_dev == 2)&#123;    if(p-&gt;duaration)    &#123;      p-&gt;alarm_num++;      if(p-&gt;alarm_num == p-&gt;duaration &amp;&amp; p-&gt;is_alarming == 0)      &#123;        p-&gt;alarm_num = 0;        *p-&gt;alarm_trapframe = *p-&gt;trapframe;        p-&gt;is_alarming = 1;        p-&gt;trapframe-&gt;epc = p-&gt;handler;      &#125;      yield();    &#125;    yield();  &#125;...\n最后实现 sys_sigreturn 系统调用。因为我们在报警之后还需要回到原来的函数，所以把陷阱帧复制回来即可。不要忘了还要在 procalloc 和 freeproc 里面进行初始化和释放。uint64sys_sigreturn(void)&#123;  struct proc *p = myproc();  *p-&gt;trapframe = *p-&gt;alarm_trapframe;  p-&gt;is_alarming = 0;  return 0;&#125;\n小结至此Lab4宣告结束，总体并不算难，跟着hint一步步做如果之前的课程比较扎实做起来还是挺舒服的。最大的感悟是Lab提供的知识真的只是这一块的很小一部分，绝大部分知识都来自于文档和讲座，甚至Lab答疑课都能让人注意到许多遗漏的小地方。然而，这些实验又不可或缺，它能帮助我们梳理之前的知识。总之，重点还是应该放在文档跟讲座的理解上，Lab终究不是重点。最后附上通关截图：\n\n  \n  图三：通关截图\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","陷阱指令"]},{"title":"MIT-6-S081-Lab5：XV6 lazy page allocation","url":"/2025/03/25/MIT-6-S081-Lab5%EF%BC%9AXV6-lazy-page-allocation/","content":"实验任务Eliminate allocation from sbrk() (easy)呃，真就一行……把...if(growproc(n) &lt; 0)    return -1;...改成...myproc()-&gt;sz += n;...就行了\nLazy allocation (moderate)第二部分要我们实现最简单的懒分配，我们在每次出现缺页异常（scause=13是读异常，scause=15是写异常）的时候，进行分配需要的虚拟地址所在的页面即可。这里不需要修改 p-&gt;trapframe-&gt;epc 是因为我们需要重试原指令。...else if(r_scause() == 13 || r_scause() == 15)&#123;    uint64 va = r_stval();    if(lazy_alloc(va) &lt; 0)      p-&gt;killed = 1;  &#125;...lazy_alloc 函数如下，因为每次只分配一页所以不需要 uvmdealloc 来解决分配很多页时内存不够的情况。intlazy_alloc(uint64 addr)&#123;  char * mem;  struct proc * p = myproc();  //printf(&quot;heh1&quot;);  if(addr &gt;= p-&gt;sz)  &#123;    return -1;  &#125;  if(addr &lt; p-&gt;trapframe-&gt;sp)  &#123;    return -2;  &#125;  addr = PGROUNDDOWN(addr);  mem = kalloc();  if(mem == 0)  &#123;    return -3;  &#125;  memset(mem, 0, PGSIZE);  if(mappages(p-&gt;pagetable, addr, PGSIZE, (uint64)mem, PTE_W|PTE_X|PTE_R|PTE_U) != 0)  &#123;    kfree(mem);    return -4;  &#125;  return 0;&#125;最后我们需要修改 uvmunmap 的逻辑，因为我们进行了懒分配，所以会出现未分配页需要释放的可能，这时候我们跳过即可。uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free)&#123;  uint64 a;  pte_t *pte;  if((va % PGSIZE) != 0)    panic(&quot;uvmunmap: not aligned&quot;);  for(a = va; a &lt; va + npages*PGSIZE; a += PGSIZE)&#123;    if((pte = walk(pagetable, a, 0)) == 0)      panic(&quot;uvmunmap: walk&quot;);    if((*pte &amp; PTE_V) == 0)      continue; // 需要释放的情况    if(PTE_FLAGS(*pte) == PTE_V)      panic(&quot;uvmunmap: not a leaf&quot;);    if(do_free)&#123;      uint64 pa = PTE2PA(*pte);      kfree((void*)pa);    &#125;    *pte = 0;  &#125;&#125;\nLazytests and Usertests (moderate)第三部分就是一些没处理的细节。我们首先处理 sbrk 为负数的情形，因为之前已经修改了 uvmdealloc，所以直接释放就行。uint64sys_sbrk(void)&#123;  struct proc * p = myproc();  int addr;  int n;  if(argint(0, &amp;n) &lt; 0)    return -1;  addr = p-&gt;sz;  if(n &gt; 0)    p-&gt;sz += n;  else    p-&gt;sz = uvmdealloc(p-&gt;pagetable, addr, addr + n);  return addr;&#125;\nsbrk 越界的情形已在第二部分解决，接下来修改复制进程需要用到的 fork。我们需要修改其调用的 uvmcopy，在找不到pte的时候不再报错。...for(i = 0; i &lt; sz; i += PGSIZE)&#123;    if((pte = walk(old, i, 0)) == 0)        continue;    if((*pte &amp; PTE_V) == 0)        continue;    pa = PTE2PA(*pte);    flags = PTE_FLAGS(*pte);    if((mem = kalloc()) == 0)        goto err;    memmove(mem, (char*)pa, PGSIZE);    if(mappages(new, i, PGSIZE, (uint64)mem, flags) != 0)&#123;        kfree(mem);        goto err;    &#125;&#125;return 0;..\n然后修改 read 和 write 的系统调用。通过对流程的分析可知，在操作系统中，当用户态程序执行 read/write 系统调用陷入内核时，RISC-V 架构的 scause 寄存器会记录环境调用异常代码8。我们要防止在内核中需要地址时页面未分配的情况。事实上，他们均通过 walkaddr 函数解析用户虚拟地址对应的物理地址，此过程需要主动遍历用户页表，其执行路径与硬件自动触发的缺页异常处理机制存在本质差异。所以我们需要修改 walkaddr 的逻辑，在找不到pte时分配页面。uint64walkaddr(pagetable_t pagetable, uint64 va)&#123;  pte_t *pte;  uint64 pa;  if(va &gt;= MAXVA)    return 0;  pte = walk(pagetable, va, 0);  if(pte == 0 || (*pte &amp; PTE_V) == 0)  &#123;    if(lazy_alloc(va) == 0)      pte = walk(pagetable, va, 0);    else        return 0;  &#125;  if((*pte &amp; PTE_U) == 0)    return 0;  pa = PTE2PA(*pte);  return pa;&#125;\n小结至此Lab5宣告结束，总体来说比较轻松（而且没有文档要看真的很爽啊哈哈哈哈！）。通过对懒分配的实现，我们对陷阱的机制有了更深的了解，还了解到 walkaddr 通过主动遍历用户页表来定位pte，跟用户态的 load/store 指令是独立的逻辑，因此不会触发缺页异常。这种差异性带来的隔离性实在是令人叹为观止。唔，test项目太多了懒得放通过截图了。\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","缺页异常","延迟页面分配"]},{"title":"MIT-6.S081-Lab1: XV6 and Unix utilities","url":"/2025/02/27/MIT-6-S081-Lab1%EF%BC%9AXV6-and-Unix-utilities/","content":"知识点这个Lab跟后面的Lab都不一样，其核心任务在于开发调用系统系统调用的应用程序，而非聚焦课程的核心目标——实现操作系统内核功能与扩展开发（如最终实验的网络协议栈实现）。\n但是我们应当注意，尽管我们正在编写C语言程序，然后用 shell 去运行它，但这并不意味着 shell 更加底层。事实上，反而C更加底层，shell 也常常是采用c编写的，内核也用C来编写。尽管编写 shell 是编写操作系统的一部分，但 shell 并不属于内核，而是一个用户态程序，通过调用系统调用来启动其他程序。\nXV6 基于 RISC-V 指令集架构设计，在 6.S081 课程中通过 QEMU 模拟硬件,以实现完整的指令集级仿真运行环境。\n常见系统调用这些是常见的系统调用，当我们在 shell 里面运行程序的时候，比如 ls，它会依次调用 fork,exec,wait,exit，而 cd 则是直接调用 chdir。\n\n进程和内存\nfork()\n参数：无  \n返回值：  \n父进程返回子进程 PID（正整数）  \n子进程返回 0  \n\n\n作用：复制当前进程内存空间创建新进程  \n注意事项：  \n单次调用双重返回（父/子进程各执行一次后续代码）  \n父子进程执行流异步，控制台输出可能交错，这也是共享文件偏移量带来的结果  \n\n\n特点：  \n新进程与原进程拥有相同的内存副本  \n通过返回值区分父子进程执行环境  \n\n\n改进  后续我们将在Lab6实现写时复制分支（COW）之类的技巧，在我们 fork后面紧跟着 exec 之类的操作的时候不进行复制。\nexit(int status)\n参数：进程终止状态码（整型）  \n返回值：无（进程直接终止）  \n作用：立即终止调用进程并释放资源  \n注意事项：  \n自动回收内存、关闭文件描述符等内核资源  \n终止状态可通过 wait 系统调用被父进程获取  \n\n\n特点：  \n\n状态码遵循 UNIX 规范（0 表示成功）\n\nwait(int *status)\n参数：存储子进程退出状态的地址指针（可为 NULL）  \n返回值：被回收子进程的 PID（失败返回 -1）  \n作用：等待任意子进程终止  \n注意事项：  \n\n若无已终止子进程，将阻塞直到子进程退出  \n当多个子进程存在时，按终止顺序处理  \n\nexec(const char *filename, char *const argv[])\n参数：  \n可执行文件路径（字符串）  \n参数指针数组（以空指针结尾）  \n\n\n返回值：成功时不返回，失败返回 -1  \n作用：允许一个进程在执行过程中被另一个程序完全替换，并从头开始执行新程序。原有进程的代码、数据、堆栈等（内存）被完全替换而进程的标识符和文件描述符表保持不变。\n注意事项：  \n文件必须符合 ELF 格式规范（详见第2章说明）  \n成功执行后从 ELF 入口地址开始运行  \n\n\n特点：  \n\n保留原进程 PID 和文件描述符表\n参数数组需包含程序名作为首个元素（argv[0]），并且最后需要以 NULL 终止符结尾，NULL 终止符不会被c语言自动补充。\n\nkill(int pid)\n参数：目标进程 PID（正整数）  \n返回值：成功返回 0，失败返回 -1  \n作用：向指定进程发送终止信号（默认 SIGTERM）  \n注意事项：  \n\n需具备目标进程的操作权限  \n实际终止可能因信号处理程序延迟  \n\nsleep(int n)\n参数：休眠秒数（整型）  \n返回值：剩余未休眠秒数（通常为 0）  \n作用：使进程暂停执行指定时长  \n注意事项：  \n实际休眠时间可能因信号中断缩短  \n精度通常为秒级  \n\n\n特点：  \n\n不占用 CPU 资源  \n常用于定时任务调度\n\ngetpid()\n参数：无  \n返回值：当前进程 PID（正整数）  \n作用：获取调用进程的进程标识符  \n注意事项：  \nPID在进程生命周期内唯一且不变  \n\n\n\n\nI/O 和文件描述符\n  文件描述符是操作系统中的一个核心概念，它本质上是一个非负整数，用于标识进程可访问的内核管理对象。这些对象包括文件、目录、设备、管道等。进程通过文件描述符与这些资源交互，而无需关心其底层差异——无论是写入文件、控制台，还是通过管道传输数据，都可以抽象为对字节流的读写操作。\n  进程获取文件描述符的常见方式包括：打开文件或设备（如调用 open()）、创建管道（pipe()）、复制现有描述符（dup() 或 fork() 继承）。其中，0、1、2 号描述符是系统预定义的：0 对应标准输入（stdin，默认从键盘读取），1 对应标准输出（stdout，默认输出到屏幕），2 对应标准错误（stderr，默认输出错误信息到屏幕）。\n  每个指向文件的文件描述符都会关联一个文件偏移量，表示当前读写位置。例如，调用 read() 会从偏移量处读取数据，读取后偏移量自动增加相应的字节数；write() 同理，写入后偏移量向后移动。偏移量的共享规则是关键：若多个描述符是通过 fork() 或 dup() 系列调用从同一原始描述符派生而来（例如复制或继承），它们会共享同一偏移量；但如果是独立打开同一文件（如两次调用 open()），即使目标文件相同，各自的描述符也会维护独立的偏移量。\n  这种设计使得文件描述符成为强大的抽象工具。无论底层是文件、管道还是设备，进程只需通过描述符的读写接口操作字节流即可。例如，向描述符 1 写入数据时，可能是输出到屏幕、重定向到文件，或是通过管道传递给其他进程，但进程代码无需为此修改。这种抽象简化了编程，同时为资源复用（如 dup2() 重定向）和进程间通信（如管道）提供了统一的基础。\nopen(const char *filename, int flags)\n参数：  \n文件路径（字符串）  \n打开模式标志（如 O_RDONLY）  \n\n\n返回值：文件描述符 fd（失败返回 -1）  \n作用：建立文件访问通道  \n特点：  \n\n返回当前最小可用文件描述符  \n标志模式如下\n一、基础访问模式（必选其一，互斥使用）  | 标志          | 值    | 说明                          |  |———————-|———-|———————————————-|  | O_RDONLY    | 0x000 | 只读模式                      |  | O_WRONLY    | 0x001 | 只写模式                      |  | O_RDWR      | 0x002 | 读写模式                      |\n二、文件创建控制（可组合使用）  | 标志          | 说明                          | 典型应用场景               |  |———————-|———————————————-|—————————————|  | O_CREAT     | 文件不存在时创建新文件          | 需要配合权限参数使用       |  | O_TRUNC     | 打开时清空文件内容（需写权限）  | 覆盖写操作初始化           |  | O_EXCL      | 与 O_CREAT 联用确保独占创建     | 防止文件覆盖的原子操作     |\n三、文件操作行为（可组合使用）  | 标志          | 说明                          | 系统支持情况              |  |———————-|———————————————-|————————————-|  | O_APPEND    | 强制追加写入（原子操作）        | 通用支持                 |  | O_NONBLOCK  | 非阻塞模式打开文件              | 管道/设备文件专用         |  | O_SYNC      | 同步写入保证数据落盘            | 高可靠性存储场景         |\n\n\nread(int fd, void *buf, size_t n)\n参数：  \n文件描述符  \n数据缓冲区地址  \n读取字节数  \n\n\n返回值：实际读取字节数（0 表示 EOF，-1 表示错误）  \n作用：从打开文件读取数据  \n注意事项：  \n缓冲区需预先分配足够空间  \n\n\n特点：  \n\n自动更新文件偏移量  \n支持管道/设备等特殊文件读取  \n\nwrite(int fd, const void *buf, size_t n)\n参数：  \n文件描述符  \n数据缓冲区地址  \n写入字节数  \n\n\n返回值：实际写入字节数（-1 表示错误）  \n作用：向打开文件写入数据  \nclose(int fd)\n参数：文件描述符  \n返回值：成功返回 0，失败返回 -1  \n作用：释放文件访问资源  \n注意事项：  \n重复关闭已关闭的 fd 会导致错误  \n进程终止时自动关闭所有 fd  \n\n\n特点：  \n\n释放的文件描述符可被后续 open 重用  \n关闭管道影响相关进程读写  \n\ndup(int fd)\n参数：源文件描述符  \n返回值：一个指向同一个输入/输出对象的新描述符（失败返回 -1）  \n作用：复制现有文件描述符  \n注意事项：  \n新 fd 共享原 fd 的文件偏移量  \n保证返回当前最小可用 fd  \n\n\n特点：  \n用于实现输出重定向  \n配合 close 实现 fd 定向替换\n\n\n\n\n管道  管道是一个小的内核缓冲区，它以文件描述符对的形式提供给进程，一个用于写操作，一个用于读操作。从管道的一端写的数据可以从管道的另一端读取。管道提供了一种进程间交互的方式。\n  尽管管道似乎可以用临时文件+重定向代替，但实际上管道和临时文件之间至少有三个关键的不同点。  首先，管道会自动清理，而对于 shell 重定向，我们必须在任务完成后手动删除临时文件（如/tmp/xyz）。  第二，管道可以传输任意长度的数据。  第三，管道支持同步操作：两个进程可以通过一对管道进行信息传递，每次读操作都会阻塞调用进程，直到另一个进程通过写操作完成数据发送。\npipe(int p[2])\n参数：包含两个整数的数组  \n返回值：成功返回 0，失败返回 -1  \n作用：创建进程间(p[0]到p[1]的)通信管道  \n注意事项：  \np[0] 为读端，p[1] 为写端  \n数据采用先进先出机制  \n\n\n特点：  \n默认阻塞式 I/O 操作  \n写入端关闭后读取返回 EOF \n\n\n\n\n文件系统  XV6 文件系统以树状结构组织数据，文件作为字节数组存储，而目录则是一种特殊文件，通过包含指向其他文件或目录的引用构建层级关系。  根目录/是树的起点，绝对路径（如/a/b/c）从根开始逐级解析，而相对路径基于进程的当前目录（可通过chdir修改）。\n  例如，无论通过分步切换目录（chdir(“/a”); chdir(“b”)）、直接跳转（chdir(“/a/b”)）、绝对路径访问（open(“/a/b/c”, …)）还是相对路径组合操作（从根目录逐步进入子目录），  所有路径最终会被解析为相同的目标文件/a/b/c。这种设计通过维护进程的当前目录状态和统一的递归路径解析机制，既允许了有丰富的操作方式，又保证了不同操作方式在文件系统底层的一致性。\n  文件名和这个文件本身也有很大的区别。同一个文件（称为 inode）可能有多个名字，称为连接 (links)。而每一个 inode 都由一个唯一的 inode 号 直接确定。系统可以通过调用 link 创建另一个文件系统的名称，它指向同一个 inode。\nchdir(const char *dirname)\n参数：目标目录路径  \n返回值：成功返回 0，失败返回 -1  \n作用：修改进程工作目录  \n注意事项：  \n\n需具备目录访问权限  \n\nmkdir(const char *dirname)\n参数：目录创建路径  \n返回值：成功返回 0，失败返回 -1  \n作用：创建新目录  \n注意事项：  \n\n需父目录写权限  \n\nmknod(const char *name, int major, int minor)\n参数：  \n设备文件路径  \n主设备号  \n辅设备号  \n\n\n返回值：成功返回 0，失败返回 -1  \n作用：创建设备特殊文件  \n注意事项：  \n通常需要超级用户权限  \n当一个进程之后打开这个文件的时候，内核将读、写的系统调用转发到内核设备的实现上，而不是传递给文件系统。\n\n\n特点：  \n\n实现设备文件抽象  \n支持字符/块设备创建  \n\nfstat(struct file *f, struct stat *st);\n参数：\nf: 指向 struct file 的文件指针，通过文件描述符（如通过 open、dup 等系统调用获取）找到。\nst: 指向 struct stat 结构体的指针，用于存储文件元信息（必须由调用者预先分配内存）\n\n\n返回值：成功返回 0，失败返回 -1  \n作用：获取文件元信息  \n注意事项：  \n信息存储于 struct stat 结构体，而非返回值\nstruct stat如下：  struct stat&#123;    int dev;     // File system’s disk device    uint ino;    // Inode number    short type;  // Type of file    short nlink; // Number of links to file    uint size;   // Size of file in bytes &#125; \n\n\n特点：  \n\n支持所有文件类型（普通文件、目录等）的元信息查询。\n不依赖于文件名进行操作，直接通过文件描述符及其指针操作。\n\nlink(const char *f1, const char *f2)\n参数：  \n现有文件路径  \n新链接路径  \n\n\n返回值：成功返回 0，失败返回 -1  \n作用：创建文件链接  \n注意事项：  \n不适用于目录链接  \n\n\n特点：  \n\n增加文件链接计数  \n多路径共享相同 inode  \n\nunlink(const char *filename)\n参数：文件路径  \n返回值：成功返回 0，失败返回 -1  \n作用：删除一个文件名  \n注意事项：  \n一个文件的 inode 和磁盘空间只有当它的链接数和文件描述符同时变为 0 的时候才会被清空，也就是没有一个文件再指向它，也没有一个程序使用它。\n\n\n特点：  \n常用于临时文件清理  \n配合 open 实现原子文件替换\n\n\n\n\n\n实验任务boot XV6（Easy）获取实验室的XV6源代码并切换到util分支，按照文档执行就行。git clone git://g.csail.mit.edu/XV6-labs-2020cd XV6-labs-2020git checkout utilmake qemu按再按x键退出。\nsleep(Easy)呃啊，注意不要在XV6上面写代码），XV6是操作系统好吗）））。\n直接调用 sleep 即可，注意不能用 return 0。\n#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;intmain(int argc, char const *argv[])&#123;    if(argc &lt; 2)    &#123;        fprintf(2, &quot;Usage:sleep [time]\\n&quot;);        exit(1);    &#125;    int time = atoi(argv[1]);    sleep(time);    exit(0);&#125;\npingpong(Easy)本题为管道的示例题，需要注意的是，管道是一个小的内存缓冲区，它提供了一对文件描述符，一个用于写操作，另一个用于读操作。记得不需要的文件描述符要 close。\n#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;intmain(int argc, char const *argv[])&#123;    int p_c[2], c_p[2];    if(pipe(p_c) == -1)    &#123;        fprintf(2, &quot;pipe error&quot;);        exit(1);    &#125;    if(pipe(c_p) == -1)    &#123;        fprintf(2, &quot;pipe error&quot;);        exit(1);    &#125;    int pid = fork();    if(pid)    &#123;        write(p_c[1], &quot;p&quot;, 2);        char buf[10];        read(c_p[0], buf, 10);        printf(&quot;%d: received pong\\n&quot;, getpid());    &#125;    else if(!pid)    &#123;        char buf[10];        read(p_c[0], buf, 10);        printf(&quot;%d: received ping\\n&quot;, getpid());        write(c_p[1], &quot;p&quot;, 2);    &#125;    close(p_c[0]), close(p_c[1]);    close(c_p[0]), close(c_p[1]);    exit(0);&#125;\nprimes (moderate) / (hard)挺奇妙的idea的，我一开始被进程和函数绕的有点晕乎，实际上逻辑很清楚。每次切到子进程后要从头开始运行一遍prime函数，只要给一个读入接口就行。还有注意管道传数值要用地址传。\n还有父进程必须等待子进程退出以回收资源，不能让子进程变成孤儿进程。#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;void prime(int fd)&#123;    int p, num;    read(fd, &amp;p, 4);    printf(&quot;prime %d\\n&quot;, p);    int pip[2];    pipe(pip);    int pid = fork();    if(pid)    &#123;        close(pip[0]);            while (read(fd, &amp;num, 4))        &#123;            if(num % p != 0)            &#123;                write(pip[1], &amp;num, 4);               &#125;        &#125;        close(pip[1]);        wait(0);    &#125;    else    &#123;        close(pip[1]);        prime(pip[0]);        close(pip[0]);        return;    &#125;&#125;intmain(int argc, char *argv[])&#123;    int pip[2];    pipe(pip);    int pid = fork();    if(pid)    &#123;        close(pip[0]);        for(int i = 2; i &lt;= 35; i++)        &#123;            write(pip[1], &amp;i, 4);        &#125;        close(pip[1]);        wait(0);    &#125;    else    &#123;        close(pip[1]);        prime(pip[0]);        close(pip[0]);    &#125;    exit(0);&#125;\nfind (moderate)愈发感觉Lab设计的精巧了，这个题让你对 ls 进行不大不小的修改，确实能练到很多东西。包括修改 fmtname 函数使得不再补全空格，通过添加文件名改变路径等等。要注意目录文件里是包含本级和上级目录的，不要递归进去造成死循环。\n说起来我才发现基本上字符串函数还有管道都是从1往0灌数据……嘶，这么一写感觉好有道理。#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;#include &quot;kernel/fs.h&quot;char*fmtname(char *path) // delete all words before the last slash&#123;  static char buf[DIRSIZ+1];  char *p;  // Find first character after last slash.  for(p=path+strlen(path); p &gt;= path &amp;&amp; *p != &#x27;/&#x27;; p--)    ;  p++;  // Return name.  char *dst = buf;  while (*p != &#x27;\\0&#x27; &amp;&amp; dst &lt; buf + DIRSIZ)  &#123;    *dst ++ = *p++;  &#125;  *dst = &#x27;\\0&#x27;;  return buf;&#125;voidfind(char *path,char *goal)&#123;  char buf[512], *p;  int fd;  struct dirent de;  struct stat st;  if((fd = open(path, 0)) &lt; 0)&#123;    fprintf(2, &quot;find: cannot open %s\\n&quot;, path);    return;  &#125;  if(fstat(fd, &amp;st) &lt; 0)&#123;    fprintf(2, &quot;find: cannot stat %s\\n&quot;, path);    close(fd);    return;  &#125;  switch(st.type)&#123;  case T_FILE:    if(strcmp(fmtname(path), goal) == 0)    &#123;      printf(&quot;%s\\n&quot;, path);    &#125;    break;  case T_DIR:    if(strlen(path) + 1 + DIRSIZ + 1 &gt; sizeof buf)    &#123;      printf(&quot;find: path too long\\n&quot;);      break;    &#125;    strcpy(buf, path);    p = buf+strlen(buf);    *p++ = &#x27;/&#x27;;    while(read(fd, &amp;de, sizeof(de)) == sizeof(de))    &#123;      if(de.inum == 0)        continue;      if(strcmp(de.name, &quot;.&quot;) == 0 || strcmp(de.name, &quot;..&quot;)  == 0 )        continue;      int len = strlen(de.name);      memmove(p, de.name, len);      p[len] = &#x27;\\0&#x27;;      find(buf, goal);    &#125;    break;  &#125;  close(fd);&#125;intmain(int argc, char *argv[])&#123;  if(argc != 3)  &#123;    printf(&quot;Usage: find [path] [filename]\\n&quot;);    exit(1);  &#125;  find(argv[1], argv[2]);  exit(0);&#125;\nxargs (moderate)关键反而在于输入的处理上，因为没有 readline 函数和 split 函数，都需要自己写一遍，其余部分倒是挺简单的。\n好吧，其实我 split 写挂了很久……这个b虚拟机是真的卡……主要是要注意指针数组跟二维数组不一样，指针数组没有初始化的时候里面的指针都是野指针，不能直接++，—操作！如果需要往里面写东西的话需要先用 malloc 分配内存！#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;intreadline(char buf[])&#123;    char *p = buf;    while (read(0, p, 1) != 0)    &#123;        if(*p == &#x27;\\n&#x27; || *p == &#x27;\\0&#x27;)        &#123;            *p = &#x27;\\0&#x27;;            return 0;        &#125;        p++;    &#125;    if(p != buf)        return 0;    return 1;&#125;voidrun(char *pro, char ** argv)&#123;    if(fork() == 0)    &#123;        exec(pro, argv);    &#125;    else    &#123;        wait(0);    &#125;&#125;#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;user/user.h&quot;intreadline(char buf[])&#123;    char *p = buf;    while (read(0, p, 1) != 0)    &#123;        if(*p == &#x27;\\n&#x27; || *p == &#x27;\\0&#x27;)        &#123;            *p = &#x27;\\0&#x27;;            return 0;        &#125;        p++;    &#125;    if(p &gt; buf)        return 0;    return 1;&#125;voidrun(char ** argv)&#123;    if(fork() == 0)    &#123;        exec(argv[0], argv);        exit(1);    &#125;    else    &#123;        wait(0);    &#125;&#125;intmain(int argc, char *argv[])&#123;    if(argc &lt; 2)    &#123;        fprintf(2, &quot;Uasge: xargs [command]\\n&quot;);        exit(1);    &#125;    char *nargv[16];    for(int i = 1; i &lt; argc; i++)    &#123;        nargv[i - 1] = argv[i];    &#125;// original parameter    int base_arges = argc - 1;    char buf[100];    while (readline(buf) == 0)    &#123;        int arg_count = base_arges;        char * src = buf;        while (src &amp;&amp; arg_count &lt; 15)        &#123;            while(*src == &#x27; &#x27;)                src++;            if(!*src)                break;            nargv[arg_count++] = src;            while(*src &amp;&amp; *src != &#x27; &#x27;)                src++;                    if(*src)                *src++ = &#x27;\\0&#x27;;        &#125;        nargv[arg_count] = 0;        run(nargv);    &#125;    exit(0);&#125;\n小结第一个Lab，总体上来说是相当磕磕绊绊了，对环境的不熟悉让我犯了许多现在看来很愚蠢的小错误。有一说一，操作系统里面真的有很多规范，像是 argv 要以 NULL 结尾，还有文件描述符的回收，都是很细节又很重要的地方。最后一个题还把二维数组跟指针数组混用写出了野指针，属实是不应该。总而言之，希望后面能自己独立写完Lab，这次的Lab参考着许多前辈的代码才勉强写完，而且时间也花了好久……可能是太久没写了吧。\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","系统调用"]},{"title":"MIT-6-S081-Lab6：Copy-on-Write Fork for XV6","url":"/2025/03/31/MIT-6-S081-Lab6%EF%BC%9ACopy-on-Write-Fork-for-XV6/","content":"知识点这里补充一些之前用到但没有深究的内容——中断和设备驱动。\n设备驱动程序驱动是操作系统中用于管理特定设备的代码：驱动控制设备硬件，通知硬件执行操作，处理由此产生的中断，与等待该设备IO的进程进行交互。编写驱动是很棘手的事情，因为驱动程序与它管理的设备同时运行。此外，驱动程序必须理解设备的硬件接口才能准确地将内核需要的操作翻译成硬件专属的控制序列，这可能很复杂，而且缺乏文档。\n当设备需要与操作系统交互时，会触发硬件中断（属于异步陷阱）。在 RISC-V 架构中：\n\n中断触发：设备通过中断线向 PLIC（Platform-Level Interrupt Controller）发出中断请求。\n中断分发：PLIC 对多个设备的中断进行优先级仲裁，将最高优先级的使能中断发送给某个 CPU（通过 meip 外部中断信号）。\nCPU 响应：CPU 检测到中断后，保存上下文并跳转到统一的陷阱处理入口（如 trap_handler），此时仍不知道中断来源。\n中断识别：在陷阱处理流程中，内核代码（如 XV6 的 devintr()）会查询 PLIC 的 claim 寄存器，获取中断号并确认是设备中断（而非定时器中断等）。\n驱动处理：根据中断号映射到具体设备（如 UART/磁盘），调用对应驱动的中断处理例程。\n中断完成：驱动处理完成后，必须向 PLIC 的 complete 寄存器写入相同中断号，PLIC 才会清除该中断的 pending 状态。\n\n大多数设备驱动在两个上下文中执行代码：上半部分运行在进程的内核线程中，下半部分则在中断处理时执行。上半部分由系统调用触发，如 read 和 write，用于请求硬件执行操作（例如请求硬盘读取数据块）。在这时，进程会进入等待状态，等待操作完成。一旦设备完成操作并触发中断，驱动程序的中断处理部分（下半部分）会识别已完成的操作，唤醒对应的等待进程，并通知硬件执行下一个操作。  \n控制台输入代码console.c 作为控制台（这玩意是模拟的终端设备，不是硬件）的驱动程序，在 XV6 中提供了一个简单的设备驱动抽象。控制台驱动程序通过连接到 RISC-V 的为通用异步接收/发送器（Universal Asynchronous Receiver/Transmitter, UART）串口硬件，接收用户输入的字符。它会累积一行输入，并处理如 Backspace 和 Ctrl-U 等特殊按键。用户进程（如 Shell）通过 read 系统调用从控制台获取完整的输入行。在 QEMU 中通过键盘输入时，按键信号会先经过 QEMU 模拟的16550芯片，再传递给 XV6 进行处理。在真正的计算机上，16550将管理连接到终端或其他计算机的RS232串行链路。运行 QEMU 时，它连接到键盘和显示器。\n在软件中看来，UART 硬件是一组映射到内存的控制寄存器，对其控制可以直接通过对特定内存地址执行 load 和 store 操作来完成。但要注意，我们的操作并不会改变硬件内部的固有逻辑，写入内存地址实质上是通过预设的接口与硬件交互，而硬件驱动则相当于翻译器。\nUART 的内存映射基地址为 0x10000000，即 UART0（在 memlayout.h 中定义）。每个控制寄存器的大小为 1 字节，其具体偏移量在 uart.c 中定义。\n在 XV6 的 main 函数中，consoleinit 用于初始化 UART 设备。它配置 UART 设备，使其在每接收到一个字节时触发接收中断，并在每次完成一个字节的输出传输时触发传输完成中断。\n在 XV6 中，Shell 通过 init.c 中打开的文件描述符来读取控制台。read 系统调用会触发调用 consoleread 函数，该函数会等待输入的到达（通过中断），并将数据保存在 cons.buf 中。当一整行输入接收完成后，consoleread 函数将数据拷贝到用户空间，并返回给用户进程。如果输入尚未完整到达，read 进程会在 sleep 调用中等待，直到收到完整的输入行。\n每当用户输入一个字符时，UART 设备都会触发一个中断，激活 XV6 的陷阱处理程序。陷阱处理程序将调用 devintr，通过读取 scause 来判断中断是否由外部设备触发。接着，程序通过 PLIC 判断中断的设备类型。如果是 UART 设备，便会调用 uartintr 函数进行处理。\nuartintr 从 UART 设备中读取所有输入字符，并将其交给 consoleintr 进行处理。该函数不会等待字符的输入，因为新的输入会触发新的中断。consoleintr 将输入字符保存在缓冲区中，直到接收到完整的一行输入，并在此过程中处理一些特殊字符（如 backspace 或 Ctrl-U）。当一整行输入到达后，consoleintr 会唤醒一个正在等待的 consoleread，以便将输入传递给用户进程。\n当 consoleread 被唤醒时，缓冲区中已经保存了完整的一行输入。此时，consoleread 会将这一行输入从缓冲区拷贝到用户空间，并将数据返回给用户进程。\n控制台输出代码在连接到控制台的文件描述符上执行 write 系统调用时，最终会调用 uartputc。设备驱动程序维护一个输出缓冲区（uart_tx_buf），因此写入的进程无需等待 UART 完成数据发送。相反，uartputc 会将每个字符添加到缓冲区，并调用 uartstart 来启动设备传输（如果尚未启动），然后立即返回。唯一会导致 uartputc 阻塞的情况是缓冲区已满。\n每当 UART 发送一个字节时，就会触发一次中断。uartintr 函数会调用 uartstart 来检查传输是否完成，如果未完成，则会开始传输下一个缓冲区中的字符。因此，当进程写入多个字符时，第一个字节会通过 uartputc 调用 uartstart 进行传输，而后续的字节则通过 uartintr 调用的 uartstart 继续传输。\n对于设备活动和进程活动，常见的解耦方式是通过缓冲和中断。控制台驱动程序能够处理输入，即使没有进程在等待读取，稍后到来的 read 操作依然可以读取到输入。类似地，进程可以进行输出而无需等待设备响应。这样的解耦方式允许进程并行执行设备 I/O，从而提高性能，特别是在设备速度较慢或需要立即响应（如输入一个字符）的情况下。这种思想被称为 I/O 并行。\n驱动中的并发在 consoleread 和 consoleintr 中，都会调用 acquire 函数。这些调用用于申请一个锁，目的是在并发访问时保护驱动程序的数据结构。在这些操作中，有三种并行风险需要考虑：\n\n多个进程在不同 CPU 上同时调用 consoleread：这可能导致多个进程并发访问共享资源，进而引发数据一致性问题。\n\n在 CPU 执行 consoleread 时，硬件触发了一个中断：硬件中断可能会在 consoleread 执行过程中打断当前进程，从而引发并行访问的冲突。\n\n在 consoleread 执行时，硬件在其他 CPU 上触发了一个中断：即使当前 CPU 正在执行 consoleread，其他 CPU 上的硬件中断也可能影响共享数据结构，导致并发访问的问题。\n\n\n通过自旋锁的使用，驱动程序能够保证在并行环境中数据的一致性和安全性，避免上述并发风险的发生。\n另一个需要关注的并发场景是：一个进程可能在等待设备输入，而此时中断信号却在另一个进程执行时异步产生。为了解决这一问题，中断处理程序必须是上下文无关的，即不能依赖于特定的进程上下文或执行代码。\n例如，中断处理程序不能安全地在当前进程的页表上调用 copyout 函数，因为这涉及到当前进程的内存空间，而中断可能会打断进程的执行并切换到另一个上下文。在中断处理程序中，应该仅执行与进程无关的工作，例如将输入字符拷贝到缓冲区中，并且应尽早唤醒顶层部分（例如 consoleread）来处理剩余的任务。这种设计可以确保中断处理程序快速而高效地完成工作，避免复杂的上下文切换和对进程状态的依赖，从而减少潜在的并发问题。\n定时器中断XV6 通过定时器中断来维护系统时钟并执行进程切换。在 usertrap 和 kerneltrap 函数中的 yield 会触发进程切换。定时器中断由RISC-V CPU内部的时钟硬件生成，XV6 通过对该时钟硬件进行编程，使其定期触发中断，确保每个 CPU 能够周期性地进行操作。\nRISC-V 要求定时器中断必须在机器模式下执行，而不是在管理模式下。机器模式是 RISC-V 的最低权限模式，在无分页环境下运行，且具有一系列专用的控制寄存器。因此，在机器模式下运行普通的 XV6 内核代码并不现实。为了应对这一限制，XV6 的定时器中断处理程序与陷阱机制完全分离。\n在 start.c 中的代码执行于机器模式下，且位于 main 函数之前，它设置了接收定时器中断。在 timerinit 函数中，定时器中断被初始化。具体过程包括：\n\n编程 CLINT 硬件：通过对本地核心中断控制器（CLINT, Core Local Interruptor）硬件进行编程，设置定时器在一定时间后产生中断信号。\n\n设置 Scratch 区域：类似于 trapframe，scratch 区域用于帮助定时器中断处理程序保存寄存器的值，以及 CLINT 寄存器的地址，确保在处理中断时能够恢复相关状态。\n\n设置 mtvec：将 mtvec 寄存器的值设置为 timervec 函数的地址，确保当定时器中断发生时，RISC-V CPU 会跳转到 timervec 进行中断处理。\n\n使能定时器中断：最后，定时器中断被允许触发，使其能够按照预定的时间间隔产生中断请求。\n\n\n这个过程确保了定时器中断能够正确地触发，并且为中断处理程序提供了必要的上下文信息。\n定时器中断可以在任何时刻触发，因此内核在执行关键操作时无法禁用定时器中断。因此，定时器中断处理程序必须设计得足够简洁，以确保不会干扰正在执行的内核代码。最基本的策略是，定时器中断处理程序在收到中断后立即生成一个软件中断并返回。这样做的目的是将定时器中断的处理工作推迟到后续的某个合适时机进行。\n生成的软件中断会通过通用的陷阱机制进行处理，从而确保能够在适当的时机执行实际的中断处理。这种设计的关键点在于，软件中断的处理可以与其他类型的中断（如设备中断）一样，进行关闭、排队或者延迟处理。\n在 XV6 中，软件中断的处理程序位于 devintr 函数中。devintr 负责处理中断后的具体任务，包括从中断队列中取出待处理的任务并执行。通过这种方式，内核确保定时器中断不会干扰到正在执行的关键操作，并且能够有效地进行进程调度、时钟维护等操作。\n机器模式的时钟中断向量为 timervec，该函数的作用是处理定时器中断。在中断发生时，timervec 会首先保存必要的寄存器状态到 start 函数准备的 scratch 区域中，这样可以确保在处理中断时不会丢失正在执行的上下文。\n接下来，timervec 会通知 CLINT 硬件，指示下一个定时器中断的时刻。这是通过设置 CLINT 寄存器来完成的，通常是将定时器的下次中断时间设置到一个未来的时刻，确保定时器中断会按计划触发。\n然后，timervec 要求RISC-V发出“软件中断”并立即返回。通过这种方式，定时器中断处理程序会将进一步的处理中断任务交给软件中断进行，这样就可以避免在定时器中断处理过程中执行过多的工作，保证及时返回。\n最后，timervec 会恢复之前保存的寄存器状态，并返回中断处理程序的控制流，确保内核继续正常执行。\n这种方法可以让定时器中断处理保持简单、快速，并将复杂的工作推迟到合适的时间（比如通过软件中断的机制进行处理）。\n另一种交互方式：轮询用中断来进行处理的方式固然很好，但如果是高速设备，需要频繁交互，那么进出中断就会浪费很多时间。因此，对于这样的设备，我们往往会采用轮询的方式。\n轮询的核心思路是：  \n\nCPU 进入循环，不断检查设备状态寄存器（Status Register）。\n设备未准备好：CPU 继续循环，浪费计算资源。\n设备准备好：CPU 读取/写入数据，完成处理后继续轮询。\n\n在实际应用中，我们通常会根据具体需求进行权衡。例如，对于某些高速设备，可以采用轮询 + 中断的混合策略——在设备高负载运行时使用轮询，而在低负载或关键事件发生时触发中断，以兼顾性能和响应速度。\n实验任务Implement copy-on write (hard)某种意义上来说，我感觉这个Lab给我的感觉像是期中测试，运用到的知识很杂很全面，所以我也基本上没看前人的代码，跟着提示自己实现了一遍。总体来说并不算难，基本上没出过什么bug，一路非常丝滑的就做完了。我真厉害hhhhhh。\n我们要实现写时复制分支，首先要修改 fork 函数，在复制的时候不进行物理内容的复制而只复制页表，同时清除 PTE_W 权限并添加 PTE_COW 权限（利用 PTE 的保留位 RSW），另外还要添加引用计数，如果对页表比较熟悉的话会比较简单。intuvmcopy(pagetable_t old, pagetable_t new, uint64 sz)&#123;  pte_t *pte;  uint64 pa, i;  uint flags;  for(i = 0; i &lt; sz; i += PGSIZE)&#123;    if((pte = walk(old, i, 0)) == 0)      panic(&quot;uvmcopy: pte should exist&quot;);    if((*pte &amp; PTE_V) == 0)      panic(&quot;uvmcopy: page not present&quot;);    pa = PTE2PA(*pte);    flags = PTE_FLAGS(*pte);    *pte = PA2PTE(pa) | (flags &amp; (~PTE_W)) | PTE_COW;    if(mappages(new, i, PGSIZE, pa, (flags &amp; (~PTE_W)) | PTE_COW) != 0)&#123;      goto err;    &#125;    add_pincount(pa, 1);  &#125;  return 0; err:  uvmunmap(new, 0, i / PGSIZE, 1);  return -1;&#125;\n然后修改 usertrap，在触发写异常时进行懒分配。...else if(r_scause() == 15)&#123;    uint64 va = r_stval();    if(cow_copy(va) == -1)        p-&gt;killed = 1;&#125;...\n其中 cow_copy 函数如下，有许多的异常判断。我写完后看了看别人的代码，这里的部分是最为百花齐放的。有些人通过引用计数是否为1来判断是直接修改还是建立新界面。这样的确可以节约一些时间，而且因为往往会进行 exec 导致引用计数变回1，所以优化幅度并不小。我采用的则是把两种情况合并，无论是否为1，都先分配新页面，再删除老页面。因为我们会修改 kfree 的逻辑，所以页面会保留，达到了我们的目的。还有，有人在这里并不会返回0或1来表示是否成功复制，而是返回复制的物理地址，这会让后面的其他部分（copyout 函数的修改）更加方便，我认为也是很不错的优化，果然大佬还是多啊。intcow_copy(uint64 va)&#123;  if(va &gt;= MAXVA)    return -1;  struct proc * p = myproc();  pte_t * old;  if((old = walk(p-&gt;pagetable, va, 0)) == 0)    return -1;  if((*old &amp; PTE_V) == 0 || (*old &amp; PTE_U) == 0 || (*old &amp; PTE_COW) == 0)    return -1;  uint flags = PTE_FLAGS(*old);  uint64 pa = PTE2PA(*old);  char * mem;  mem = kalloc();  if(mem == 0)    return -1;  memmove(mem, (char *)pa, PGSIZE);  *old = PA2PTE(mem) | flags | PTE_W;  kfree((void *)pa);  return 0;&#125;\n接下来实现引用计数，我们需要添加全局数组 int page_pin[PHYSTOP/PGSIZE]，用于储存每个页面的被引用次数。然后我们添加函数 add_pincount 和 get_pincount，前者用于增加引用计数，后者用于查询。voidadd_pincount(uint64 pa, int num)&#123;  acquire(&amp;kmem.lock);  page_pin[pa / PGSIZE] += num;  release(&amp;kmem.lock);&#125;int get_pincount(uint64 pa)&#123;  return page_pin[pa / PGSIZE];&#125;\n然后修改几个原有的函数，分配页面时增加计数，初始化页面时增加计数，删除时减小计数，计数为0时即刻释放。void *kalloc(void)&#123;  struct run *r;  acquire(&amp;kmem.lock);  r = kmem.freelist;  if(r)    kmem.freelist = r-&gt;next;  release(&amp;kmem.lock);  if(r)&#123;    memset((char*)r, 5, PGSIZE); // fill with junk    add_pincount((uint64)r, 1);  &#125;  return (void*)r;&#125;voidfreerange(void *pa_start, void *pa_end)&#123;  char *p;  p = (char*)PGROUNDUP((uint64)pa_start);  for(; p + PGSIZE &lt;= (char*)pa_end; p += PGSIZE)  &#123;    page_pin[(uint64)p / PGSIZE] = 1;    kfree(p);  &#125;&#125;voidkfree(void *pa)&#123;  struct run *r;  if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP)    panic(&quot;kfree&quot;);  acquire(&amp;kmem.lock);  int pin = --page_pin[((uint64)pa) / PGSIZE];  release(&amp;kmem.lock);  if(pin &gt; 0)    return;  // Fill with junk to catch dangling refs.  memset(pa, 1, PGSIZE);  r = (struct run*)pa;  acquire(&amp;kmem.lock);  r-&gt;next = kmem.freelist;  kmem.freelist = r;  release(&amp;kmem.lock);&#125;\n最后我们还要修改 copyout，因为我们在调用 write 的时候可能会出现权限还未恢复的情况（跟Lab5一样），这样就会报错。如果之前采用的是返回物理地址的方式这里会很轻松，我们的方法就还需要复制一遍。intcopyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)&#123;  uint64 n, va0, pa0;  while(len &gt; 0)&#123;    va0 = PGROUNDDOWN(dstva);    pa0 = walkaddr(pagetable, va0);    if(va0 &gt;= MAXVA)      return -1;    pte_t * old;    if((old = walk(pagetable, va0, 0)) == 0)      return -1;    if((*old &amp; PTE_V) == 0 || (*old &amp; PTE_U) == 0)      return -1;    if(PTE_COW)    &#123;      uint flags = PTE_FLAGS(*old);      pa0 = PTE2PA(*old);      char * mem;      mem = kalloc();      if(mem == 0)        return -1;      memmove(mem, (char *)pa0, PGSIZE);      *old = PA2PTE(mem) | flags | PTE_W;      kfree((void *)pa0);      pa0 = (uint64)mem;    &#125;    n = PGSIZE - (dstva - va0);    if(n &gt; len)      n = len;    memmove((void *)(pa0 + (dstva - va0)), src, n);    len -= n;    src += n;    dstva = va0 + PGSIZE;  &#125;  return 0;&#125;\n小结至此 Lab6 宣告结束，这个Lab运用到的知识比较全面，不过并不算难。感觉整个 6.s081 就是每次 Lab 都会涉及到一点点后面的内容，又不具体告诉你原理，可能是想让大家自己探索吧。不过也有可能是操作系统整个浑然一体，不可避免的需要用到其他部分的接口。总之，XV6 确实很精妙啊！\n\n  \n  通关截图\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","缺页异常","写时复制分支"]},{"title":"MIT-6-S081-Lab7：Multithreading","url":"/2025/04/10/MIT-6-S081-Lab7%EF%BC%9AMultithreading/","content":"知识点调度是操作系统中的关键机制，负责在多个进程或线程之间分时共享 CPU。它与线程密切相关，决定了哪个线程获得执行权。虽然调度逻辑常常在陷阱、时钟中断等机制触发下执行，但从功能上看，它与系统调用、页表等模块相对独立，通常隐藏在内核的幕后，协调整个系统的运行秩序。\n但为了完成实验，我们还需要Lab8的知识（事实上课程也是先讲的锁），锁的知识就放在Lab8的笔记里了。\n多路复用XV6 通过在两种情况下将每个 CPU 从一个进程切换到另一个进程，实现了 CPU 的多路复用（multiplexing）：\n\n阻塞等待时：当进程因等待设备或管道 I/O 完成、等待子进程退出，或在 sleep 系统调用中主动等待时，XV6 使用 sleep / wakeup 机制切换到其他可运行的进程。\n周期抢占时：为了防止计算密集型进程长时间占用 CPU，XV6 使用定时中断（timer interrupt）周期性地强制进程让出 CPU，实现抢占式调度。\n\n\n这种切换机制让每个进程看起来像是独占了一个 CPU，就像 XV6 利用内存分配器和硬件页表机制，使每个进程看起来拥有独立的内存空间一样。\n实现多路复用时，我们将面临一系列挑战：\n\n  上下文切换的实现：从一个进程切换到另一个进程，虽然在思想上很简单，但其实现细节却是 XV6 中最晦涩难懂的部分之一。\n  对用户透明的强制切换：XV6 采用标准技术，通过定时器中断驱动上下文切换，以实现对用户进程透明的抢占。\n  多核并发下的争用控制：在多核系统中，多个 CPU 可能同时在进行进程切换，因此必须使用加锁等同步机制来避免争用和数据竞争。\n  资源回收的限制：进程退出时需要释放内存和其他资源，但它不能自行完成所有清理操作，例如它不能在仍然在使用内核栈的时候释放它。\n  核心状态的隔离：每个 CPU 核心必须独立记录当前运行的进程，以确保系统调用正确作用于对应进程的内核状态。\n  睡眠与唤醒的同步：sleep 让进程主动放弃 CPU，wakeup 则让其他进程唤醒它。实现这对机制时必须格外小心，防止竞态条件导致唤醒信号丢失。\n\n\n虽然 XV6 力求用尽量简单的方式解决这些问题，但相关代码依然复杂且难以掌握。\n上下文切换\n上图展现了用户进程切换的流程：首先，旧进程通过系统调用或中断从用户态进入内核态；接着，内核将当前 CPU 从旧进程的内核线程切换到调度器线程；然后，调度器选择一个新进程并切换到其内核线程；最后，控制流从新进程的内核态返回到用户态。\n调度器不能运行在旧进程的内核栈上，因为其他内核可能会唤醒该进程并使其在另一个 CPU 上运行——这将导致多个内核同时使用同一个栈，后果是灾难性的。为了解决这个问题，XV6 为每个 CPU 分配了一个专用的调度器线程（包含独立的寄存器上下文和栈空间）。\n从一个线程切换到另一个线程时，操作系统需要保存旧线程的 CPU 寄存器状态，并恢复新线程之前保存的寄存器状态。这其中最关键的是 SP 和 RA，因为它们决定了线程的执行位置和调用栈。也就是说，线程切换时不仅切换了执行的代码位置，还切换了它使用的栈空间。\n函数 swtch 实现了内核线程之间的切换，通过保存和恢复一组寄存器（即“上下文”）来完成这个过程。swtch 本身对线程并没有具体了解；它只是简单地处理上下文的保存与恢复。\n当某个进程需要放弃 CPU 时，它的内核线程会调用 swtch，将当前的上下文保存下来，并跳转到调度器的上下文。每个上下文由一个 struct context表示，该结构体通常嵌套在一个进程的 struct proc 或一个 CPU 的 struct cpu 中。context 主要保存进程的内核态寄存器（如寄存器、栈指针等），而 trapframe 则保存用户态的寄存器（如程序计数器和堆栈指针）。它们都与进程绑定，确保在上下文切换时能够恢复该进程的状态。\nswtch 接收两个参数：struct context *old 和 struct context *new。它会将当前寄存器状态保存到 *old 指向的结构体中，再从 *new 中恢复寄存器状态，并跳转执行到新上下文中。\n在Lab4中我们看到，中断结束时的一种情况是 usertrap 调用了 yield，yield 进一步调用 sched，而 sched 又调用 swtch，将当前进程的上下文保存在 p-&gt;context 中，并切换到之前保存在 cpu-&gt;scheduler 中的调度器上下文。\n通过这种方式，当前进程的状态被妥善保存，而 CPU 进入调度器以选择新的进程运行，实现了多进程之间的协作式切换。\nswtch 只保存被调用者保存的寄存器（callee-saved registers），而调用者保存的寄存器（caller-saved registers）通常由调用它的 C 代码在必要时显式保存到栈上。swtch 知道 struct context 中每个寄存器字段的偏移量，因此可以直接读写对应位置的值。注意，这里是在内核中主动发起的上下文切换，它属于正常的函数调用，而不是中断或陷阱，因此硬件不会自动帮你保存 pc。swtch 程序会保存 ra 寄存器——也就是调用 swtch 时的返回地址——来间接实现对程序执行位置的恢复。接下来，swtch 会从新线程的上下文中恢复寄存器，这些值正是之前某次 swtch 所保存的内容。此时，ra 中保存的是新线程先前调用 swtch 时的返回地址，因此 swtch 返回时会跳回到新线程原先执行的那条指令上，并且在新线程的栈上继续执行。\n调度器与进程锁调度器（scheduler）以每个 CPU 上一个特殊线程的形式存在，每个线程都运行 scheduler 函数。该函数的主要任务是选择下一个要运行的进程。当一个进程希望放弃 CPU 时，它必须先获得自己的进程锁 p-&gt;lock，并释放它持有的任何其他锁，接着更新自己的状态（p-&gt;state），然后调用 sched。yield、sleep 和 exit 都遵循这一约定，后续我们将进一步探讨。sched 会再次检查这些条件，并确保在持有锁的情况下禁用中断，以避免竞争条件。\n最终，sched 调用 swtch，将当前进程的上下文保存到 p-&gt;context 中，并切换到 cpu-&gt;scheduler 中保存的调度程序上下文。swtch 会在调度程序的栈上返回，就像 scheduler 的 swtch 返回一样。然后，scheduler 会继续其 for 循环，找到下一个 RUNNABLE 状态的进程，并切换到该进程，循环执行直到所有任务完成。\n这样，调度程序通过不断的上下文切换，实现了进程的多路复用和高效的 CPU 调度。\nXV6 在调用 swtch 时会持有 p-&gt;lock：调用 swtch 的进程必须首先获取该锁，并将锁的控制权传递给切换后的代码。这种做法在锁的使用上是较为不寻常的；通常，获取锁的线程也负责释放锁，这样有助于推理和确保操作的正确性。然而，在上下文切换的过程中，有必要打破这一惯例，因为 p-&gt;lock 用于保护进程的状态（p-&gt;state）和上下文（p-&gt;context）字段上的不变量，而这些不变量在 swtch 执行时并不成立。如果在 swtch 执行期间没有保持 p-&gt;lock，可能会出现问题：当进程在调用 yield 后将状态设置为 RUNNABLE，但尚未通过 swtch 停止使用自己的内核栈时，另一个 CPU 可能会决定运行该进程。结果将是两个 CPU 在同一栈上运行，这将导致错误。\n内核线程总是在 sched 中放弃其 CPU，并始终切换到调度程序中的同一位置，而调度程序（几乎）总是切换回之前调用 sched 的某个内核线程。因此，如果打印出切换线程时的行号，你将观察到一个简单而固定的模式：切换在相同的位置来回发生。这种在两个线程之间进行固定位置切换的过程通常被称为协程（coroutines）。\n有一种特殊情况下调度程序对 swtch 的调用不会以 sched 结束。当一个新进程第一次被调度时，它会从 forkret 开始执行。forkret 的作用是释放 p-&gt;lock，随后调用 usertrapret。虽然新进程此时尚未经历一次真正的陷阱，但它仍然可以从 usertrapret 开始“返回”到用户态。这是因为在 fork 过程中，已经手动设置好了新进程的 trapframe 和进入 usertrapret 所需的上下文。\nscheduler 执行一个简单的循环：它不断查找可以运行的进程，运行该进程直到它主动让出 CPU，然后重复这一过程。具体来说，scheduler 会在进程表中遍历，查找状态为 RUNNABLE 的进程。一旦找到，它就会将当前 CPU 的 proc 指针设置为该进程，将进程状态设置为 RUNNING，然后调用 swtch 切换到该进程，开始执行。\n总而言之，可以将调度代码的结构看作是：它强制每个进程维持一组不变量，并在这些不变量不成立时保持对 p-&gt;lock 的持有。其中一个关键不变量是：当进程处于 RUNNING 状态时，计时器中断触发的 yield 必须能够安全地将其切换出去。这意味着，CPU 的寄存器中仍需保存进程的现场（也就是说，还没有通过 swtch 转移到 p-&gt;context 中），并且 c-&gt;proc 必须指向当前进程。另一个关键不变量是：当进程处于 RUNNABLE 状态时，空闲的调度器必须能够安全地运行它。这要求 p-&gt;context 中已经保存好了进程的寄存器状态（即寄存器现场不在真实寄存器中），没有任何 CPU 正在该进程的内核栈上运行，也没有任何 CPU 的 c-&gt;proc 指向这个进程。\n需要注意的是：在持有 p-&gt;lock 的期间，这些不变量通常不成立，因为进程状态正在发生改变，调度器正处于中间状态。因此，p-&gt;lock 的存在就是为了在这些中间状态下保护这些关键字段的正确性，防止并发干扰。\n维护上述不变量正是 XV6 经常在一个线程中获取 p-&gt;lock，却在另一个线程中释放它的原因。例如，yield 中获取锁，而在 scheduler 中释放。一旦 yield 开始将一个处于 RUNNING 状态的进程修改为 RUNNABLE，必须持续持有锁，直到相关不变量得以恢复。最早可以安全释放锁的时机，是 scheduler（运行在自己的内核栈上）将 c-&gt;proc 清空之后。同理，当 scheduler 开始将一个 RUNNABLE 的进程切换为 RUNNING 状态时，也必须一直持有 p-&gt;lock，直到该进程真正开始执行（即 swtch 之后，例如在 yield 中）。在此之前，绝不能释放锁。\n除了维持调度相关的不变量之外，p-&gt;lock 还用于保护其他关键操作。例如，它协调 exit 和 wait 之间的配合，防止唤醒信号的丢失（详见后续内容），并避免进程退出期间与其他进程对其状态的访问产生竞争——例如，exit 可能会读取 p-&gt;pid 并设置 p-&gt;killed。\n出于代码清晰性考虑，也出于性能优化的需求，我们有必要考虑是否有可能将 p-&gt;lock 所承担的多种职责拆分开来，使每种用途拥有更明确的边界和更细粒度的控制。\nmycpu 和 myprocXV6 为每个 CPU 维护一个 struct cpu，用于记录当前在该 CPU 上运行的进程（如果有），保存调度线程的寄存器状态，并管理中断禁用所需的自旋锁嵌套计数。函数 mycpu 返回一个指向当前 CPU 所对应 struct cpu 的指针。事实上，RISC-V 为每个 CPU 分配了一个唯一的硬件线程编号（hartid），XV6 将每个 CPU 的 hartid 存储在对应 CPU 的 tp 寄存器中。这使得 mycpu 可以通过 tp 寄存器对全局 cpus 数组进行索引，从而获取当前 CPU 的 struct cpu。\n确保每个 CPU 的 tp 寄存器始终保存其对应的 hartid 并不容易。在 CPU 启动的早期阶段（仍处于机器模式），XV6 通过 mstart 设置了 tp。由于 tp 是通用寄存器，用户进程可能会修改它，因此我们将其保存在蹦床页面上，并仅在进入内核时临时借用 tp。RISC-V 编译器保证永远不会使用 tp 寄存器，这为 XV6 的实现提供了便利。若 RISC-V 在管理模式下允许直接读取当前的 hartid，这一实现将更加简洁——但遗憾的是，只有在机器模式下才能读取。\ncpuid 和 mycpu 的返回值是脆弱的：如果定时器中断导致线程让步并切换到另一个 CPU，那么之前返回的值将不再准确。为避免此问题，XV6 要求调用者在获取返回的 struct cpu 后禁用中断，并且仅在使用完返回的 struct cpu 后才重新启用中断。因为这里是只读，所以禁用中断即可，不需要上锁。\n函数 myproc 返回当前 CPU 上运行进程的 struct proc 指针。myproc 禁用中断后，调用 mycpu，从 struct cpu 中获取当前进程的指针（c-&gt;proc），然后再启用中断。即使中断被启用，myproc 返回的值仍然是安全的：如果计时器中断导致进程切换到另一个 CPU，struct proc 指针不会改变，因为 struct proc 始终与当前 CPU 上的进程保持一致。\nsleep 与 wakeup至此我们已经能让进程彼此切换，但我们还不能帮助进程进行有意的交互。XV6 使用了一种名为 sleep 和 wakeup 的机制，它允许进程在等待某个事件时进入休眠状态，并在事件发生后由另一个进程将其唤醒。这个机制通常被称为 序列协调（sequence coordination）或 条件同步（conditional synchronization）机制。\n为了说明这一点，让我们考虑一个名为信号量（semaphore）的同步机制，它用于协调生产者和消费者。信号量维护一个计数，并提供两个操作：“V”操作（对于生产者）增加计数，“P”操作（对于消费者）等待计数为非零，然后递减并返回。如果只有一个生产者线程和一个消费者线程，并且它们在不同的 CPU 上执行，且编译器没有进行过过于积极的优化，那么这个实现将是正确的：\nstruct semaphore &#123;    struct spinlock lock;    int count;&#125;;void V(struct semaphore* s) &#123;    acquire(&amp;s-&gt;lock);    s-&gt;count += 1;    release(&amp;s-&gt;lock);&#125;void P(struct semaphore* s) &#123;    while (s-&gt;count == 0)        ;    acquire(&amp;s-&gt;lock);    s-&gt;count -= 1;    release(&amp;s-&gt;lock);&#125;\n这样的实现代价是相当昂贵的。如果生产者很少行动，消费者就会将大部分时间花在 while 循环中，反复等待计数为非零。这样，消费者的 CPU 就无法从等待中解脱出来，导致浪费时间。\n为了避免这种情况，我们需要一种机制来让消费者能够释放 CPU，只有在 V 操作增加计数后才恢复执行。可以设想一组配对使用的调用：sleep 和 wakeup，其工作机制如下所示。sleep(chan) 会使调用它的进程在某个值为 chan 的等待通道（wait channel）上进入睡眠状态，从而让出 CPU，用于执行其他任务。与之对应的 wakeup(chan) 则会唤醒所有在该通道上休眠的进程（如果存在），使它们从 sleep 调用中返回。若当前没有进程在该通道上等待，wakeup 调用不会产生任何效果。\n我们可以借助这两个函数将原来的信号量实现进行修改，以避免繁忙等待。下面是修改后的版本，添加了注释说明变更的部分：void V(struct semaphore* s) &#123;    acquire(&amp;s-&gt;lock);    s-&gt;count += 1;    wakeup(s);  // !pay attention    release(&amp;s-&gt;lock);&#125;void P(struct semaphore* s) &#123;    while (s-&gt;count == 0)        sleep(s);  // !pay attention    acquire(&amp;s-&gt;lock);    s-&gt;count -= 1;    release(&amp;s-&gt;lock);&#125;\n在引入 sleep 和 wakeup 之后，消费者不再浪费 CPU 去自旋等待，而是主动通过 sleep 放弃 CPU，这显然是一种改进。但这也引入了经典的并发问题 —— 丢失唤醒（lost wake-up）。\nsleep 必须在持锁的情况下调用，因为它不仅要修改进程自身的状态，还要在进入休眠前检查某个条件（例如资源是否可用）。这一检查与休眠必须是原子的，否则可能在检查后、进入睡眠前的一瞬间错过唤醒信号。\n相比之下，wakeup 的逻辑就简单得多。它只是遍历进程表，查找那些在给定 chan 上睡眠的进程，并将它们标记为 RUNNABLE。它并不依赖或访问 chan 代表的共享数据，只是把 chan 当作一个标签来匹配对应的进程，因此不需要外部持锁。\n设想如下情况：消费者线程执行 P 操作，在第 9 行检查发现 s-&gt;count == 0。就在它即将进入休眠（也就是在第 9 行和第 10 行之间的时间窗口内），生产者线程在另一个 CPU 上运行，它执行了 V 操作，将 s-&gt;count 增加为非零，并调用了 wakeup。由于此时消费者还未正式进入睡眠状态，wakeup 发现没有进程在等待通道上，因而什么也没做。接着，消费者继续执行第 10 行，调用 sleep 并进入睡眠状态。结果就出现了问题：消费者正在等待一个已经发生过的事件，而 wakeup 已经错过了唤醒它的时机。除非生产者再次调用 V，否则消费者将永远休眠，即使此时 count 已为非零。\n这个场景揭示了 sleep 和 wakeup 原始接口在缺乏原子性保护时容易引发竞态条件，因此必须借助一把锁来同步。然而，这里的竞态问题不同于常规的资源冲突：我们不能让 P 在持有锁的情况下直接进入睡眠，否则会造成死锁。\n为解决这一问题，sleep 被设计为支持带锁进入。它在调用进程被标记为 asleep 并挂载到睡眠通道后，会自动释放锁，允许其他线程修改它关心的数据。一旦进程被唤醒，sleep 会重新获取这把锁，从而保证让调用 sleep 的线程可以继续安全地访问它之前关心的数据。\nvoid V(struct semaphore* s) &#123;    acquire(&amp;s-&gt;lock);    s-&gt;count += 1;    wakeup(s);    release(&amp;s-&gt;lock);&#125;void P(struct semaphore* s) &#123;    acquire(&amp;s-&gt;lock);    while (s-&gt;count == 0)        sleep(s, &amp;s-&gt;lock);  // !pay attention    s-&gt;count -= 1;    release(&amp;s-&gt;lock);&#125;\n下面我们来了解一下 sleep 和 wakeup 的具体实现。\nsleep 会先获取进程锁并释放持有的锁，然后设置好通道，接着将当前进程标记为 SLEEPING，最后调用 sched 来释放 CPU，使系统可以调度其他进程运行。而 wakeup 则会在获取进程锁之后查找所有在指定等待通道上休眠的进程，并将它们的状态设置为 RUNNABLE，使其能够重新进入调度队列。sleep 和 wakeup 的调用者可以使用任何便于区分的值作为等待通道。XV6 中通常使用相关内核数据结构的地址作为通道，以自然地表示进程在等待的具体资源。\n这里有一个可能会令人感到困惑的点：为什么这里就可以释放持有的锁？事实上，这个锁的目的本就是为了确保共享数据 chan 的一致性，或者说保证没有其他进程可以启动唤醒程序。那么，在已经持有进程锁的情况下，唤醒程序自然不能启动，因此这个锁的任务已经结束，可以释放。\n还有一个细节就是这里的锁如果跟进程锁一样的话就会导致自锁，此时实际上我们不需要做任何事情，在 wait 持有 p-&gt;lock 访问 sleep时就属于这种情况。\n现在 sleep 只持有进程锁，它可以通过记录睡眠通道、将进程状态更改为 SLEEPING 并调用 sched 将进程置于睡眠状态。\n在某个时刻，一个进程会获取条件相关的锁，修改睡眠者正在等待的条件，并调用 wakeup(chan)。在持有锁的情况下调用 wakeup 是至关重要的。wakeup 会遍历整个进程表，并为它检查的每一个进程获取该进程的 p-&gt;lock——这样做不仅是为了可能修改进程状态，更是为了确保 sleep 和 wakeup 之间不会发生竞态，避免彼此“错过”。\n一旦 wakeup 发现某个进程处于 SLEEPING 状态，且其等待的 chan 与传入参数匹配，它就会将该进程的状态改为 RUNNABLE。随后，调度器在下一次运行时会注意到该进程已经准备好运行，并适时唤醒它。尽管仍有可能等待的条件还不足以让它醒来，此时该进程会再次陷入沉睡。\n通过睡眠与唤醒机制，我们可以实现条件同步，让进程进行合适的交互。\n管道一个更复杂的使用睡眠和唤醒机制来同步生产者和消费者的例子是 XV6 的管道实现。\n每个管道由一个 struct pipe 表示，其中包含一把锁 lock 和一个数据缓冲区 data。字段 nread 和 nwrite 分别记录读取和写入缓冲区的总字节数。缓冲区是环形结构：在 buf[PIPESIZE - 1] 之后，写入的下一个字节是 buf[0]。但 nread 和 nwrite 本身不是环形的，而是不断递增的计数器。这种设计使得我们可以轻松区分缓冲区满（nwrite == nread + PIPESIZE）和缓冲区空（nwrite == nread）的情况。但也因此，访问缓冲区时必须通过取模操作，例如使用 buf[nread % PIPESIZE]，而不能直接用 nread（nwrite 同理）。\n假设 piperead 和 pipewrite 的调用分别在两个不同的 CPU 上同时发生。pipewrite 首先获取管道的锁，这把锁用于保护计数器、数据缓冲区及相关的不变量。此时，piperead 也尝试获取同一把锁，但由于锁已被持有，它会在 acquire 中自旋等待。\n在 piperead 等待期间，pipewrite 会遍历 addr[0..n-1] 中的字节，逐个将其写入管道缓冲区。在这个过程中，缓冲区可能被写满。此时，pipewrite 会调用 wakeup，通知所有在等待数据的读进程：缓冲区已有数据可读。随后，pipewrite 在 &amp;pi-&gt;nwrite 上睡眠，等待读进程从缓冲区中取出一些字节。pipewrite 睡眠时，sleep 会自动释放 pi-&gt;lock，以便其他进程可以访问管道。\n此时，pi-&gt;lock 变得可用，piperead 成功获取锁并进入临界区。它发现 pi-&gt;nread != pi-&gt;nwrite（即还有数据可读——这是因为 pipewrite 进入睡眠时，满足的是 pi-&gt;nwrite == pi-&gt;nread + PIPESIZE，表示缓冲区已满）。于是，piperead 进入循环，从管道中复制数据，并按读取的字节数递增 nread。这些被读出的字节腾出了空间，因此 piperead 在返回前调用 wakeup 唤醒所有在 &amp;pi-&gt;nwrite 上休眠的写进程。wakeup 会查找那些在该等待通道上睡眠的进程——它们此前在缓冲区写满时停止在 pipewrite 中。找到后，wakeup 将这些进程标记为 RUNNABLE，使其可以被调度器重新运行。\n管道代码为读进程和写进程分别使用独立的睡眠通道（pi-&gt;nread 和 pi-&gt;nwrite），这样做的好处是在极少数读者和写者大量并发等待同一管道的情况下，能提高系统的效率。代码总是在检查条件的循环中调用 sleep；因此，如果有多个读者或写者在等待，除了第一个被唤醒且条件已满足的进程之外，其余进程醒来后通常仍会发现条件不成立，并再次进入睡眠。\nsleep/wakeup 的使用，本质是为了“条件同步”，而不是“等待时间长短”。在 pipe 中选择使用基本的睡眠/唤醒机制而非睡眠锁是因为它只需要同步，并不需要长时间等待，用基本的睡眠/唤醒机制是为了减小开销。\nwait, exit和killsleep 和 wakeup 可以用于多种类型的等待。另一个有趣的例子出现在第一章的子进程 exit 和父进程 wait 之间的交互之中。\n总体上来看，当子进程退出时，父进程可能正在 wait 中休眠，也可能在做其他事情；后者的情况下，随后的 wait 调用必须能够察觉到子进程已经退出，即使是在子进程调用 exit 很久之后。为了确保这一点，XV6 在子进程退出时将其状态设置为 ZOMBIE，并保留该状态直到父进程调用 wait。wait 会将子进程状态改为 UNUSED，复制其退出状态码，并将子进程的 PID 返回给父进程。如果父进程先于子进程退出，XV6 会将该子进程的父进程改为 init 进程。而 init 进程会不断调用 wait，确保所有孤儿进程最终都能被正确清理。\n这一机制背后的实现挑战在于：父进程与子进程之间的 wait 与 exit，以及并发 exit 之间可能存在的竞态和死锁问题。\n由于 wait 关心的资源与进程的所有子进程相关，使用一个与进程本身相关的锁无疑是一个合适的选择，最直接的选择就是进程锁。wait 使用调用进程自己的 p-&gt;lock 作为条件锁，以避免丢失唤醒问题，并在开始时获取这把锁。接着它会扫描整个进程表，查找属于自己的子进程。如果它发现某个子进程处于 ZOMBIE 状态，说明该子进程已经退出但尚未被清理。此时，wait 会回收该子进程占用的资源并释放其 proc 结构体；如果调用时传入了非空地址，还会将子进程的退出状态码复制到该地址；最后返回子进程的 PID；如果扫描过程中找到了子进程但没有任何一个已经退出，wait 就会调用 sleep，等待某个子进程的退出事件，然后再重新扫描一次。此处 sleep 所释放的锁就是调用进程自身的 p-&gt;lock，这是 XV6 中少见的以调用者自己的锁作为条件锁的情形。\n当然，在某些版本的实现中，为了简化 wait() 的实现并避免复杂的锁依赖，XV6 选择使用一把全局锁 wait_lock 来作为 sleep() 的条件锁。这种方式避免了对每个进程都使用独立的 p-&gt;lock，从而绕开了 wait() 中需要先持有父进程锁、再访问子进程的锁所带来的潜在死锁风险。由于 wait() 需要遍历整个 proc[] 表查找其子进程的状态，而每次访问子进程的成员（如 state）都必须加锁，因此该实现在进入 sleep() 前只需确保自己仍拥有 wait_lock 即可。在对应的 exit() 中，内核也在唤醒父进程之前加锁 wait_lock，从而保证了唤醒不会丢失。这种设计虽然加大了锁的粒度，可能影响并发性，但换来了更清晰的锁结构和更低的死锁风险，更适合教学场景和简单内核结构。\n需要特别注意的是，wait 过程中可能同时持有两把锁：它首先获取自己的锁 p-&gt;lock，在此基础上再尝试获取子进程的锁。这就要求整个 XV6 系统在处理父子进程关系时必须遵循一致的加锁顺序（即先父后子），以避免死锁。\nwait 通过检查每个进程的 np-&gt;parent 字段来查找其子进程。它在未持有 np-&gt;lock 的情况下访问该字段，这违反了通常的并发规则：共享变量的访问应受到锁的保护。然而，这么做是出于避免死锁的考虑。np 可能是当前进程的祖先，如果在遍历过程中尝试获取 np-&gt;lock，就可能违反“先锁父、再锁子”的锁获取顺序，从而导致死锁。尽管这种无锁读取看似危险，但这里是安全的：一个进程的 parent 字段只会被它的父进程修改。因此，如果 np-&gt;parent == p 在某一时刻为真，那除非当前进程自己改变它，该值在后续也不会变化。\nexit 记录退出状态码，释放部分资源，将所有子进程转交给 init，如果父进程正在等待，则唤醒它。随后，它将自身标记为僵尸进程（ZOMBIE），并永久让出 CPU。  \n这个过程的最后几个步骤顺序较为微妙：退出进程必须在将其状态设为 ZOMBIE 并唤醒父进程时，持有父进程的锁——这是因为 wait 使用父进程的锁作为条件锁，以避免丢失唤醒。同时，退出进程还必须持有自己的 p-&gt;lock，否则父进程可能在它仍在运行时就观察到 ZOMBIE 状态并开始回收该结构体。锁的获取顺序对避免死锁至关重要：由于 wait 总是先获取父锁再获取子锁，因此 exit 也必须遵循相同的顺序。\nexit 会调用一个专门的唤醒函数 wakeup1，这是因为我们规定了锁的获取顺序，所以不能用 wakeup 函数。该函数只会唤醒当前进程的父进程，且父进程必须正处于 wait 中的睡眠状态。虽然子进程在将自身状态设置为 ZOMBIE 之前就唤醒了父进程，这看起来可能存在竞态，但实际上是安全的：尽管 wakeup1 可能导致父进程立即运行，但 wait 中的循环在调度器释放子进程的 p-&gt;lock 之前，无法观察到子进程的状态。因此，父进程不会在 exit 设置状态之前就看到子进程处于 ZOMBIE 状态，也就不会提前对其进行回收。\nexit 允许进程自行终止，而 kill 则允许一个进程请求终止另一个进程。直接立即销毁目标进程（即被 kill 的进程）是非常复杂且危险的，因为目标进程可能正运行在另一个 CPU 上，甚至可能正处于修改内核数据结构的关键时刻。因此，kill 的实现非常简洁：它仅仅设置目标进程的 p-&gt;killed 标志，如果目标进程当前处于睡眠状态，还会将其唤醒。\n目标进程最终一定会再次进入或离开内核，而在进入内核（如通过系统调用或中断）时，如果发现 p-&gt;killed 被设置，usertrap 中的代码就会触发 exit，使进程终止。即使目标进程当时正运行在用户空间，它也很快会因为系统调用或定时器中断等事件重新进入内核，从而触发退出流程。\n如果受害进程正在休眠，kill 调用中的 wakeup 会使其从休眠中返回。这本身是有潜在风险的，因为唤醒时等待的条件可能尚未满足。不过，XV6 的所有 sleep 调用都被包裹在一个 while 循环中，该循环会在 sleep 返回后重新检查条件是否成立。\n此外，一些 sleep 调用还会在循环中检查 p-&gt;killed 标志。如果发现该标志被设置，则会中止当前操作。当然，只有在中止是合理的前提下，才会进行这种检查。比如，在管道的读写代码中，如果检测到进程被 kill，将会立即返回；后续执行路径最终会进入 trap（陷阱处理），在这里系统会再次检查 killed 标志并调用 exit 退出。\n这里不用睡眠锁的理由又有所不同，这里目标并不是保护共享资源，而是让父进程等待子进程的退出。在这个过程中，父进程并不会直接操作共享数据结构，因此不需要使用睡眠锁来同步。只有等待时间长且需要修改共享资源时，才需要使用睡眠锁来保护数据结构的完整性。\n说起来今天才知道 VSCode 的 vim 插件用的寄存器跟系统剪切板不一样，如果要用系统剪切板要开 set clipboard=unnamedplus。\n小总结：XV6 进程状态一览\n  \n    \n      状态\n      含义\n      会被调度？\n      何时设置？\n      会变为？\n      举例\n    \n  \n  \n    \n      UNUSED\n      空槽，未被占用\n      ❌\n      proc 被初始化或回收后\n      分配后 → EMBRYO\n      空闲 proc[] 表项\n    \n    \n      EMBRYO\n      正在创建\n      ❌\n      allocproc() 中\n      RUNNABLE\n      刚分配的进程\n    \n    \n      SLEEPING\n      睡眠中，等待事件\n      ❌\n      sleep(chan, lock)\n      被 wakeup → RUNNABLE\n      等待输入、锁资源\n    \n    \n      RUNNABLE\n      可运行队列\n      ✅\n      被 wakeup 或刚创建好\n      RUNNING\n      等待被调度\n    \n    \n      RUNNING\n      正在 CPU 上执行\n      ✅\n      被调度器挑中运行时\n      执行结束或主动放弃 CPU\n      \n    \n    \n      ZOMBIE\n      已退出，等待父收尸\n      ❌\n      exit() 时\n      被 wait() → UNUSED\n      子进程退出但父未 wait\n    \n  \n\n\n实验内容Uthread: switching between threads (moderate)第一个小实验要求我们实现简单的“用户级线程”，也就是说我们完全在用户态自己管理、创建、切换一些小线程。它切换快，控制透明，对内核透明，而且可移植性高，适合轻量、可控的任务模型。\n这个实验很简单，我们参考内核中的 proc.h,proc.c 以及 swtch.S 即可。类似进程的结构体，我们用一个 thread_context 保存上下文。struct thread_context&#123;  uint64 ra;  uint64 sp;  // callee-saved  uint64 s0;  uint64 s1;  uint64 s2;  uint64 s3;  uint64 s4;  uint64 s5;  uint64 s6;  uint64 s7;  uint64 s8;  uint64 s9;  uint64 s10;  uint64 s11;&#125;;struct thread &#123;  char       stack[STACK_SIZE]; /* the thread&#x27;s stack */  int        state;             /* FREE, RUNNING, RUNNABLE */  struct thread_context context;/* the thread&#x27;s context*/&#125;;\n然后完善 thread_create 函数。参考 procinit 函数，我们知道初始时进程只要保存 ra 和 sp 寄存器，也即返回地址和栈指针。这里的返回地址就是我们的函数所在位置，我们假装自己是调用了 func 准备返回。void thread_create(void (*func)())&#123;  struct thread *t;  for (t = all_thread; t &lt; all_thread + MAX_THREAD; t++) &#123;    if (t-&gt;state == FREE) break;  &#125;  t-&gt;state = RUNNABLE;  // YOUR CODE HERE  t-&gt;context.ra = (uint64)func;  t-&gt;context.sp = (uint64)&amp;t-&gt;stack[STACK_SIZE - 1];&#125;\n然后在 thread_schedule 里面调用 thread_switch 函数来切换进程上下文。if (current_thread != next_thread) &#123;         /* switch threads?  */  next_thread-&gt;state = RUNNING;  t = current_thread;  current_thread = next_thread;  /* YOUR CODE HERE   * Invoke thread_switch to switch from t to next_thread:   * thread_switch(??, ??);   */  thread_switch((uint64)&amp;t-&gt;context, (uint64)&amp;next_thread-&gt;context);&#125; else  next_thread = 0;\n最后完善 thread_swtch 函数，把 swtch.S 里面的上下文切换函数抄过来即可。thread_switch:\tsd ra, 0(a0)\tsd sp, 8(a0)\tsd s0, 16(a0)\tsd s1, 24(a0)\tsd s2, 32(a0)\tsd s3, 40(a0)\tsd s4, 48(a0)\tsd s5, 56(a0)\tsd s6, 64(a0)\tsd s7, 72(a0)\tsd s8, 80(a0)\tsd s9, 88(a0)\tsd s10, 96(a0)\tsd s11, 104(a0)\tld ra, 0(a1)\tld sp, 8(a1)\tld s0, 16(a1)\tld s1, 24(a1)\tld s2, 32(a1)\tld s3, 40(a1)\tld s4, 48(a1)\tld s5, 56(a1)\tld s6, 64(a1)\tld s7, 72(a1)\tld s8, 80(a1)\tld s9, 88(a1)\tld s10, 96(a1)\tld s11, 104(a1)\t\tret    /* return to ra */\nUsing threads (moderate)这个实验也很简单，要我们解决并发时候的竞态问题。我们可以发现是插入桶的时候可能有并发问题，那么最简单的解决方法就是给整个表上一个锁。但这样就将所有的操作都串行化了，没有利用多线程的性能，加上额外开销导致性能甚至比单线程要低。\n\n  \n  图一：表级锁结果\n\n\n\n更好的方法是给每个桶加一个锁，如果需要插入修改，就给对应的桶上锁。不要忘了测试前要 make ph。\npthread_mutex_t lock[NBUCKET];static void put(int key, int value)&#123;  int i = key % NBUCKET;  // is the key already present?  struct entry *e = 0;  for (e = table[i]; e != 0; e = e-&gt;next) &#123;    if (e-&gt;key == key)      break;  &#125;  if(e)&#123;    // update the existing key.    e-&gt;value = value;  &#125; else &#123;    // the new is new.    pthread_mutex_lock(&amp;lock[i]);    insert(key, value, &amp;table[i], table[i]);    pthread_mutex_unlock(&amp;lock[i]);  &#125;&#125;intmain(int argc, char *argv[])&#123;  ...  // 初始化锁  for (int i = 0; i &lt; NBUCKET; i++)    pthread_mutex_init(&amp;lock[i], NULL);  ...&#125;\n\n  \n  图二：桶级锁结果\n\n\nBarrier(moderate)最后一个实验是实现一个屏障，让所有线程同步。不难看出这个就是 sleep 和 wakeup 机制的最简单利用。我们在睡眠前获取锁，带锁进入睡眠，被唤醒后再释放锁即可。\nstatic void barrier()&#123;  // YOUR CODE HERE  pthread_mutex_lock(&amp;bstate.barrier_mutex);  bstate.nthread++;  if (bstate.nthread == nthread)  &#123;    bstate.round++;    bstate.nthread = 0;    pthread_cond_broadcast(&amp;bstate.barrier_cond);  &#125;  else    pthread_cond_wait(&amp;bstate.barrier_cond, &amp;bstate.barrier_mutex);  pthread_mutex_unlock(&amp;bstate.barrier_mutex);&#125;\n小结Lab7 慢慢悠悠地完结了，这Lab难度跟手册上的例子难度差的不是一点半点，简单的过头了。如果对比较难的手册内容都理解了的话，稍微简化一些就可以搬到Lab中用了。总之，进程是操作系统中相当有趣的一部分。通过多个进程、线程的切换，可以很好地协调整个系统，提高效率。\n\n  \n  图三：通关截图\n\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","线程","自旋锁"]},{"title":"MIT-6-S081-Lab8：Locks","url":"/2025/04/10/MIT-6-S081-Lab8%EF%BC%9ALocks/","content":"知识点2000年左右，随着技术的进步，CPU 的时钟频率达到了一个极限，单线程性能也随之趋于瓶颈。然而，随着晶体管数量的不断增加，CPU 开始向多核架构发展。因此，大多数现代操作系统采用多核处理器，交替执行多个任务。虽然这种并行执行大大提高了系统的总体处理能力，但也带来了并发性问题和潜在的风险。\n在并发环境中，多个进程或线程可能会访问共享资源，这就需要一种机制来确保数据的一致性和任务的正确性。这时，锁成为了至关重要的工具。锁通过同步并发任务的执行，确保在任何时刻只有一个进程或线程能访问某个共享资源，从而避免竞态条件、数据竞争等问题，确保程序在并发环境中的正确性和有序执行。\n锁的设计和实现，随着多核处理器的普及，成为了操作系统中不可或缺的一部分。通过精确的锁机制，操作系统能够有效地管理多个并发执行的活动，保证系统稳定、可靠地运行。\n并发控制与锁的原理在讨论设备中断时，我们已经意识到并发带来的风险。接下来，我们将深入探讨如何有效应对这些风险。\n操作系统能够交错执行多个活动，部分原因在于它拥有多个处理器硬件，这些 CPU 独立执行任务，但共享物理内存。XV6 利用这种共享来维护跨 CPU 的数据结构，如进程表或调度器状态。为了保证这些数据结构在并发访问下的一致性和正确性，系统需要采取措施避免多个 CPU 同时访问或修改相同的数据，进而导致数据损坏。此外，即使在单核系统中，内核也会在多个线程之间切换执行，导致指令流交错，从而可能引发类似问题。设备中断同样可能在任意时刻打断当前执行流，导致中断处理程序修改正在访问的共享数据。为了应对这些并发问题，操作系统设计采用了多种同步机制，如锁，以确保多个执行流在访问共享资源时不会发生冲突。\n锁提供了互斥，确保在任何时刻只有一个 CPU 可以持有锁。当程序员将每个共享数据项与一个锁关联，并确保在访问数据时始终持有相应的锁时，数据项在同一时刻只能被一个 CPU 使用。在这种情况下，我们称锁为“保护”数据项。尽管锁是一个易于理解的并发控制机制，它的缺点在于可能会显著降低性能，因为锁会串行化本应并行的操作。\n竞争条件指的是一个内存位置被并发访问，且至少有一个访问是写入操作。竞争通常是 bug 的表现，可能导致更新丢失或读取到不完整的数据。竞争的结果取决于两个 CPU 执行的实际顺序，以及内存系统如何排序这些操作，这使得竞争引发的 bug 难以复现和调试。例如，插入 printf 语句进行调试时，可能会改变执行时间，从而使竞争条件消失。\n当我们说锁保护数据时，实际意味着锁保护了应用在数据上的一系列不变性。一个操作的正确性依赖于操作开始时不变性是否成立。虽然操作可能会暂时违反不变性，但必须在操作结束前恢复不变性。例如，对于链表，其不变性是头指针指向第一个元素，且每个元素的 next 域指向下一个元素。执行 push 操作时，l-&gt;next = list 会暂时破坏不变性，因为头指针不再指向第一个元素。竞争条件发生时，另一个 CPU 上的操作依赖于这些不变性，而这些不变性被暂时破坏了。使用锁可以保证在数据结构的临界区内只有一个 CPU 执行操作，从而避免在不变性被破坏时执行操作。\n可以认为，锁通过将并发的临界区串行化，确保在任何时刻只有一个操作在执行，从而保护了不变性。也可以将被锁保护的临界区视为对其他临界区具有原子性，确保每个临界区的修改对其他操作来说是完整的，永远不会出现部分修改的情况。\n正如之前所说，尽管锁的正确使用能够确保代码的正确性，但它也会影响性能。例如，当两个进程同时调用 kfree 时，锁会将这两个调用串行化，这意味着即使它们在不同的 CPU 上运行，也无法获得并行的性能收益。因此在内核设计中，一个重要的课题是如何减少锁争用。虽然 XV6 在这方面的处理较为简单，但更复杂的内核会通过优化数据结构和算法来减少锁争用。例如，内核可能会为每个 CPU 维护独立的空闲内存链表，只有在当前 CPU 的链表为空时，才会向其他 CPU 请求空闲内存。其他形式的争用可能需要更为复杂的设计。\n此外，锁的位置也会显著影响性能。例如，在 push 操作中，如果将 acquire 放在较前的位置，会确保更早地获取锁，但这也会使 malloc 调用被串行化，从而降低性能。\n自旋锁XV6中有两种锁：自旋锁和睡眠锁。自旋锁定义为 struct spinlock，最重要的域就是 locked，1 代表被持有而 0 代表未被持有。理论上 XV6 可以通过下列代码来上锁：\nvoidacquire(struct spinlock *lk) // does not work!&#123;  for(;;) &#123;    if(lk-&gt;locked == 0) &#123;      lk-&gt;locked = 1;      break;    &#125;  &#125;&#125;\n但这种方式无法在多个处理器之间实现真正的互斥。例如，当两个 CPU 同时读取 locked 并看到其值为 0 时，它们可能都会尝试获取该锁，从而导致同时进入临界区，无法保证互斥性。因此，我们需要将这些操作原子化。\n为此，多核处理器通常提供专门的原子指令，并依赖特殊的硬件机制来保障其正确性。在 RISC-V 架构中，这条原子交换指令是 amoswap r, a。它会将寄存器 r 中的值写入内存地址 a，同时将该地址原有的值读出并存入寄存器 r，实现寄存器与内存之间内容的交换。整个过程由底层硬件以原子方式完成，确保在读写之间没有其他 CPU 能访问该内存地址。这种特殊的硬件支持是实现互斥的关键，使得操作系统能够在多处理器环境中安全地管理共享资源。\n获取锁的过程通过 acquire 函数实现，它调用可移植的C库函数 __sync_lock_test_and_set，其在底层就是通过 amoswap 来实现的。该函数的返回值是 locked 原先的值，也就是交换前的内容。\nacquire 在一个循环中不断调用这个交换操作，直到成功获取锁为止（这被称为自旋）。每次循环中，函数将值 1 写入 locked，并通过原子交换得到它之前的值：如果旧值为 0，说明锁原本未被占用，当前线程成功获取了锁，同时也已将 locked 设置为 1；如果旧值为 1，则表示锁已被其他 CPU 持有，虽然进行了交换，但 locked 的值仍然是 1，锁未被获取，循环将继续尝试。\n获取锁后，用于调试，acquire 将记录下来获取锁的 CPU。lk-&gt;cpu 字段受锁保护，只能在保持锁时更改。\nrelease 函数则与 acquire 相反，该函数需要清空 CPU 域并释放锁。理论上释放只需要将 locked 域置 0 即可。但因为C语言标准运行编译器使用多存储指令来实现赋值，因此一条赋值语句也可能不是原子的。因此，release 需要使用C库函数 __sync_lock_release 来进行原子性赋值，它的底层也是通过 amoswap 指令实现的。\n我们这里的底层之所以不使用 load 或者 store 来读写，是因为它们尽管看起来很简单，但并不是原子的，实际实现中可能由几个小步骤来实现。\n锁的使用我们往往不得不使用锁，但锁的使用又会降低效率，所以使用多少锁和他们各自保护哪些不变量都值得仔细斟酌。最基本的原则是：\n\n当一个变量被一个 CPU 写入时，如果其他 CPU 也可以对其进行读写，就需要使用锁来避免操作重叠\n如果一个不变量涉及多个内存位置，那么每个位置都需要被单独的锁来保护，从而保证不变量\n\n如果不考虑效率，我们完全可以通过限制同一时刻只允许一个线程执行来避免所有并发问题。一个简单的做法是在多处理器系统上为整个内核设置一个锁：每当线程进入内核时，必须先获取这个锁，在离开内核时再释放它（尽管如管道读取或 wait 的系统调用会带来问题）。这样可以确保在任意时刻，只有一个线程在执行内核代码，从而完全避免并发带来的风险。很多单处理器系统已经使用这种方法来在多处理器上运行，这被称作“大内核锁”。但这破坏了并行性，为了提高效率，我们往往倾向于使用一组更细粒度的锁来让内核可以同时在多个处理器上执行。\n一个粗粒度锁的例子是 XV6 的 kalloc.c 的分配器，它只有一个被锁保护的空闲链表。如果多个进程申请页面，他们都需要在 acquire 中自旋等待。为了提升效率，可以改变分配器的设计，使用多个空闲链表，让每个链表单独持有锁，从而允许真正的并行分配来提高性能。\n一个细粒度锁的例子是 XV6 的文件锁，XV6 对于每个文件都有一个单独的锁，操作不同文件的进程无需等待其他的文件的锁。文件锁模式的粒度可以变得更加的细，比如控制每个区域之类的。总之，粒度需要综合锁的复杂性与性能度量来决定。\nXV6 中使用的锁如下表所示：\n\n\n\n\n锁名\n描述\n\n\n\n\nbcache.lock\n保护块缓冲区缓存项的分配\n\n\ncons.lock\n串行化对控制台硬件的访问，避免混合输出\n\n\nftable.lock\n串行化文件表中文件结构的分配\n\n\nicache.lock\n保护索引结点缓存项的分配\n\n\nvdisk_lock\n串行化对磁盘硬件和 DMA 描述符队列的访问\n\n\nkmem.lock\n串行化内存分配\n\n\nlog.lock\n串行化事务日志操作\n\n\npi-&gt;lock\n串行化每个管道的操作\n\n\npid_lock\n串行化 next_pid 的递增\n\n\np-&gt;lock\n串行化进程状态的改变\n\n\ntickslock\n串行化时钟计数操作\n\n\nip-&gt;lock\n串行化索引结点及其内容的操作\n\n\nb-&gt;lock\n串行化每个块缓冲区的操作\n\n\n\n\n死锁和锁排序如果某段内核代码在执行过程中必须同时持有多个锁，那么所有相关的代码路径必须按照相同的顺序依次获取这些锁。这种统一的获取顺序对于避免死锁至关重要。若不同路径以不同顺序获取锁，就可能出现循环等待的情况，从而导致循环等待死锁。所以我们需要约定一个获取锁的顺序。\nXV6 中存在许多长度为 2 的锁顺序链，通常涉及进程锁，其中一个常见的场景是 sleep 函数的使用。例如，consoleintr 是用于处理输入字符的中断处理函数。当新的一行输入到达时，内核会唤醒所有等待控制台输入的进程。在调用 wakeup 时，consoleintr 持有 cons.lock，而 wakeup 会获取目标进程的锁来修改其状态。为了避免死锁，必须遵循一条锁顺序规则：cons.lock 必须在任意进程锁之前获取。\nXV6 文件系统代码中包含了最长的锁链。例如，在创建一个新文件时，系统可能需要依次获取：目录的锁、新文件的 inode 锁、磁盘块缓冲区的锁、磁盘驱动的 vdisk_lock，以及调用进程的锁。为了避免死锁，文件系统代码通常严格按照约定的顺序获取这些锁。\n然而，遵守全局锁顺序以避免死锁可能非常困难。首先，锁顺序有时会与程序结构的逻辑冲突，例如模块 M1 调用了模块 M2，那么锁顺序要求必须先知道 M2 中所有的锁，但我们模块化的目的本就是希望将不同的功能模块分离开，使得每个模块在功能上独立。其次，有时在获取一个锁之前，并不能预知接下来需要获取哪个锁。比如，在文件系统中根据路径名逐级查找目录项时，只有在拿到当前目录的锁后，才能确定下一个要访问的目录或文件，从而决定接下来的锁。此外，wait 和 exit 函数在遍历进程表查找子进程时也存在类似情况。\n为了降低循环等待死锁的风险，锁的设计往往不得不牺牲一定的并发性，采用较粗粒度的策略。锁的数量越多、粒度越细，系统中可能出现的锁依赖关系就越复杂，死锁的可能性也随之上升。因此，在内核实现中，如何有效地避免死锁是一项至关重要的设计任务。\n在自旋锁和中断的交互中也可能有死锁风险。在 XV6 中，一些自旋锁用于保护既可能被内核线程访问，又可能被中断处理程序访问的共享数据。例如，定时器中断处理程序 clockintr 会更新 ticks 变量，而与此同时，一个内核线程可能正在 sys_sleep 中读取 ticks。tickslock 会将这两种访问串行化，确保在任意时刻只有一个执行流可以访问 ticks。\n因此，自旋锁与中断的交互可能引发严重问题。假设 sys_sleep 获取了 tickslock 后运行时被定时器中断打断，中断处理程序 clockintr 随即尝试获取同一个锁。由于锁已被持有，clockintr 会忙等等待锁释放。然而，只有 sys_sleep 能释放该锁，而它必须等中断返回才能继续执行。这就造成了死锁：CPU 被困在中断处理程序中，无法继续运行原线程，也就无法释放锁，进而导致所有依赖该锁的代码陷入冻结状态。\n为了避免这种情况，如果某个自旋锁会在中断处理程序中被使用，那么必须保证在中断开启的情况下，CPU 不会持有该锁。XV6 采取了更为保守的策略：每当 CPU 申请任何自旋锁时，都会在本地关闭中断。这样可以确保当前 CPU 不会在持锁期间被中断打断，从而避免自陷式死锁。需要注意的是，中断在其他 CPU 上仍然是可以发生的，因此这些中断处理程序依然可以尝试获取锁并等待，只要等待的不是当前 CPU 持有的锁，就不会造成问题。\n当一个 CPU 不再持有自旋锁时，中断会被重新允许。为了处理嵌套的临界区，XV6 通过一些小的记录来跟踪当前 CPU 的嵌套层次。具体来说，acquire 调用 push_off，而 release 调用 pop_off 来管理临界区的嵌套状态。当计数器为 0 时，pop_off 会恢复到最外层临界区开始前的中断允许状态。intr_off 和 intr_on 分别用于执行 RISC-V 指令来关闭和开启中断，同时记录当前的中断状态，intr_get 则用于获取当前的中断允许状态。\n这里还有一个需要注意的小细节：在 acquire 设置 lk-&gt;locked 之前调用 push_off 是非常重要的。如果两者顺序交换，就会存在一个小窗口：此时锁已经被获取，但中断却仍然是允许的。如果在这个窗口期间发生了中断，可能会导致系统死锁。类似地，在 release 释放锁之后再调用 pop_off 也非常关键，确保在释放锁后恢复正确的中断状态，以避免潜在的死锁或中断问题。\n指令和内存访问排序人们通常认为程序是按照源代码中语句的顺序执行的。然而，为了提高性能，许多编译器和 CPU 并不按照源代码的顺序执行指令。事实上，编译器和 CPU 往往会采用指令重排技术来提高执行效率。\n当一条指令需要较长时间才能完成时，CPU 可能会提前发出其他指令，以便与当前指令的执行重叠，从而避免 CPU 停顿。例如，在顺序执行的指令A和B之间，如果它们之间没有依赖关系，CPU 可能会选择先执行指令B。这样做的原因是，指令B可能先准备好所需的输入，或者 CPU 可以通过同时执行A和B来提高吞吐量。\n编译器也会使用类似的技术，称为“指令重排”，它通过在源代码中先发出一条语句的指令，然后再发出另一条语句的指令，从而优化执行顺序。这种优化不仅提升了性能，还避免了 CPU 空闲等待的情况。\n编译器和 CPU 在进行指令重排时需要遵循一定规则，以确保不会改变正确编写的串行代码的执行结果。然而，这些规则确实允许在重排后改变并发代码的执行结果，并且这种改变很容易在多处理器系统上引发不正确的行为。我们将 CPU 的这种排序规则称为内存模型。\n例如，在 push 的代码中，编译器或 CPU 可能会将对应于第4行的存储指令移动到第6行 release 后的某个地方，这会导致并发的风险：l = malloc(sizeof *l);l-&gt;data = data;acquire(&amp;listlock);l-&gt;next = list;list = l;release(&amp;listlock);\n如果发生这样的重新排序，就会出现一个窗口期，在此期间另一个 CPU 可能会获取锁并访问已经更新的 list，但此时 list-&gt;next 可能尚未初始化，导致读取到未定义或错误的值。\n为了防止硬件和编译器执行此类重新排序，XV6 在 acquire 和 release 函数中都使用了 __sync_synchronize()。该函数是一种内存屏障，用于指示编译器和 CPU 不得跨越该屏障对 load 或 store 指令进行重排。由于 XV6 在访问共享数据时通过加锁来实现同步，这些内存屏障在几乎所有重要场景下都能确保内存操作的顺序性——尽管在后续的课程中可能会涉及一些例外情况。\n睡眠锁自旋锁类似于轮询，而睡眠锁则更像中断机制。\n有时，XV6 需要长时间持有某个锁。例如，文件系统在对磁盘进行读写时会持有文件锁，而这些操作可能耗时数十毫秒。当其他进程尝试获取该锁时，如果使用的是自旋锁，就会造成大量浪费，因为等待锁的进程会持续占用 CPU 进行忙等。\n自旋锁还有一个缺点：持锁进程不会让出（yield）CPU。但当它在等待磁盘等慢速资源时，我们希望其他进程能够使用 CPU。然而正如之前所说，持有自旋锁时让出 CPU 是不安全的，因为这可能导致死锁。例如，第二个线程在尝试获取该锁时持续自旋，可能会阻碍第一个线程运行，从而无法释放锁。\n因此，XV6 引入了一种新的锁机制：在等待获取锁时，它可以让出 CPU；即使在已经持有锁的情况下，也允许让出 CPU 并重新开启中断。\nXV6 以睡眠锁（sleep-locks）的形式提供了这种锁。acquiresleep 函数利用下一章将介绍的机制实现了这一点。从结构上看，睡眠锁内部有一个 locked 字段，并使用一个自旋锁来保护它。acquiresleep 会调用 sleep，在原子地释放自旋锁的同时让出 CPU，这样其他线程就可以在它等待期间继续执行。\n由于睡眠锁在持锁期间保持中断开启，因此不能在中断处理程序中使用。同时，由于 acquiresleep 可能会让出 CPU，睡眠锁也不能在自旋锁的临界区中使用（尽管可以在睡眠锁的临界区中使用自旋锁）。\n考虑到自旋锁在等待期间会浪费 CPU 时间，它更适用于临界区较短的场景；而睡眠锁则更适合用于执行时间较长的操作。\n实验任务Memory allocator(moderate)正如我们之前所说，XV6 的内存分配器使用一个全局锁来保护空闲链表，这样虽然简单，但会导致性能下降。我们将通过实现一个更细粒度的锁来提高性能。\n我们将为每个 CPU 分配一个独立的空闲链表，并为每个链表分配一个锁。这样，每个 CPU 都可以独立地从自己的链表中分配内存，而不需要等待其他 CPU 释放锁。在 CPU 自身的链表内存不足时，它会尝试从其他 CPU 的链表中获取内存。\n先修改kmem结构体，变成 NCPU 个链表。struct &#123;  struct spinlock lock;  struct run *freelist;&#125; kmem[NCPU];\n然后修改 kinit 函数，初始化每个锁。voidkinit()&#123;  for(int i = 0; i &lt; NCPU; i++)    initlock(&amp;kmem[i].lock, &quot;kmem&quot;);  freerange(end, (void*)PHYSTOP);&#125;\n然后修改 kfree 函数，使用 cpuid() 来获取当前 CPU 的id，注意要禁用中断。voidkfree(void *pa)&#123;  struct run *r;  if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP)    panic(&quot;kfree&quot;);  // Fill with junk to catch dangling refs.  memset(pa, 1, PGSIZE);  r = (struct run*)pa;  push_off();  int cpu_id = cpuid();  acquire(&amp;kmem[cpu_id].lock);  r-&gt;next = kmem[cpu_id].freelist;  kmem[cpu_id].freelist = r;  release(&amp;kmem[cpu_id].lock);  pop_off();&#125;\n最后修改 kalloc 函数，尝试从当前 CPU 的链表中分配内存，如果当前链表为空，则尝试从其他 CPU 的链表中获取内存。void *kalloc(void)&#123;  struct run *r;  push_off();  int cpu_id = cpuid();  acquire(&amp;kmem[cpu_id].lock);  r = kmem[cpu_id].freelist;  if(r)    kmem[cpu_id].freelist = r-&gt;next;  release(&amp;kmem[cpu_id].lock);  if(r == 0)  &#123;    for(int i = 0; i &lt; NCPU; i++)    &#123;      int next_cpu_id = (cpu_id + i + 1) % NCPU;      acquire(&amp;kmem[next_cpu_id].lock);      r = kmem[next_cpu_id].freelist;      if(r)        kmem[next_cpu_id].freelist = r-&gt;next;      release(&amp;kmem[next_cpu_id].lock);      if(r)        break;    &#125;  &#125;  if(r)    memset((char*)r, 5, PGSIZE); // fill with junk  pop_off();  return (void*)r;&#125;\n这样就完成了内存分配器的修改。现在每个 CPU 都有自己的空闲链表和锁，可以独立地进行内存分配和释放。当然，为了区分每个锁，我们还可以对锁用 snprintf 进行格式化命名。\nBuffer cache(hard)呃，怎么说呢，虽然还没学缓冲区，但这个实验的确不需要知道什么东西。我们的目的还是细化锁的粒度，因此我们会考虑把缓冲区拆成多个部分，用哈希表来选择从哪个缓冲区中分配。然后，拆开后把所有锁给无脑改掉就行了……#define NBUCKET 13#define NBUCKETSIZE 10struct &#123;  struct spinlock lock;  struct buf buf[NBUCKETSIZE]; // Buffer structures  struct buf head;&#125; bcache[NBUCKET];\nhash函数就用简单的取模即可，复杂的反而可能引入更多的竞争。#define HASH(dev, blockno) blockno % NBUCKET\n然后在 binit 中初始化锁。voidbinit(void)&#123;  struct buf *b;  for(int i = 0; i &lt; NBUCKET; i++)  &#123;    initlock(&amp;bcache[i].lock, &quot;bcache&quot;);    bcache[i].head.prev = &amp;bcache[i].head; // double linked list    bcache[i].head.next = &amp;bcache[i].head;    for(b = bcache[i].buf; b &lt; bcache[i].buf + NBUCKETSIZE; b++)    &#123;      b-&gt;next = bcache[i].head.next;      b-&gt;prev = &amp;bcache[i].head;      initsleeplock(&amp;b-&gt;lock, &quot;buffer&quot;);      bcache[i].head.next-&gt;prev = b;      bcache[i].head.next = b;    &#125;  &#125;&#125;在 bget 中获取锁。static struct buf*bget(uint dev, uint blockno)&#123;  struct buf *b;  int hash = HASH(dev, blockno);  acquire(&amp;bcache[hash].lock);  // Is the block already cached?  for(b = bcache[hash].head.next; b != &amp;bcache[hash].head; b = b-&gt;next)&#123;    if(b-&gt;dev == dev &amp;&amp; b-&gt;blockno == blockno)&#123;      b-&gt;refcnt++;      release(&amp;bcache[hash].lock);      acquiresleep(&amp;b-&gt;lock);      return b;    &#125;  &#125;  // Not cached.  // Recycle the least recently used (LRU) unused buffer.  for(b = bcache[hash].head.prev; b != &amp;bcache[hash].head; b = b-&gt;prev)&#123;    if(b-&gt;refcnt == 0) &#123;      b-&gt;dev = dev;      b-&gt;blockno = blockno;      b-&gt;valid = 0;      b-&gt;refcnt = 1;      release(&amp;bcache[hash].lock);      acquiresleep(&amp;b-&gt;lock);      return b;    &#125;  &#125;  panic(&quot;bget: no buffers&quot;);&#125;\n然后brelse,bpin 和 bunpin 也一样。voidbrelse(struct buf *b)&#123;  if(!holdingsleep(&amp;b-&gt;lock))    panic(&quot;brelse&quot;);  releasesleep(&amp;b-&gt;lock);  int hash = HASH(b-&gt;dev, b-&gt;blockno);  acquire(&amp;bcache[hash].lock);    b-&gt;refcnt--;  if (b-&gt;refcnt == 0) &#123;    // no one is waiting for it.    b-&gt;next-&gt;prev = b-&gt;prev;    b-&gt;prev-&gt;next = b-&gt;next;    b-&gt;next = bcache[hash].head.next;    b-&gt;prev = &amp;bcache[hash].head;    bcache[hash].head.next-&gt;prev = b;    bcache[hash].head.next = b;  &#125;    release(&amp;bcache[hash].lock);&#125;voidbpin(struct buf *b) &#123;  int hash = HASH(b-&gt;dev, b-&gt;blockno);  acquire(&amp;bcache[hash].lock);  b-&gt;refcnt++;  release(&amp;bcache[hash].lock);&#125;voidbunpin(struct buf *b) &#123;  int hash = HASH(b-&gt;dev, b-&gt;blockno);  acquire(&amp;bcache[hash].lock);  b-&gt;refcnt--;  release(&amp;bcache[hash].lock);&#125;然后就没了……真就是完全不要动脑子，直接拆开就行了。\n小结Lab8 也相当的简单，就是让你细化锁的粒度。但是吧，这种单独拆分完全没有啥技术含量啊，毕竟前人已经把大粒度的实现了，你要做的只是拆分，都不需要理解原理什么的……不过虽然实验简单，但在实际中锁的粒度却很难把控，尤其是当锁的数量增多时，可能会导致死锁等问题。我们在实验中只需要考虑简单的锁顺序和避免死锁，但在实际中可能会遇到更复杂的情况，需要更深入的思考和设计。\n无论如何，锁还是一个相当实用的工具，能够有效地解决并发问题。如果要自己设计，想必也会相当麻烦。\n最后照例附上通关截图：\n\n  \n  图一：通关截图\n\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","自旋锁","睡眠锁"]},{"title":"MIT-6-S081总结","url":"/2025/05/06/MIT-6-S081%E6%80%BB%E7%BB%93/","content":"6.S081 是麻省理工 2020 年秋季的操作系统课程，它包括 11 个实验以及若干公开课，是一门非常合适的操作系统入门课程。通过公开课对 XV6 架构的讲解以及手册、源码的阅读，加上高质量的实验，能让小白比较轻松地理解操作系统。这篇 blog 作为我学习课程的总结，整理了我个人的笔记和比较好用的一些参考资料，如果有有缘人看到可供参考。代码其实传到了 github 上面，但好像 MIT 的老师不喜欢这种公开实验代码我也就懒得公开了。（反正也不会有人看到的是吧）\n课程资源时间表及课程资料：https://pdos.csail.mit.edu/6.S081/2020/schedule.html课程中文翻译：https://www.bilibili.com/video/BV1rS4y1n7y1挺好用的民间资料翻译：https://xv6.dgs.zone/csdiy：https://csdiy.wiki/操作系统/MIT6.S081/#_4\n参考博客我参考的一般是这两个星遥见：https://www.cnblogs.com/weijunji/tag/XV6/BambooWine：https://zhuanlan.zhihu.com/p/686681660\nLab 指引\nLab0 - Preperation before experiment｜实验前准备目标简述：配置环境，拉取实验代码。博客链接：MIT-6-S081-Lab0：实验环境配置\n\nLab1 - Unix utilities｜Unix 实用工具目标简述：实现几个用户态程序及 Unix 实用工具，尝试在 XV6 环境下进行开发，熟悉系统调用的接口，难度不大，主要是熟悉环境。博客链接：MIT-6-S081-Lab1：XV6-and-Unix-utilities\n\nLab2 - System calls｜系统调用目标简述：添加几个简单的系统调用以及对系统调用进行追踪，难度一般，帮助熟悉系统调用的流程。博客链接：MIT-6-S081-Lab2：System-call\n\nLab3 - Page tables｜页表目标简述：探索页表机制，为每个进程维护独立的内核页表，并通过页表修改简化用户态向内核态的数据拷贝过程，难度很大，属于是“三集定律”了，要有耐心。博客链接：MIT-6-S081-Lab3：Page-tables\n\nLab4 - Traps｜中断陷阱目标简述：理解用户空间结构（尤其是栈帧），掌握定时器中断等中断处理。难度一般，关键是看对相关概念的理解程度。博客链接：MIT-6-S081-Lab4：Traps\n\nLab5 - Lazy allocation｜内存页懒分配目标简述：实现内存页的懒分配机制，仅在内存访问触发缺页异常时才进行实际分配，从而提升内存使用效率，难度不大，细节挺多，甚至有三段提示。博客链接：MIT-6-S081-Lab5：XV6-lazy-page-allocation\n\nLab6 - Copy-on-write fork｜fork 懒拷贝目标简述：实现写时复制机制，让子进程与父进程共享物理内存页，但在写操作时再进行实际复制，难度一般，跟着提示应该挺顺利的。博客链接：MIT-6-S081-Lab6：Copy-on-Write-Fork-for-XV6\n\nLab7 - Multithreading｜多线程目标简述：实现用户态线程库，使用多线程提升程序性能，以及实现线程同步屏障。难度不大，如果对进程切换比较熟悉会相当轻松。博客链接：MIT-6-S081-Lab7：Multithreading\n\nLab8 - Parallelism/Locking｜并发与锁目标简述：细化锁的粒度。难度很小，虽然看着挺麻烦，不过其实挺无脑的，毕竟只是细化不是设计。博客链接：MIT-6-S081-Lab8：Locks\n\nLab9 - File System｜文件系统目标简述：扩展 XV6 文件系统，使得支持大文件与符号链接功能。难度比较大，细节挺多的。博客链接：MIT-6-S081-Lab9：File-system\n\nLab10 - Mmap｜文件内存映射目标简述：实现简化版的 mmap 系统调用，将文件映射到用户空间，并支持将修改写回磁盘。难度很大，我感觉跟 Lab3 差不多，不过可能是大家到这里都还比较老练了体感没那么刻骨铭心。博客链接：MIT-6-S081-Lab10：Mmap\n\nLab11 - Network stack | 网络栈目标简述：我猜是实现网络栈。博客链接：咕咕咕？\n\n\n总结从 2025/2/27 到 2025/5/6，大概经过了两个多月，终于也是把 6.s081 的主体内容给学了一遍。这门课体验实在是相当好啊，Lab设计得很精妙，还有多样的测试集，比如 mmap 中就帮我找到了缺页异常中的处理缺失，如果可以的话非常推荐对操作系统感兴趣的人来学一学。gpt 还给我做了张通关截图，你别说还不错啊~\n\n  \n  最终通关截图\n\n\n封面插画来自于海怪平老师。\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081"]},{"title":"PS版权警告解决方案","url":"/2025/04/22/PS%E7%89%88%E6%9D%83%E8%AD%A6%E5%91%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"\n本文所述内容仅用于学术研究和网络协议分析之目的。所有操作和技术实现都旨在增加对网络协议、流量管理和相关技术的理解，且不应被用于任何非法或未经授权的行为。使用本文中提到的技术和方法，用户需遵守所在地区的相关法律法规，并对使用结果承担全部责任。本文中的任何技术或方法均不针对特定用户或设备，而是作为网络研究的一部分进行展示。\n\n拦截 PS 流量的方法可以从两大类角度进行：设置防火墙的出入站规则和使用网络代理工具拦截流量。以下是详细的总结：\n一、设置防火墙出入站规则通过配置防火墙的出入站规则，可以有效地阻止不需要的流量。常见的防火墙配置方法包括：\n\n出站规则：控制从内部网络发出的流量。例如，禁止 Photoshop 连接到 Adobe 的服务器，防止自动更新或未经授权的网络访问。\n\n入站规则：可以阻止外部对Photoshop相关服务的访问，或者防止Photoshop连接到外部恶意站点。\n\n配置流程：\n\nWindows防火墙：在 Windows 安全中心-防火墙和网络保护-高级设置里，添加出入站规则，在“程序”中选中 PS.exe 的位置，阻止其网络连接。\nLinux防火墙（iptables）：通过命令行设置规则，来拦截Photoshop相关的流量。iptables -A INPUT -s &lt;Adobe服务器的IP地址&gt; -j DROP   # 禁止Photoshop连接Adobe服务器iptables -A OUTPUT -d &lt;Adobe服务器的IP地址&gt; -j REJECT  # 禁止Photoshop发送请求到Adobe服务器\n\n\n\n\n二、通过网络代理解决流量拦截（以Clash为例）在许多情况下，我们需要使用网络代理工具，那么我们也要拦截代理的流量。\n\n打开配置规则：在“配置”里右键点击你的代理，点击“编辑”进行规则配置\n\n（可选）选择代理我们可以在 Proxies 里面新增一个专门过 Adobe 的代理，在 proxies 里面选择想用的节点。\n- &#123; name: AdobeProxy, type: select, proxies: [&#x27;日本01 -NF/GPT&#x27;]&#125;\n这里因为我们是要拦截，所以不需要选择代理。\n\n配置规则：配置中可以使用多种规则，如 DOMAIN-SUFFIX, DOMAIN-KEYWORD 等，来精确控制拦截的流量。拦截规则根据代理的不同有所差别，需要根据自己的代理进行合适的调整。\n\nDOMAIN-SUFFIX：根据域名后缀进行拦截，如 .com、.org 等。\nDOMAIN-KEYWORD：根据域名中的关键词进行拦截，如拦截包含 adobe 字样的域名。\n示例配置： rules:- &quot;DOMAIN-KEYWORD, adobe, REJECT&quot;    # 拦截所有包含 &#x27;adobe&#x27; 的域名- &quot;DOMAIN-SUFFIX, adobe.com, REJECT&quot; # 拦截所有访问 adobe.com 的请求\n注意：yaml是按顺序匹配的，有可能你的代理之前就设置了adobe相关的规则，不要忘了搜索一下进行同样的拦截。\n\n\n匹配解析器你可能还会发现如果代理进行更新，那么你的配置文件会被覆盖，这个问题相当难解决。一个思路是利用 proxy_providers ，这种方法需要自己写配置文件，然后找自己的代理的更新 yaml 配置文件的 url，挂载到自己的配置文件里面即可。但是，并不是所有的代理都会提供有 yaml 文件的 url，一个比较通用的解法是利用“配置文件预处理”，匹配所有配置文件后，添加 yaml 文件要插入的规则。\nparsers: # array - reg: ^.*$   yaml:     # 添加规则     prepend-rules: # 规则由上往下遍历，如上面规则已经命中，则不再往下处理       - &quot;DOMAIN-KEYWORD, adobe, REJECT&quot;          # 拦截所有包含 &#x27;adobe&#x27; 的域名       - &quot;DOMAIN-SUFFIX, adobe.com, REJECT&quot;       # 拦截所有访问 adobe.com 的请求\n流量拦截和日志查看：\n在 Clash 的日志中可以看到拦截到的流量。例如，当访问包含 adobe.com 的流量被拦截时，日志中会记录 REJECT 的信息，表示该请求被拒绝：[TCP] connectedcc-cdn.adobe.com:443FROM -- 127.0.0.1:51885 RULE -- DOMAIN-SUFFIX(adobe.com) PROXY -- REJECT\n通过这种方式，Clash不仅能够实现拦截流量，还能通过代理分流，让合规的流量走代理，其他流量被拒绝或处理，从而实现对不同流量的灵活管理。\n\n\n\n总结\n防火墙主要通过控制进出网络的流量来进行拦截。通过配置出入站规则，可以精准地拦截特定的IP、域名或端口流量。\nClash和类似的网络代理工具，通过自定义规则（如 DOMAIN-SUFFIX 和 DOMAIN-KEYWORD）来拦截特定的网络流量。这种方法更加灵活，可以根据流量的特征（如域名、关键词等）进行精细化拦截。\n\n","categories":["DEBUG"],"tags":["DEBUG","网络","PS","绘画"]},{"title":"MIT-6-S081-Lab9：File system","url":"/2025/04/29/MIT-6-S081-Lab9%EF%BC%9AFile-system/","content":"知识点在前面的章节中，我们已经学习了地址空间管理、系统调用机制、中断处理、内核同步与进程调度等操作系统的关键组成部分。这些机制相互协作，为用户程序提供了稳定且高效的运行环境。接下来我们要学习 XV6 的文件系统，它构建在前述所有机制之上，是操作系统最复杂且最贴近用户的一项核心服务。\n文件系统的主要目的是组织和存储数据，同时支持用户和应用程序之间的数据共享，并确保数据在系统重新启动后仍然可用（即持久性）。\nXV6 提供了一个简化但完整的文件系统，具备与 Unix 类似的文件、目录和路径名机制。它通过 virtio 磁盘实现数据的持久化，并在此基础上解决了多个核心问题：\n\n数据结构管理：文件系统在磁盘上维护一组数据结构，用于表示命名的目录树和文件树，记录每个文件所占用的磁盘块，以及标记哪些磁盘块是空闲的。\n\n崩溃恢复（Crash Recovery）：系统可能在写入过程中突然崩溃（例如电源故障），这可能导致磁盘上的数据结构处于不一致状态（例如，一个块被某个文件使用，但同时仍被标记为空闲）。因此，文件系统必须设计机制，在系统重启后仍能恢复到一致、可用的状态。\n\n并发访问：多个进程可能同时读写文件，文件系统代码必须使用合适的同步机制，保持系统不变量，确保数据的正确性和一致性。\n\n缓存机制：由于磁盘的访问速度比内存慢得多，为了提高性能，文件系统会在内存中维护一个块缓存（block cache），用于加速对常用数据的访问。\n\n\n通过学习这一部分内容，我们将了解 XV6 如何将前面章节介绍的陷阱、中断、锁、调度等机制结合起来，构建出一个稳定、高效且具备持久化能力的文件系统。\n概述XV6 文件系统的实现分为7层，如下表所示：\n\n  \n    \n      层级\n      概念\n    \n  \n  \n    \n      应用层\n      文件描述符（File descriptor）\n    \n    \n      用户接口\n      路径名（Pathname）\n    \n    \n      命名结构\n      目录（Directory）\n    \n    \n      文件存储结构\n      索引结点（Inode）\n    \n    \n      缓存管理\n      缓冲区高速缓存（Buffer cache）\n    \n    \n    \n      一致性保障\n      日志（Logging）\n    \n      底层存储\n      磁盘（Disk）\n    \n  \n\n\n文件系统的各层自底向上协同工作，构建出完整的抽象。最底层是磁盘层，负责读取和写入 virtio 硬盘上的块。其上是缓冲区高速缓存层，用于缓存磁盘块，并通过锁机制同步访问，确保同一时刻只有一个内核进程能够修改某个块的数据。日志层为更高层提供了事务支持：它允许将多个块的更新封装成一次原子操作，在系统崩溃时能确保要么所有修改都完成，要么全部不生效。索引结点层（inode）提供对单个文件的抽象，每个文件由一个 inode 表示，包含唯一编号（i-number）和指向数据块的指针。目录层在 inode 之上，将目录实现为一种特殊的文件，其内容是若干目录项（包含文件名与对应 inode 编号）。路径名层支持分层路径解析，例如 /usr/rtm/XV6/fs.c，通过递归查找目录项逐步解析路径。最上层是文件描述符层，它将各种 Unix 资源（如文件、设备、管道等）统一抽象为文件描述符，极大简化了用户程序对资源的访问方式。\n磁盘层XV6 将磁盘划分为若干区域，如图所示。块 0 不被文件系统使用，它存放的是引导扇区。块 1 是超级块，包含文件系统的元数据，如文件系统的总大小（以块为单位）、数据块的数量、索引节点（inode）的数量以及日志所占的块数。紧随其后的是日志区域，从块 2 开始，用于支持崩溃恢复。日志之后是索引节点区，每个块存放多个 inode，用于描述文件。再往后是位图区域，用于记录哪些数据块正在被使用。剩余的部分是数据块区域：每个块要么被标记为空闲（由位图决定），要么用于存储文件或目录的内容。超级块由一个名为 mkfs 的独立程序初始化，它负责构建初始的文件系统结构。\n\n  \n  图一：磁盘划分\n\n\n缓冲区高速缓存层Buffer cache（缓冲区高速缓存） 在 XV6 中承担两个主要职责：\n\n同步磁盘块的访问：确保每个磁盘块在内存中始终只有一个副本，且任何时刻只有一个内核线程可以访问该副本；\n缓存常用块：避免频繁从慢速磁盘读取，提高文件系统性能。\n\n其核心代码位于 bio.c 中。\nBuffer cache 层提供的主要接口包括：\n\nbread：从磁盘读取一个块并返回其内存副本（struct buf），该副本会被上锁以供当前线程独占访问；\nbwrite：将修改后的内存副本写回磁盘；\nbrelse：释放缓冲区并解除锁定，使其可供其他线程使用。\n\n每个缓冲区都使用一个睡眠锁来保证互斥访问：bread 返回的是已加锁的缓冲区，而 brelse 负责释放该锁。\n值得注意的是，Buffer cache 中缓冲区的数量是固定的。这意味着当请求一个当前不在缓存中的块时，系统必须回收一个已有的缓冲区来腾出空间。Buffer cache 使用最近最少使用（LRU）策略进行回收：选择最久未被使用的缓冲区，因为这些块最不可能在短时间内再次被访问。\n为了实现 LRU，我们会选择维护一个双向链表。初始时，main 函数调用 binit 函数，使用静态数组 buf[] 中的 NBUF 个缓冲区来初始化链表。之后，对缓冲区的所有访问都通过 bcache.head 引用链表，而不是直接引用 buf[] 数组。\n每个缓冲区都有两个重要的状态标志：valid 和 disk。\n\nvalid 表示缓冲区中是否存储了有效的数据；\ndisk 表示缓冲区与磁盘的数据是否同步。\n\nbread 通过调用 bget 获取指定扇区对应的缓冲区。如果该缓冲区尚未从磁盘读取，bread 会在返回之前调用 virtio_disk_rw 将数据从磁盘读入缓冲区。\nbget 会扫描缓冲区链表，它只负责查找与指定设备和扇区号匹配的缓冲区。如果找到了，bget 会获取该缓冲区的睡眠锁，并返回已加锁的缓冲区。\n如果缓冲区中不存在指定扇区，bget 必须创建一个新的缓冲区副本，这可能需要重用当前用于其他扇区的缓冲区。它会再次扫描缓冲区链表，查找未被使用的缓冲区（即 b-&gt;refcnt == 0），这些缓冲区都可以被重用。bget 会更新缓冲区的元数据以记录新的设备号和扇区号，并获取该缓冲区的睡眠锁。注意，读取数据前，bget 会将 b-&gt;valid 设为 0 来确保 bread 会从磁盘重新读取块数据，而不会错误地使用缓冲区中旧的内容。\n缓冲区的锁非常特别，它不需要调用者显式加锁，一次只允许一个持有者，强力保障一致性，适用于低级资源。在保证每个磁盘扇区最多只有一个缓冲区的前提下，文件系统通过缓冲区上的锁实现同步，二者共同确保了读取操作能够看到最新的写入结果。bget 在整个过程中——从第一次循环检查目标块是否已被缓存，到第二次循环选择一个空闲缓冲区并设置其 dev、blockno 和 refcnt 等字段——始终持有 bcache.lock，以确保扇区对应至多一个缓冲区这一不变量的成立。这使得检查和分配缓冲区这两个操作具有原子性，避免竞态条件的发生。\nbget 在 bcache.lock 的临界区之外获取缓冲区的睡眠锁是安全的，因为非零的 b-&gt;refcnt 会阻止该缓冲区在此期间被重新用于其他磁盘块。注意，睡眠锁用于保护对单个块缓冲区中数据的读取和写入，确保同一时间只有一个线程可以访问该缓冲区的内容。而 bcache.lock 则用于保护整个缓冲区缓存系统的元数据，包括当前缓存了哪些磁盘块、这些缓冲区是否正在被使用等信息。（当然明显这个锁的粒度可以细化，我们在Lab8中已经做过类似的优化。）\n如果所有缓冲区都正忙于被其他进程使用，说明同时执行文件系统调用的进程太多，bget 会触发 panic。尽管一个更合适的做法是让进程等待直到某个缓冲区变为空闲，但这种方式可能引入死锁的风险，因此 XV6 选择了更保守的处理方式。\n一旦 bread（在需要时）从磁盘读取数据并返回缓冲区，调用者就可以独占地使用该缓冲区，读取或修改其中的数据字节。如果调用者对缓冲区内容进行了修改，则必须在释放缓冲区之前调用 bwrite，将更改写回磁盘。bwrite 最终调用 virtio_disk_rw 与磁盘硬件进行交互，完成数据写入操作。\n当调用方使用完缓冲区后，必须调用 brelse 来释放缓冲区。brelse 会释放缓冲区的睡眠锁，并将该缓冲区移动到链表的前端。这样的移动操作会根据使用频率对缓冲区列表进行排序：链表前端的缓冲区是最近被使用过的，而末尾的是最久未使用的。bget 中的两个循环正是利用了这一策略：尽管在最坏情况下可能需要遍历整个链表来查找目标缓冲区，但它会优先检查最近使用的缓冲区（从 bcache.head 开始，沿 next 指针向后扫描），在访问局部性良好的场景中，这有助于减少遍历时间。而在选择要重用的缓冲区时，bget 会从链表末尾开始，沿 prev 指针向前查找，从而优先选择最近最少使用的缓冲区进行回收。\n日志层文件系统设计中最具挑战性的问题之一是崩溃恢复。这个问题的根源在于，许多文件系统操作需要多次写入磁盘，如果在部分写入完成后系统崩溃，可能会导致磁盘上的文件系统处于不一致状态。例如，考虑在截断一个文件（将其长度设为零并释放其内容块）过程中发生崩溃：根据写入磁盘的顺序，崩溃可能会导致索引节点仍然指向已被标记为空闲的内容块，或者产生一些已分配但未被引用的内容块。\nXV6 通过一种简单的日志机制来解决文件系统操作中的崩溃问题。XV6 的系统调用不会直接将更改写入磁盘上的文件系统数据结构；相反，它会先将所有计划执行的磁盘写入操作记录到磁盘上的日志中（log）。当系统调用记录了它的所有写入操作，它就会在日志中写入一条特殊的提交记录（commit），表示日志中的内容构成一个完整的文件系统操作。随后，系统调用才将这些修改实际写入文件系统对应的数据结构。完成写入后，系统调用会清除磁盘上的日志。\n如果系统崩溃并重新启动，文件系统会在运行任何进程之前执行恢复操作。恢复过程会首先检查日志是否被标记为包含一个完整的操作（即是否存在提交记录）。如果日志是完整的，恢复代码会将日志中记录的所有写操作复制到磁盘上的文件系统相应位置，完成操作的恢复。如果日志不完整（即缺少提交记录），则说明该操作未完成，恢复过程会忽略日志内容，不执行任何写入。最后，无论日志是否被应用，恢复代码都会擦除日志，确保其处于干净状态。通过日志，我们可以使操作在崩溃时成为原子操作。本质上是对一系列写入操作进行“压缩”和“包装”，以实现原子性和崩溃恢复。\n日志被保存在超级块指定的固定位置上，包含一个头块（header block）和若干数据块副本（logged blocks）。头块记录了一个扇区号数组，每个扇区号对应一个 logged block，同时还包含一个计数字段，表示日志中记录的块数。如果计数为零，表示当前没有活动事务；如果非零，则说明日志中包含一个完整且已提交的事务，记录了指定数量的块。只有在系统调用提交事务时（commit），XV6 才会将信息写入头块，在这之前头块保持为空。事务提交后，XV6 会将日志中的数据块复制到文件系统的目标位置，并将头块中的计数清零，从而表示事务已经完成。\n因此，如果系统在事务提交前崩溃，日志头块的计数仍为零，表示没有有效事务；如果系统在提交后崩溃，则计数为非零，说明日志包含一个需要恢复的完整事务。\n每个系统调用的代码都会标记其写入操作的开始和结束。为了应对系统崩溃，这些写入必须具有原子性。为了支持多个进程并发执行文件系统操作，日志系统允许将多个系统调用的写入累积到同一个事务中。因此，一次提交可能包含多个完整系统调用的写入。为了防止将单个系统调用的写操作拆分到多个事务中，从而导致部分操作成功、部分操作失败、进而破坏文件系统的一致性，日志系统仅在没有系统调用正在进行时才执行提交操作。\n同时提交多个事务的技术被称为组提交（group commit）。组提交通过将多个操作合并为一次提交，减少了磁盘操作的次数，从而分摊了固定的提交开销。此外，它还能为磁盘系统提供更多并发的写入请求，有助于在一次磁盘旋转时间内完成多个写操作。尽管 XV6 的 virtio 驱动不支持这种批量处理，XV6 的文件系统设计本身是支持组提交的。\nXV6 在磁盘上预留了固定空间用于存储日志。事务中系统调用所写入的块总数必须能够适应该日志空间。这导致了两个主要后果：首先，任何单个系统调用的写入操作不能超过日志空间所能容纳的块数。虽然对于大多数系统调用来说，这通常不成问题，但有两个系统调用可能会写入多个块：write 和 unlink。例如，写入一个大文件时，write 可能会涉及多个数据块、多个位图块以及一个 inode 块；而 unlink 大文件时，可能会修改多个位图块和 inode 块。为了避免这个问题，XV6 的 write 系统调用会将较大的写入操作分解为多个适合日志空间的较小写入。而 unlink 操作则不会导致类似问题，因为 XV6 文件系统只使用一个位图块。日志空间的有限性还意味着，除非能够确定系统调用的写入操作可以完全适应日志中剩余的空间，否则日志系统将不允许启动该系统调用。\n在 XV6 中，一个典型的提交日志场景如下：begin_op();...bp = bread(...);bp-&gt;data[...] = ...;log_write(bp);...end_op();\n这之中，begin_op 会等待，直到日志系统当前没有处于提交状态，并且直到有足够的未被占用的日志空间来容纳此次写入，它会将 log.outstanding 的值增加1。log.outstanding 统计了已预定日志空间的系统调用数量；为这些系统调用保留的总空间为 log.outstanding 乘以 MAXOPBLOCKS。每次递增 log.outstanding 时，都会预定相应的空间，并防止在该系统调用期间发生提交操作。为了保证安全，代码保守地假设每个系统调用最多可能写入 MAXOPBLOCKS 个不同的块。\nlog_write 充当 bwrite 的代理。它将块的扇区号记录在内存中，在磁盘上的日志中预定一个槽位，并调用 bpin 将缓存固定在块缓存（block cache）中，以防止块缓存将其逐出。\n在提交之前，块必须保留在缓存中，因为在提交前，缓存的副本是修改的唯一记录；只有在提交后，修改才会被写入磁盘上的对应位置。同一事务中的其他读取操作必须看到这些修改。log_write 会处理单个事务中多次写入同一块的情况，并在日志中为该块分配相同的槽位，这种优化通常称为合并（absorption）。例如，多个文件 inode 所在的磁盘块在一个事务中可能会被多次写入。通过将多个磁盘写入操作合并为一个，文件系统能够节省日志空间并提升性能，因为只有一个磁盘块副本需要写入磁盘。\nend_op 首先减少未完成系统调用的计数。如果该计数降为零，表明当前没有系统调用正在进行，日志系统才会调用 commit() 提交当前事务。提交过程分为四个阶段：\n\nwrite_log()：将事务中所有被修改的块从缓冲区缓存复制到磁盘上的日志槽位中；\nwrite_head()：将日志头块写入磁盘。这一步是提交点（commit point）：写入之后即使系统崩溃，重启时也会从日志中重放这些写入操作；\ninstall_trans()：将日志中的每个块写入文件系统中它们所属的磁盘位置；\n最后，end_op 将日志头的计数字段写为零。这一步必须发生在下一个事务开始写入日志块之前，以防止系统崩溃后出现使用一个事务的头块和后一个事务的日志块混合进行恢复的情况。\n\n最后来看日志怎么恢复，recover_from_log 由 initlog 调用，而 initlog 又在系统引导阶段由 fsinit 调用，发生在第一个用户进程运行之前。recover_from_log 会读取日志头；如果日志头表明日志中包含一个已提交的事务，它将模拟 end_op 的行为来完成事务提交。\n文件和目录的数据存储在磁盘块中，而这些磁盘块需从空闲块池中分配。XV6 的块分配器通过在磁盘上维护一个空闲位图来管理这一过程。位图中的每一位对应一个磁盘块，值为 0 表示该块空闲，值为 1 表示已被占用。初始化程序 mkfs 会将引导扇区、超级块、日志块、inode 块和位图块对应的位设置为 1，表示这些块已使用。\n块分配器提供两个核心功能：\n\nballoc 用于分配新磁盘块；\nbfree 用于释放已占用的块。\n\nballoc 的实现中使用了一个双重循环，从块号 0 到 sb.size（文件系统总块数）依次检查每个块是否空闲。外部循环遍历位图的每个块，内部循环检查该位图块中所有 BPB 位（每个位表示一个数据块）。如果找到空闲块，balloc 会设置对应位为 1 并返回该块号。\n由于任何时刻，一个位图块在缓冲区缓存中只能被一个进程独占使用，因此两个进程并发分配块时可能会出现争用，但通过 bread 和 brelse 隐式地实现了互斥，无需额外锁机制。\nbfree 的实现与之类似，它定位对应的位图块并将目标位清零，以标记该块为空闲。需要注意的是，和本章大多数文件系统相关操作一样，balloc 和 bfree 必须在日志事务内部调用，以确保崩溃时的一致性恢复。\n索引节点层磁盘上的索引节点（inode）被组织在一个称为“inode块”的连续磁盘区域中。由于每个 inode 大小相同，因此可以轻松地根据一个编号 $n$ 定位磁盘上的第 $n$ 个 inode。这个编号被称为 inode 号（i-number），在实现中用于标识特定的 inode。\n磁盘上的 inode 结构由 struct dinode 定义。其 type 字段用于区分常规文件、目录或特殊文件（如设备文件）；nlink 字段记录有多少目录条目引用该 inode，用于判断何时可以释放该 inode 及其数据块；size 字段表示文件的字节数；addrs 数组存储实际保存文件内容的磁盘块编号。\nXV6 内核在内存中维护一组活跃的 inode，其表示形式为 struct inode，是磁盘中 struct dinode 的内存映像。只有当存在某些 C 指针引用一个 inode 时，内核才会在内存中保存它。ref 字段记录当前有多少 C 指针引用该 inode；当计数归零时，内核会将该 inode 从缓存中清除。iget 和 iput 函数分别用于获取和释放对 inode 的引用，并更新引用计数。\niget 返回的 inode 并不一定包含有效数据。为了确保 inode 包含磁盘中对应数据的副本，必须调用 ilock 来加锁该 inode（防止其他进程同时访问），并在必要时从磁盘读取其内容；iunlock 用于释放该锁。在某些场景中，将 inode 的获取和加锁分离有助于避免死锁，比如在目录查找过程中。尽管多个进程可以同时持有由 iget 返回的 inode 指针，但在任一时刻，最多只有一个进程能够加锁它。\ninode 缓存只缓存当前被内核数据结构引用的 inode，它的主要职责是实现并发访问的同步，缓存效果是次要的。如果 inode 被频繁访问，那么其内容更可能是由缓冲区缓存保存在内存中，而不是 inode 缓存本身。inode 缓存相当重要，因此它采用直写策略（write-through），即一旦修改了缓存中的 inode，必须立即通过 iupdate 写回磁盘。\n下面来看 inode 的具体实现。\n为了分配一个新的 inode（例如在创建文件时），XV6 调用 ialloc。ialloc 的工作方式类似于 balloc：它逐块遍历磁盘上的 inode 结构，查找一个标记为空闲的 inode。当找到一个空闲 inode 后，ialloc 通过将新的 type 写入磁盘，来声明该 inode 已被占用。随后，它调用 iget 将该 inode 加载到缓存中并返回条目。\nialloc 的正确性依赖于这样一个事实：在同一时刻，只有一个进程能访问某个 inode 所在的磁盘块。由于对该块的访问通过缓冲区缓存进行，并且 bread 返回的缓冲区在释放之前具有独占访问权，因此，ialloc 只修改缓冲区而不直接修改 inode。缓冲区和磁盘块会自动加锁，确保在一个进程完成 inode 分配之前，其他进程无法看到该 inode 仍为空闲，从而避免多个进程争用同一个 inode 的情况。\niget 主要在 inode 缓存中查找具有指定设备号和 inode 编号的活动条目（即 ip-&gt;ref 字段大于 0 的 inode）。如果找到，则返回对该 inode 的一个新的引用（增加 ref）。如果在缓存中没有找到指定的 inode，iget 会从磁盘加载该 inode，并将其缓存到 inode 缓存中。此外，iget 在查找过程中还会记录第一个空闲槽位的位置，以便在需要时分配新的缓存项。\n当修改内存中的 inode 元数据时，代码必须使用 ilock 锁定这个 inode，这是因为 inode 的锁相比缓冲区锁更细，我们可以单独锁上一个 inode，而不会自动锁上整个块。因为等待时间相对较长且需要修改共享资源，我们使用睡眠锁。在获取了睡眠锁之后，ilock 会根据需要从缓冲区读取 inode。iunlock 负责释放睡眠锁，它可能唤醒任意睡眠进程。\niput 通过减少引用计数来释放指向 inode 的 C 指针。如果这是最后一次引用，那么 inode 缓存中对应的槽位将变为空闲，可以重用于其他 inode。如果 iput 发现没有任何 C 指针引用指向该 inode，且该 inode 没有任何指向它的链接（如无目录时），则必须释放该 inode 及其数据块。iput 会调用 itrunc 将文件截断为零字节，释放其数据块；同时，将该 inode 的类型设置为 0（表示未分配），并将 inode 写入磁盘。\niput 对 inode 的处理方式值得注意。一个潜在的风险是，其他线程可能正在调用 ilock 等待获取该 inode 的锁，但此时该 inode 已经不再有效。不过这种情况不会发生，因为当 ip-&gt;ref 为 1 且链接数为 0 时，说明当前只有 iput 的线程持有该 inode 的引用，系统中不可能有其他线程能访问到它。虽然 iput 会在不持有 icache.lock 的情况下检查引用计数，但由于此时 inode 的链接数为 0，因此也不可能有新的引用产生。\n另一个风险是并发调用 ialloc 时，可能选择 iput 正在释放的 inode。这只能发生在 iupdate 将 inode 的 type 设置为零之后，但这同样不会引起问题，因为分配线程会等待锁，直到 iput 完成。\niput() 可能会将 inode 写回磁盘，这意味着任何使用文件系统的系统调用都有可能触发磁盘写入。即使是像 read() 这样看似只读的系统调用，也可能在调用 iput() 时释放某个 inode 的最后一个引用，从而导致写操作。因此，凡是涉及文件系统的系统调用，即使逻辑上是只读的，也必须包装在事务中。\niput() 与系统崩溃之间存在一种复杂的交互。在文件不再出现在目录中之后（即不再有路径名指向它），iput() 并不会立刻回收对应的 inode 和数据块。这是因为某些进程可能仍然持有该 inode 的引用，例如文件被打开后，虽然它的目录项被删除，但进程仍在读取或写入该文件。\n如果系统在最后一个进程关闭该文件之前崩溃，该文件的 inode 和数据块就会仍然保留在磁盘上，但却已经无法再通过任何路径访问。这种“孤儿文件”会导致磁盘空间泄漏。\n为了解决这个问题，文件系统通常采取两种策略之一：\n\n扫描恢复：在系统重启时，扫描整个文件系统，查找哪些文件被标记为已分配，但却没有任何目录项引用它们。这些文件将被识别为孤儿文件并被释放。\n\n显式记录：更先进的文件系统在文件变为“不可见”但仍被引用时，会将它们的 inode 编号记录到磁盘上的一个特殊位置（如超级块中的列表）。当该文件最终不再被任何进程引用时，文件系统会将其从这个列表中移除。若系统崩溃，恢复过程只需检查该列表并释放其中的 inode，无需遍历整个磁盘。\n\n\n但是！XV6 两种都没有实现，所以可能会有磁盘空间不足的风险。\n最后再看看 inode 的内部结构。\n磁盘上的 inode 结构体 struct dinode 包含一个 size 字段和一个块号数组 addrs，如下图所示。文件的数据存储在由 addrs 数组指定的数据块中。数组的前 NDIRECT 个元素直接给出了数据块的地址，这些块被称为直接块（direct blocks）。数组的最后一个元素不是数据块地址，而是一个间接块（indirect block）的地址；这个间接块本身是一个数据块，其中存储着更多数据块的地址，总共可容纳 NINDIRECT 个。\n\n  \n  图二：inode结构\n\n\n因此，文件的前 NDIRECT × BSIZE 字节（例如 12 KB）可以通过 inode 直接访问；而接下来的 NINDIRECT × BSIZE 字节（例如 256 KB）则需通过读取间接块来访问。这种分层结构在磁盘上是一种高效的表示方式，但对调用者来说相对复杂。\n为了屏蔽这种复杂性，bmap(struct inode *ip, uint bn) 函数负责解析这种表示。它返回 inode ip 的第 bn 个数据块对应的磁盘块号；如果该数据块尚未分配，bmap 会为其分配一个新块。这为更高级别的函数如 readi 和 writei 提供了简单统一的接口。\nitrunc 释放文件所占用的数据块，并将 inode 的 size 字段重置为 0。它首先释放所有直接块，然后释放间接块中列出的数据块，最后释放间接块本身。\nbmap 简化了 readi 和 writei 访问 inode 数据的过程。\nreadi 首先确保读取的偏移量和字节数不会超过文件末尾：  \n\n若起始偏移量已超过文件大小，则返回错误；  \n若读取从文件末尾开始或跨越文件末尾，则返回的字节数将少于请求的字节数。\n\n接下来的主循环逐块读取文件内容，并将数据从缓冲区复制到目标地址 dst。\nwritei 与 readi 的结构类似，但有三处不同：  \n\n从文件末尾开始或穿越文件末尾的写操作会增长文件，最多到达最大文件大小；  \n它将数据复制到缓冲区而非从缓冲区读取；  \n如果写操作扩展了文件，writei 需要更新 inode 的大小字段。\n\nreadi 和 writei 都从检查 ip-&gt;type == T_DEV 开始。这一分支处理特殊设备类型，它们的数据并不位于文件系统中——后续在文件描述符层会进一步解释这种情况。\n最后，stati 函数会将 inode 的元数据复制到一个 stat 结构体中，以通过 stat 系统调用提供给用户程序。\n目录层目录其实就是一个特殊的文件，其 inode 的 type 为 T_DIR，其数据是一系列目录条目（directory entries）。目录中的每个条目（entry）是一个 struct dirent，包含两个字段：名称 name 和 inode 编号 inum。名称的最大长度为 DIRSIZ（14）个字符；若名称不足 14 字节，则以 NUL（0）字节终止。若 inum 为 0，则表示该条目为空。\n函数 dirlookup 在目录 inode 中查找具有指定名称的目录项。如果找到，它会返回一个通过 iget 获取的指向对应 inode 的指针，并将目录项在目录中的字节偏移量写入 *poff，以供调用者在需要修改该目录项时使用。\n值得注意的是，dirlookup 返回的 inode 是未加锁的。这是为了避免死锁：调用者在调用 dirlookup 前通常已持有目录 inode dp 的锁。如果查找的是 .（当前目录的别名），则 iget 返回的 inode 与 dp 相同；此时若 dirlookup 尝试再次加锁，就会导致对同一 inode 的重复加锁，从而引发死锁。类似的问题也可能出现在更复杂的情况中，例如涉及多个进程或目录项为 ..（父目录的别名）时。因此，dirlookup 的设计是在返回目标 inode 时不加锁，交由调用者在解锁 dp 后再去锁定目标 inode，从而确保整个过程中始终只持有一个锁，避免死锁风险。\n函数 dirlink 会将给定的名称和 inode 编号写入目录 dp，创建一个新的目录项。如果该名称已在目录中存在，dirlink 会返回错误。它的主循环遍历目录中的所有条目，查找一个未被使用的条目（即 inum == 0）。如果找到，循环会提前退出，并将 off 设置为这个空闲条目的偏移量；如果没有找到，off 则被设置为目录末尾（dp-&gt;size），意味着将在目录尾部添加新条目。最后，dirlink 会在 off 指定的位置写入新的目录项，实现目录更新。\n路径名层路径名查找涉及对 dirlookup 的一系列调用，每个路径组件对应一次调用。函数 namei 解析整个路径并返回对应的 inode，而其变体 nameiparent 则在路径的最后一个元素之前停止，返回父目录的 inode，并将最后一个路径组件复制到 name 中。这两个函数都调用一个通用的内部函数 namex 来完成具体的路径解析逻辑。\nnamex 首先确定路径解析的起始位置：如果路径以斜线 / 开头，则从根目录开始；否则从当前目录开始。接着，它通过 skipelem 函数逐个提取路径中的元素，并在一个循环中依次处理这些元素。\n每次迭代中，namex 都会锁定当前 inode ip，并检查它是否是一个目录；如果不是，则查找失败（锁定是必要的，不是因为 ip-&gt;type 可能被更改，而是因为在 ilock 之前无法保证从磁盘中加载了该字段的值）。\n如果调用的是 nameiparent，并且当前路径元素是最后一个，则根据其语义应提前停止。此时，最后一个路径元素已经被复制到 name 中，namex 只需解锁 ip 并返回它。\n否则，循环使用 dirlookup 查找当前路径元素，并将返回的 inode 赋给 ip 以进行下一次迭代。当路径中的所有元素都处理完毕时，namex 返回最终的 ip。\n文件描述符层Unix 通过文件描述符层将控制台、管道等设备以及真实文件都表示为文件。XV6 为每个进程提供了独立的文件描述符。每个打开的文件由 struct file 表示，它是 inode 或管道的封装，并包含一个 I/O 偏移量。每次调用 open 都会创建一个新的 struct file 实例；如果多个进程独立打开同一个文件，那么每个实例将拥有不同的 I/O 偏移量。另一方面，同一个文件（同一个 struct file）可以出现在同一进程的多个文件表中，或者出现在多个进程的文件表中。如果进程通过 open 打开文件，然后使用 dup 创建别名，或者通过 fork 与子进程共享文件，则会发生这种情况。引用计数用于跟踪某个文件被引用的次数。文件可以同时进行读取和写入，readable 和 writable 字段用来跟踪文件的操作状态。\n系统中所有打开的文件都保存在全局文件表 ftable 中。文件表提供了用于分配文件（filealloc）、创建重复引用（filedup）、释放引用（fileclose）以及读取和写入数据（fileread 和 filewrite）的函数。\n前三个函数遵循了我们熟悉的模式。filealloc 扫描文件表以查找未被引用的文件（f-&gt;ref == 0），并返回一个新的引用；filedup 增加引用计数；fileclose 则递减引用计数，当文件的引用计数降为零时，fileclose 会释放底层的管道或 inode。\n函数 filestat、fileread 和 filewrite 实现了对文件的 stat、read 和 write 操作。filestat() 仅允许对 inode 操作，并调用了 stati；fileread 和 filewrite 会检查文件的打开模式是否允许该操作，然后将调用传递给管道或 inode 的实现。如果文件表示为 inode，fileread 和 filewrite 会使用 I/O 偏移量作为操作的偏移量，并将文件指针前移该偏移量（对于管道来说，不存在偏移的概念）。需要注意的是，inode 的函数要求调用方处理锁，inode 锁定的一个方便副作用是可以原子地更新读取和写入的偏移量，因此对同一文件的多次同时写入不会互相覆盖，尽管这些写入最终可能会交错。\n系统调用大多数文件系统的系统调用都比较简单，但其中有几个值得分析一下，比如 link 和 unlink。sys_link 和 sys_unlink 通过编辑目录项来创建或删除对 inode 的引用，他们的实现都在日志的帮助下得以简化。\nsys_link 首先获取其参数，即旧路径和新路径两个字符串。如果旧路径对应的文件存在且不是目录，sys_link 会递增该 inode 的 nlink 计数。随后，sys_link 使用 nameiparent 查找新路径的父目录以及最终路径名，并在该目录中创建一个指向旧 inode 的新目录项。注意，新目录必须已经存在，且该目录与旧 inode 必须位于同一设备上，因为 inode 编号只在单个磁盘内部具有唯一性。\n事务机制简化了这一实现过程：尽管此操作需要更新多个磁盘块，但我们无需担心它们的执行顺序。要么所有更新都成功提交，要么全部回滚。例如，如果没有事务机制，在创建链接之前更新 ip-&gt;nlink 会使文件系统短暂地处于不一致状态，此时如果系统崩溃，可能会导致文件系统损坏。而在事务机制下，我们无需担心此类问题。\n实验内容Large files(moderate)第一个实验是增加大文件的大小，如果理解了 inode 的结构跟 bmap 的作用就是一个常规的拓展而已。\n我们先修改 inode 和 dinode 的结构，使得它们支持二级块。#define NDIRECT 11#define NINDIRECT (BSIZE / sizeof(uint))#define NININDIRECT NINDIRECT * NINDIRECT#define MAXFILE (NDIRECT + NINDIRECT + NININDIRECT)struct dinode &#123;  short type;           // File type  short major;          // Major device number (T_DEVICE only)  short minor;          // Minor device number (T_DEVICE only)  short nlink;          // Number of links to inode in file system  uint size;            // Size of file (bytes)  uint addrs[NDIRECT+2];   // Data block addresses&#125;;struct inode &#123;  uint dev;           // Device number  uint inum;          // Inode number  int ref;            // Reference count  struct sleeplock lock; // protects everything below here  int valid;          // inode has been read from disk?  short type;         // copy of disk inode  short major;  short minor;  short nlink;  uint size;  uint addrs[NDIRECT + 2];&#125;;\n然后修改 bmap，一个小坑是一级目录也要分配块、写入日志、释放块，不然修改不会保存。static uintbmap(struct inode *ip, uint bn)&#123;  uint addr, *a, *a2;  struct buf *bp, *bp2;  ···  bn -= NINDIRECT;  if(bn &lt; NININDIRECT)  &#123;    if((addr = ip-&gt;addrs[NDIRECT + 1]) == 0)      ip-&gt;addrs[NDIRECT + 1] = addr = balloc(ip-&gt;dev);    bp = bread(ip-&gt;dev, addr);    a = (uint*)bp-&gt;data;    if((addr = a[bn / NINDIRECT]) == 0)    &#123;      a[bn / NINDIRECT] = addr = balloc(ip-&gt;dev);      log_write(bp);    &#125;    brelse(bp);    bp2 = bread(ip-&gt;dev, addr);    a2 = (uint*)bp2-&gt;data;    if((addr = a2[bn % NINDIRECT]) == 0)    &#123;      a2[bn % NINDIRECT] = addr = balloc(ip-&gt;dev);      log_write(bp2);    &#125;    brelse(bp2);    return addr;  &#125;  panic(&quot;bmap: out of range&quot;);&#125;最后修改 itrunc 函数，在清空的时候也要注意一级块的修改。voiditrunc(struct inode *ip)&#123;  int i, j;  struct buf *bp, *bp2;  uint *a, *a2;  ···  if(ip-&gt;addrs[NDIRECT + 1])&#123;    bp = bread(ip-&gt;dev, ip-&gt;addrs[NDIRECT + 1]);    a = (uint*)bp-&gt;data;    for(j = 0; j &lt; NINDIRECT; j++)    &#123;      if(a[j])      &#123;        bp2 = bread(ip-&gt;dev, a[j]);        a2 = (uint*)bp2-&gt;data;        for(i = 0; i &lt; NINDIRECT; i++)        &#123;          if(a2[i])            bfree(ip-&gt;dev, a2[i]);        &#125;        brelse(bp2);        bfree(ip-&gt;dev, a[j]);      &#125;    &#125;    brelse(bp);    bfree(ip-&gt;dev, ip-&gt;addrs[NDIRECT + 1]);    ip-&gt;addrs[NDIRECT + 1] = 0;  &#125;  ip-&gt;size = 0;  iupdate(ip);&#125;\n出现下图测试结果说明正确。\n\n  \n  图三：大文件测试\n\n\nSymbolic links(moderate)这个实验要我们实现符号链接，也就是软链接。它实际上不是数据的副本，而是对另一个路径的引用。相比于硬链接，它可以跨文件系统使用，可以指向目录，甚至可以指向不存在的目标，灵活性很高。而且依托于硬链接，它的实现也简单得多。尽管可能有悬挂链接等问题，开销也更大，但在实现重定向、快捷方式和抽象路径层等时非常方便。\n首先我们要向 kernel/stat.h 添加新的文件类型（T_SYMLINK）以表示符号链接。\n#define T_SYMLINK 4   // Symbol link\n然后在 kernel/fcntl.h 中添加一个用于 open 系统调用的新标志（O_NOFOLLOW）。\n#define T_SYMLINK 4   // Symbolic link\n添加系统调用过程不再赘述，我们重点来看函数内容和 sys_open 的修改。\n这个函数其实就是将路径写入目标位置的文件，在进行 open 调用的时候再解析。先判断目标位置有没有符号链接，如果有就直接返回，否则先用 create 函数创建一个文件，再用 writei 函数将路径写入。最后要记得解锁和解除引用，还要提交日志。\nuint64sys_symlink(void)&#123;  char target[MAXPATH], path[MAXPATH];  struct inode *ip;  if(argstr(0, target, MAXPATH) &lt; 0 || argstr(1, path, MAXPATH) &lt; 0)    return -1;  begin_op();    if((ip = namei(path)) != 0)&#123;    end_op();    return -1;  &#125;  if((ip = create(path, T_SYMLINK, 0, 0)) == 0)&#123;    end_op();    return -1;  &#125;  if(writei(ip, 0, (uint64)target, 0, strlen(target)) != strlen(target))&#123;    iunlockput(ip);    end_op();    return -1;  &#125;  iunlockput(ip);  end_op();  return 0;&#125;\n然后修改 open 调用时的解析逻辑。在打开符号链接且需要跟随时，我们先用 readi 读取文件内容，然后调用 namei 进行解析。但是，因为目标文件也可能是符号链接，所以我们需要循环解析下去，为了防止无限循环，我们在超过10次读取之后就强行中止。\nuint64sys_open(void)&#123;  char path[MAXPATH];  int fd, omode;  struct file *f;  struct inode *ip;  int n;  // ...  begin_op();  if(omode &amp; O_CREATE)&#123;    // ...  &#125;  int depth = 0;  while(ip-&gt;type == T_SYMLINK &amp;&amp; (omode &amp; O_NOFOLLOW) == 0)  &#123;    char target[MAXPATH];    if(readi(ip, 0, (uint64)target, 0, sizeof(target)) &lt; 0)    &#123;      iunlockput(ip);      end_op();      return -1;    &#125;    iunlockput(ip);        if((ip = namei(target)) == 0)    &#123;      end_op();      return -1;    &#125;    ilock(ip);    depth++;    if(depth &gt; 10)    &#123;      iunlockput(ip);      end_op();      return -1;    &#125;  &#125;  // ...  iunlock(ip);  end_op();  return fd;&#125;\n至此我们就实现了符号链接。\n小结Lab9 难度相对还比较大，因为文件系统本身就比较复杂，它的实现之精妙令我叹为观止。即使看完了手册和视频，写完了Lab，我仍然觉得自己对文件系统的理解不够深入。七层的设计，每一层都有非常重要的作用，睡眠锁、自旋锁的自如使用，获取扇区时自动上锁的设计，日志与直写策略的交替使用，都淋漓尽致地向我展现着操作系统的精美。不得不说，作为 XV6 学习过程中最后的一块拼图，它的确让我对操作系统的理解更加深刻了几分。至此 XV6 的手册部分就全部阅读完成了，还是有点令人感慨，几个月的操作系统之旅，虽说学得还比较认真，但也只了解了这么一个小巧的 XV6 的大部分思想，源码部分终究是走马观花，不够深入。更多的想法等到最后总结时再写吧，前面还有 Lab10 跟 Lab11（不知道会不会写），希望不要太难。\n最后照例附上通关截图：\n\n  \n  图四：通关截图\n","categories":["6.s081"],"tags":["操作系统","Linux","6.s081","文件系统"]},{"title":"gdb命令简述","url":"/2025/03/23/gdb%E5%91%BD%E4%BB%A4%E7%AE%80%E8%BF%B0/","content":"gdb（GNU 调试器）基本用法gdb 是一个强大的调试工具，允许用户调试 C、C++ 等程序。使用 gdb 可以让你在程序运行时检查和修改程序状态、查看变量值、设置断点、单步执行等。\ngdb [选项] [可执行文件]\n[选项]：可选的 gdb 命令行选项。[可执行文件]：要调试的程序的可执行文件。\n当不输入任何内容按下回车键时，会再次执行上一次输入的调试指令。\n常见操作\n1. quit：\n\n功能：退出 gdb。\n用法：(gdb) quit\n示例：(gdb) quit\n\n\n\n2. run：\n\n功能：启动调试的程序。\n用法：(gdb) run\n示例：(gdb) run\n\n\n3. watch：\n\n功能：设置监视点，当指定的表达式值发生变化时，程序会暂停。\n用法：(gdb) watch &lt;表达式&gt;\n示例：(gdb) watch x\n当变量 x 的值发生变化时，程序会暂停。\n\n\n4. break系列：\n\n功能：\n\nbreak\n在指定行或函数设置断点，程序执行到断点处会暂停。\n\ntbreak\n设置临时断点，仅在第一次执行时暂停，之后自动删除。\n\nbreak + if\n 设置带条件的断点，只有在条件满足时才暂停。\n\n\n\n用法：(gdb) break &lt;位置&gt;(gdb) tbreak &lt;位置&gt;(gdb) break &lt;位置&gt; if &lt;条件&gt;\n示例：(gdb) break main.c:10  # 在 main.c 的第 10 行设置断点(gdb) break foo        # 在函数 foo 开始处设置断点(gdb) tbreak main  # 在函数 main 入口处设置一个临时断点，执行到达时暂停一次，之后断点自动移除(gdb) break foo if x &gt; 10  # 只有 x &gt; 10 时才在 foo 函数暂停\n\n\n5. ignore：\n功能：忽略断点的命中次数，直到达到指定次数时才暂停。\n用法：(gdb) ignore &lt;断点编号&gt; &lt;次数&gt;\n示例：(gdb) ignore 1 5\n忽略编号为 1 的断点前 5 次的命中，之后再暂停。\n\n\n6. delete：\n功能：删除指定的断点或监视点。\n用法：(gdb) delete &lt;断点编号&gt;\n示例：(gdb) delete 1  # 删除编号为 1 的断点(gdb) delete    # 删除所有断点\n该命令可以用来删除一个或多个断点，也可以删除所有设置的断点。\n\n\n7. next/ni：\n\n功能：单步执行源代码行/单步执行汇编指令，但是不进入函数。\n用法：(gdb) next\n\n\n\n8. step/si：\n\n功能：单步执行源代码行/单步执行汇编指令，如果遇到函数会进入函数内部。\n用法：(gdb) step\n\n\n\n9. continue：\n\n功能：继续程序的执行，直到下一个断点。\n用法：(gdb) continue\n\n\n10. until：\n\n功能：继续执行程序，直到到达指定行或返回调用函数。\n用法：(gdb) until &lt;行号&gt;\n示例：(gdb) until 25\n继续执行，直到程序执行到第 25 行时暂停。\n\n\n11. print：\n\n功能：查看指定变量的值。\n用法：(gdb) print &lt;变量名&gt;\n示例：(gdb) print x(gdb) p/x *argv@2   # 十六进制格式打印argv的两个指针的内容\n\n\n\n12. examine：  \n\n功能：查看内存地址或寄存器中的原始数据（二进制、数值、字符串或汇编指令）。  \n语法：  \n(gdb) x/[数量][格式][单位] &lt;地址表达式&gt;  \n\n参数详解：  \n\n参数\n可选值\n说明\n\n\n数量\n正整数（默认为1）\n指定显示的数据项数量\n\n\n格式\nx(十六进制)、d(十进制)、s(字符串)、i(指令)、c(字符) 等\n控制数据显示形式\n\n\n单位\nb(1字节)、h(2字节)、w(4字节)、g(8字节)\n定义每个数据项的大小\n\n\n地址\n寄存器（如 $a1）、绝对地址（如 0xde4）、符号（如 main）\n要查看的地址或表达式\n\n\n\n\n\n示例：  \n\n查看寄存器指向的字符串：  (gdb) x/2c $a1          # 从寄存器 a1 的地址读取 2 个字符  # 输出示例：0x7ffff0: 65 &#x27;A&#x27; 66 &#x27;B&#x27;  \n反汇编代码：  (gdb) x/3i 0x8048000    # 查看地址 0x8048000 处的 3 条汇编指令  # 输出示例：  # 0x8048000: addi a0, zero, 42  # 0x8048004: jal ra, 0x8048020  # 0x8048008: lw t0, 0(sp)  \n混合参数查看内存：  (gdb) x/4xw main+0x10   # 查看 main 函数偏移 0x10 处的 4 个字（4字节一组），十六进制显示  # 输出示例：  # 0x8048010: 0x12345678 0x9abcdef0  # 0x8048018: 0xdeadbeef 0xcafebabe  \n\n\n注意事项：  \n默认沿用上次参数（如上次用 x/4xw，直接输入 x 0x1000 等效于 x/4xw 0x1000）。  \n查看指令时地址需按架构对齐（如 RISC-V 指令需 4 字节对齐）。  \n字符串格式（s）会持续输出直到遇到 0x00 终止符。  \n\n\n\n\n13. backtrace：\n\n功能：显示程序的调用栈帧。\n用法：(gdb) backtrace\n示例：(gdb) backtrace\n\n\n\n14. list：\n\n功能：查看当前执行位置附近的源代码。\n用法：(gdb) list\n示例：(gdb) list 10 # 显示第 10 行及其附近的代码(gdb) list main # 显示 main 函数中的代码\n\n\n\n15. finish：\n\n功能：让当前函数执行到结束，然后暂停并返回到调用该函数的地方。\n用法：(gdb) finish\n说明：如果你正在函数内部调试，而不想逐步跟踪整个函数，可以使用 finish 跳过该函数。\n\n\n16. tui：  \n\n功能：TUI（文本用户界面）模式允许在调试过程中同时查看源代码、汇编代码和寄存器等调试信息，提供更直观的调试体验。  \n相关命令：  \ntui enable：启用 gdb 的文本用户界面（TUI）模式。  \ntui disable：关闭 TUI 模式，返回普通的命令行界面。  \ntui status：查看 TUI 模式的当前状态（启用或禁用）。  \n\n\n\n\n17. layout：  \n\n功能：切换或显示不同的 TUI 布局（布局包括源代码、汇编代码、寄存器等）。  \n用法：  (gdb) layout &lt;模式&gt;  \n常见的 layout 模式：  \nsrc：显示源代码。  \nasm：显示汇编代码。  \nsplit：源代码和汇编代码分屏显示。  \nreg：显示寄存器信息。  \n\n\n示例：  (gdb) layout src  \n\n\n18. focus：  \n\n功能：在 TUI 模式下切换当前焦点窗口（如源代码窗口、寄存器窗口等），用于操作特定窗口（如滚动查看内容）。  \n用法：  (gdb) focus &lt;窗口名&gt;   # 直接切换焦点  (gdb) focus next       # 切换到下一个窗口  (gdb) focus prev       # 切换到上一个窗口  \n常见窗口名：  \nsrc：源代码窗口  \nasm：汇编代码窗口  \nreg：寄存器窗口\n\n\n\n\n19. info：  \n\n功能：查看程序运行时的详细信息（如寄存器值、断点列表、线程状态等），与 TUI 窗口内容互补。  \n用法：  (gdb) info &lt;参数&gt;  \n常用参数：  \nregisters：显示所有寄存器的当前值（即使未启用 reg 布局）。  \nbreakpoints：列出所有断点及其状态。  \nframe：显示当前函数调用栈帧的详细信息（如寄存器值、局部变量、返回地址等）。  \nargs：显示当前函数的参数及其值。  \nthreads：列出所有线程及其状态信息。\n\n\n示例：  (gdb) info registers   # 查看寄存器内容  \n\n\n\n20. &lt;Ctrl-x&gt;：  \n\n功能：gdb TUI 模式的控制命令前缀。  \n常见的组合：  \nCtrl-x o：切换 TUI 窗口焦点（等同于 focus next）。\nCtrl-x 2：在 TUI 模式下分屏显示。  \nCtrl-x a：激活/禁用汇编代码窗口。  \n\n\n\n\n21. refresh：  \n\n功能：刷新 TUI 模式下的显示。  \n用法：  (gdb) refresh  \n说明：当 TUI 模式下屏幕显示异常（如内容错乱）时，使用 refresh 重新绘制界面。  \n\n\n\n调试常见问题符号调试如果编译时没有使用 -g 选项生成调试信息，gdb 可能无法显示变量的值和源代码。因此，要在编译时加上 -g 选项：\ngcc -g -o program program.c\n常用选项：\n\n-g：生成调试信息，允许在 gdb 中查看源码。\n-q：禁止 gdb 输出启动信息。\n-tui：启动 gdb 的文本用户界面模式，提供更好的界面体验。\n\n例子：调试一个简单的 C 程序gcc -g -o test test.c  # 编译并生成调试信息gdb test              # 启动 gdb 调试 test 程序(gdb) break main      # 设置断点(gdb) run             # 运行程序(gdb) next            # 单步执行(gdb) print x         # 打印变量 x 的值(gdb) quit            # 退出 gdb\n调试大程序的技巧\n条件断点\n\n自定义函数查看复杂数据结构\nvoid display_2Darray(int a[][len])&#123;  int i, j;  for(i = 0; i &lt; len; i++)    for(j = 0; j &lt; len; j++)      printf(&quot;%3d&quot;, a[i][j]);&#125;\n可以用\n(gdb) print display_2Darray\n来查看输出\n\n对于几十步才会出现的bug的调试\n 方法：利用检查点checkpoint\n checkpoint:生成当前状态的快照\n info checkpoint:显示快照信息\n restart checkpoint-id:恢复到某个checkpoint\n delete checkpoint checkpoint-id:删除某个checkpoint\n\n\n","categories":["工具"],"tags":["gdb","命令"]},{"title":"ssh连接方式22端口被封锁解决方案","url":"/2025/03/29/ssh%E8%BF%9E%E6%8E%A5%E6%96%B9%E5%BC%8F22%E7%AB%AF%E5%8F%A3%E8%A2%AB%E5%B0%81%E9%94%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"方案1：切换为 HTTP 连接在当前仓库的 .git/config 文件中，将以下行：url = git@github.com:username/repo.git修改为：url = https://github.com/username/repo.git这样我们就可以让 Git 通过 HTTPS 连接 GitHub 仓库。\n方案2：切换 SSH 端口在 ~/.ssh 目录下创建或编辑 config 文件，添加以下配置：Host github.comUser gitHostname ssh.github.comPreferredAuthentications publickeyIdentityFile ~/.ssh/id_rsaPort 443这样 SSH 就会通过端口 443 连接 GitHub。\n","categories":["DEBUG"],"tags":["DEBUG","ssh"]},{"title":"k大构成L2","url":"/2025/05/02/k%E5%A4%A7%E6%9E%84%E6%88%90L2/","content":"知识点复习重复物体一定要遵循“三的定理”，我想是因为比较明显，其实如果都看成抽象形状，那么其实不止重复图形需要遵守这一点。但实际上因为任何地方都会有形状相似的动物/植物/建筑/地形等，所以这一点尤为重要。\n构成中也有秩序美，但我们一般会避免完全一样，一般是有类似数列的变化：长度逐渐增大，间距逐渐增加等。\n速写练习目的2：提升概括和提炼图形的能力节奏在形状中的一个最直接体现就是一二三级形，速写可以从这个方向出发。图形练习时，重点在于大形状、转折处、长宽比。\n一级形：画面最大的轮廓（剪影）\n二级形：内部结构（衣服款式等等、内部切割）\n三级形：花纹细节、装饰、褶皱、小色块（尤其是闭塞）\n三级形会让人觉得画面精致，所以我们需要有很小的细节。但是不能陷入细节之中，要先画大块，再画细节。\n正如L2作业，我们就可以利用一二三级形，先画大块形状，再在里面逐渐加小形状。\n外轮廓同样也有轮廓的一二三级形，要做到整洁又丰富。\n三级形通常有两种表现方式：一种是认真刻画细节结构，或者通过头皮屑、小落叶等来增加小细节，而且可以与外轮廓产生遮挡来进一步丰富；另一种则是通过小排线、死角闭塞、豆芽型等手法来单纯丰富画面层次，也就是不单纯地画线，还增加了光影信息。\n在练习过程中，还可以注意线条的运用。我们可以根据不同的层级，在相应的位置调整线条的粗细。为了加强空间关系，使画面看起来更丰富、更具立体感，可以在物体穿插的位置上适当加重空间关系中更靠前的线条。在具体的用线方式上，我们同样采用 CSI 方法，即通过点对点连线来构建结构。\n邪道：高斯模糊增加质感。不过要上色的图应该没有必要？\n如果是一个比较完整的速写练习的话，一般是这样一个步骤\n\n抓趋势\n在趋势上填图形\n赋予立体感\n\n我们要积累的也就是这三个方面：趋势、图形、结构。\n双主角所谓“双主角”，其实就是之前提到的“点景”概念。当画面显得过于空旷时，可以考虑加入一些次要的景物来丰富构图。但要注意保持画面的整体平衡，不能只在一侧安排景物。同时，还需要设计好景点的“参观顺序”，也就是引导视线的画面动势，使观者在浏览画面时有明确的视觉路径。\n答疑补充\n为了表现趋势的立体感，我们可以用带有立体感的动线来确定趋势，如下图所示：\n\n如果需要把两个大的图形拼在一起，那么为了避免均分，可以人为拆分一个图形，做出大中小的区分：\n\n如果觉得动线没补全，可以用一些小的形状去拼贴：\n\n\n","categories":["绘画"],"tags":["绘画","构成"]},{"title":"修改文件名后导致github上路径和本地不一致的解决办法","url":"/2025/05/07/%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%90%8D%E5%90%8E%E5%AF%BC%E8%87%B4github%E4%B8%8A%E8%B7%AF%E5%BE%84%E5%92%8C%E6%9C%AC%E5%9C%B0%E4%B8%8D%E4%B8%80%E8%87%B4%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","content":"修改文件名后导致 GitHub 上路径和本地不一致的解决办法问题描述在使用 Hexo 部署博客时，修改了文章的文件名后，GitHub 上生成的路径和本地不一致，导致页面无法正确访问。\n原因Hexo 默认使用 .md 文件的文件名作为生成页面的 URL 路径。如果修改了文件名但没有正确同步部署，GitHub Pages 上的路径不会自动更新，导致路径不一致。\n解决办法清除 Hexo 缓存\n删除 .deploy_git 文件夹，强制清除缓存。\n重新执行 Hexo 部署命令：\n\nhexo cleanhexo ghexo d\n这样可以确保 Hexo 不会使用旧的缓存记录，重新部署并生成正确的路径。\n其实感觉自己找找也可以……不过没必要。\n","categories":["DEBUG"],"tags":["DEBUG","git"]},{"title":"git命令速查版","url":"/2025/02/27/git%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5%E7%89%88/","content":"Git 常用命令速查表仓库初始化# 创建新仓库git init# 克隆远程仓库git clone https://github.com/用户名/项目名.git # 克隆整个仓库git clone -b 分支名 仓库地址 # 克隆指定分支\n文件操作# 添加修改到暂存区git add . # 添加所有修改的文件到暂存区git add 文件名 # 添加单个文件到暂存区# 删除git clean -n # 显示会被删除的文件（只是预览，不实际删除）git clean -f # 强制删除未追踪的文件（实际执行）git clean -fd # 强制删除未追踪的文件和目录# 撤回暂存区文件git reset # 把暂存区文件，撤回到工作区git reset HEAD 文件名 # 撤销某个文件的 git addgit reset --soft HEAD^ # 回退到上一个提交，保留修改内容在暂存区（add 过）git reset --mixed HEAD^ # 回退到上一个提交，修改内容回到工作区（默认行为）git reset --hard HEAD^ # 回退到上一个提交，彻底删除改动（不可恢复）# 恢复文件到上次提交状态（不删除本地修改）git checkout -- 文件名# 提交更改到本地仓库git commit -m &quot;提交描述&quot;\n查看信息# 查看当前状态（修改/暂存文件）git status# 查看提交历史git log             # 查看提交日志（时间、作者、commit ID）git log --oneline   # 压缩成一行显示# 查看未暂存的修改内容git diff\n分支管理# 查看所有分支git branch# 创建新分支git branch feature-login# 切换分支git checkout main# 创建并切换分支git checkout -b hotfix# 删除分支git branch -d old-branch\n远程协作# git 配置git config --global user.name &quot;你的用户名&quot; # 设置全局用户名git config --global user.email &quot;你的邮箱&quot;  # 设置全局邮箱git config --global http.proxy &quot;http://127.0.0.1:7890&quot;git config --global https.proxy &quot;http://127.0.0.1:7890&quot; # 设置代理git config --global --unset http.proxygit config --global --unset https.proxy # 取消代理设置git config --global --list # 查看当前所有全局配置git config --list # 查看当前仓库和全局的综合配置# 远程仓库管理git remote add &lt;name&gt;\t# 添加新远程仓库git remote -v\t# 查看所有远程仓库及其 URLgit remote set-url\t# 修改已有远程仓库的 URLgit remote remove\t# 删除指定远程仓库git remote rename\t# 重命名远程仓库# 推送git push # 推送当前分支到远程对应分支git push -u origin 分支名 # 第一次推送，需要绑定本地分支和远程分支git push origin 分支名 # 推送到指定远程分支，不设置上游git push origin --delete 分支名 # 删除远程分支# 拉取代码git pull # 拉取远程当前分支并合并git pull origin 分支名 # 从远程指定分支拉取并合并","categories":["工具"],"tags":["命令","git"]},{"title":"k大构成L1","url":"/2025/04/25/k%E5%A4%A7%E6%9E%84%E6%88%90L1/","content":"知识点实践角度我们一般可以把画面分为以下内容：\n\n人物主角\n背景\n飞行道具\n重复物体\n特殊道具（第二、第三亮点）\n\n\n分子特效\n\n理论大方向：趋势、图形、节奏主次不管是人物、背景还是飞行道具都要考虑趋势，趋势有大有小，小趋势也有节奏主次、包含疏密结构（比如说褶皱）\n图形也是需要归纳的，我们要避免轮廓出现太多凹凸起伏。\n趋势和图形都要考虑主次关系：从大形状到小形状、从外部到内部。要注意宽窄的差异对比，线条的长短差异等等，制造节奏感。\n对于重复的物体，他们一般是为了丰富趋势线，主次关系有“三的定理”：大中小，重叠，错落。\n同样还要考虑直曲对比，比如csi。\n某种意义上来说，特殊道具与重复物体的区别也是一种简繁对比。人物也是一样，我们可以先画素体，然后设计点景，最后填空。\n飞行道具属于“点”，我们可以用“线”把“点”给串起来，也就是做视觉引导。这属于趋势与图形的配合。\n“互动陷阱”：让任务和道具之间产生互动是非常难的事情，初期尽可能不要尝试。\n速写练习目的1：练习趋势速写可以练习结构、形状、趋势、增加元素库等等，这堂课讲的是趋势的练习。\n以练习趋势为目的的话，首先就要抓最大的趋势，在人物上，“趋势”一般被称之为“动态线”。人物的趋势有几个比较重要的部分：中轴、肩腰臀,双膝,脚掌,五官、外轮廓，在练习时要重点注意。\n然而对整张图去把控它的趋势相当困难，所以我们一般通过练习人物的速写掌握人物的趋势，熟悉之后在拓展到全图。\n为了把握趋势线，我们先了解这之中的原理。\n因为人的眼睛对于“光滑又流畅”的线的敏感度很高，结合完型理论，这就会会让我们产生“很有动态感”的错觉。\n为此，如果我们刻意地想要增加这种动态感，就要增加同样趋势的长线段。如果要刻意练习，就可以先画趋势线，然后刻意让形状贴齐趋势线。\n正如我们之前所说，趋势线需要直曲结合，这样才会好看。\n而趋势线的设计一般就是开始时有一定的设想，然后在过程中不断调整。“好的设计是调整出来的”。\n作业人物显然非常复杂，背景也需要透视，所以最简单的理论实践应当从飞行道具开始。\n第一堂课的目的是学习元素的积累。注意我们创作的时候，是根据想要的形状拼贴相应的物体，因此我们要试着去把物体变成形状。\n也就是说，增加元素库的方法大概分为以下几步：\n\n临摹照片、分析部位\n拆成零件、积累形状\n零件变形、组合整理\n\n接下来是配合动线，也就是说与趋势相结合，这时候就是根据想要的趋势线拼贴相应的形状。为了保证趋势线明显，要增加适合趋势线的平滑长线段。\n综合来看，L1的作业就全面地带我们了解了构成最基本的几个部分，以及从积累到创作的全流程。这看起来无疑是有难度的，我们要在练习中时刻思考知识点的内容，应该能更好地吸收。\n补充：线条风格化\n每个人有不同的线条风格，要学习就得对着相应的老师的作品去临摹研究。但对于初学者来说，三级无压感线条已经够用。\n答疑补充\n节奏 大小差距在1:0.6的大小差异下，才能被区分出明显大小层级。\n 在具有大中小层级的圆圈中，要避免一下两种情况：\n \n 常用的组织节奏感的方式是以三两成群为基本单位，以“2+1”的模式为一组，用两个有交叠的圆圈外带一个疏离的圆圈的模式。同时，交叠的圆圈通常组成更大的范围，疏离的圆圈以配角身份陪衬，这样可以形成主次。\n \n 同时，开头结尾最好用中间大小的，会比较有收束感。\n\n趋势满足 尽管有动态线穿过，但观众不一定能感觉到。所以我们要做到的是，即使没有动态线，圆圈的摆放也能让人感受到动态线的大致走向。\n 填补具象物体时，要注意填充物的饱满，避免填入后画面的重心失衡，或者与之前预设的气泡节奏严重偏离。就算圆圈的趋势明确了，填入鱼群后会形成新的趋势，有可能违背气泡的预设。因此如果有必要，需要再对画面进行修正，让鱼群的队伍也有明确朝向。（有冲突时，以成图为准）\n\n拆分重组 重组之后，尽量也要保证金鱼的形态特征。元素的部位也要顺应整体趋势，最好让各个元素的小趋势顺着整体趋势会比较顺滑。\n 处理拼贴与遮挡的时候，也要注意视觉上的自然，有些次要内容需要让位给关键识别信息，比如头部。就算有尾巴挡住鱼头的必要，也不要在主要显眼的位置。\n\n线条 最粗的线意味着第一层级的轮廓，也就是要让观众第一眼识别的位置。但是，比起线条粗细，更加重要的反而是疏密。如果细节比较繁琐，大胆删减不需要的线段即可，一般我们保留外轮廓，留下一点点内部线条即可（边缘附近优先，根部和结构连接处优先）。\n\n\n","categories":["绘画"],"tags":["绘画","构成"]},{"title":"斑斓之镇L1笔记","url":"/2025/03/20/%E6%96%91%E6%96%93%E4%B9%8B%E9%95%87L1%E7%AC%94%E8%AE%B0/","content":"总目标课程体系WWHT（文玩核桃）：W（练什么）、W（为什么）、H（怎么练）、T（然后呢）\n目标立绘为主的色彩抓色临摹（插画见色彩正课）\n目的累计基本技能点\n怎么练跟课程\n然后呢为后续技能铺路\n知识点\n    本周目标：认识颜色、培养色感\n        \n            色彩三要素：H（色相）S（饱和度）B（明度）\n            色感：颜色的搭配 / 色彩的敏感度\n            相互影响：在饱和度最高的时候，明度顺序依次为：黄色、水蓝色最亮，绿色、紫色中等，红色、深蓝最暗。\n        \n    \n    练习原因\n        \n            认知是有差异的，人眼会骗人，所见即所得是需要刻意锻炼的技能点。\n        \n    \n    练习方法\n        \n            抓型练习练抓色，核心练习练流程。\n            不用照片临摹的原因是照片太复杂，概括就很难，而且眼睛会骗人。\n            抓色热身要点：\n                \n                    步骤：先肉眼试验，再手动调节 HSB 数值。有颜色时优先判断色相，再看明度，最后看饱和度。\n                    注意点：以练习色准为第一优先级，不能用调色工具或者重叠试色。\n                    小贴士：有些颜色抓不准色相是正常的，比如绿色的区域天生长一些，自然容易抓不准。\n                    感想：直觉是会骗人的，需要纠正！比如你可能会认为这个颜色不够“橙”，实际上可能不是纯度不够，而是色相上有差异；同样的，当你觉得这个颜色不够暗的时候，也有可能是因为不够纯。当一个颜色周围有比较暗的颜色时，肉眼就会误判它的亮度，这时候我们必须按照知识去纠正。\n                \n            \n            色彩临摹要点：\n                \n                    步骤：\n                        \n                            线稿：导入线稿。\n                            剪影：选择线稿图层，用魔棒工具点外面，选择反向再 Alt+Delete 填充一个剪影。\n                            固有色大色块：在剪影的上一个图层创建剪切蒙版，魔棒 - 选择 - 修改 - 拓展 - 填充固有色大色块。大色块从最大面积入手，遵循从大到小、从高饱和到低饱和的顺序铺色，每个区域抓主要颜色即可，先忽略花纹和渐变。有渐变的地方优先抓浅色区域。调整要在所有固有色上完之后调整，因为颜色会相互影响。调整就取消连续，Ctrl-U 来调整颜色。\n                            花纹+渐变+细节：渐变要关掉连续，用喷枪笔刷轻轻刷一下。\n                            线稿改色：颜色使用实心笔，渐变用喷枪笔刷。\n                        \n                    \n                    目的：熟悉流程 > 色彩准确。\n                    注意点：调色和重叠试色可以弹性使用。目前没有阴影，不用担心。\n                    快捷键：Ctrl-J 复制图层。\n                \n            \n        \n    \n    小技巧\n        \n            颜色搭配萌新技巧：\n                \n                    黑白关系拉开。\n                    确定主色，邻居配色技巧（用着色功能）。\n                    添加高饱和或对比色抢眼。\n                    花纹和渐变有奇效。\n                \n            \n            头发改色原理：\n                \n                    大块固有色边缘要强调，不用改色。\n                    为了区分发束的前后，想要强调区别的时候，不用改色。\n                \n            \n            新建饱和度图层并填充没有饱和度的颜色可以检查黑白关系。\n            肤色色相 20-30 之内，饱和度 10 左右，明度 95 往上。\n            颜色混在一起时可以用渐变拉开，用喷枪刷一下。\n        \n    \n    未来的方向\n        \n            未来发展路径：所见即所得 → 主动整理颜色 → 颜色搭配（HSB的对比）\n            可以从色卡去积累，要关注颜色的比例。\n        \n    \n\n","categories":["绘画"],"tags":["绘画","色彩"]},{"title":"斑斓之镇L4笔记","url":"/2025/04/01/%E6%96%91%E6%96%93%E4%B9%8B%E9%95%87L4%E7%AC%94%E8%AE%B0/","content":"知识点\n    本周目标：累积形状搭配\n        \n            【软体】：结构会变化、灵活性高的物体\n            软体的形状容易变化，适合做形状搭配\n        \n    \n    练习原因\n        \n            形成【节奏感】\n            模拟【真实】\n        \n    \n    构成节奏：大小穿插破\n        \n            大中小、穿插、点线面\n                \n                    通过不同尺度的元素交错排列，形成节奏感。\n                    结合点、线、面的对比，使构图更有层次感。\n                \n            \n            破型与完形\n                \n                    夹缝可以在中间断掉，形成“破型”效果，让视觉自行补全。\n                    适当留白，让观者的视觉去推测缺失的部分，可以提高图形的趣味性。\n                \n            \n            豆芽形的应用\n                \n                    豆芽形状结合了点和线的特性，可以灵活运用在构图中。\n                    既能作为连接元素，又能单独起到视觉引导作用。\n                \n            \n            舍与取的原则\n                \n                    舍：\n                        \n                            转折处，平滑处多一些（增强流畅性）。\n                            肌肉手臂等区域少一些（避免过于琐碎）。\n                        \n                    \n                    取：\n                        \n                            为了暗示结构，可以添加小块元素，但不完全勾勒出形态。\n                            为了加强头发等与脸部之间的空间感，我们有时候会在“反光源”的部分加投影，也是属于主观处理。\n                            让视觉自行补全，增强整体的空间感与层次感。\n                        \n                    \n                \n            \n        \n    \n    未来指路\n        \n            丰富颜色的地基：注意保留二分形状\n                \n                    形状【轮廓】：选取亮面颜色拉高，当作过渡来做，交界线软一些，投影最多一点点\n                    形状【内部】：藏色，见下节课~\n                \n            \n            形状能够带来风格变化\n                分析 → 提取 → 安装\n                先分析图形经常出现的地方，提取形状，按“大小穿插破”和之前的常见位置安装到对应的地方，再结合二分之类的知识进行补全。\n                像花、褶皱、头发这种软体，本质上都是形状，只要有类似的形状，我们都会认为他是那一个物体。\n                同时，我们要注意防止“写实陷阱”，如果在进行二次元创作时，转面不宜过多，因此某些部分过于纠结结构、过于写实就会导致信息量不匹配，看起来会很奇怪。\n            \n            金属材质：做好二分后，在亮部搞一个非常明显的高光，再在高光周围搞一个非常暗的部分，形成强烈对比，看起来会更光滑。\n            取消视图-对齐之后，可以解决移动图层组之后图层之间会偏离几个像素的问题\n        \n    \n\n","categories":["绘画"],"tags":["绘画","色彩","二分"]},{"title":"斑斓之镇L3笔记","url":"/2025/03/28/%E6%96%91%E6%96%93%E4%B9%8B%E9%95%87L3%E7%AC%94%E8%AE%B0/","content":"知识点\n    本周目标：观察精致二分\n        \n            注意 投影 和 夹缝 \n        \n    \n    练习原因\n        \n            提升 画面信息量，锁住观众眼睛\n            进阶 画家之眼，多观察生活\n        \n    \n    练习方法\n        \n            画家之眼：\n                \n                    多观察生活中的细节，如缝隙和花纹\n                    可以通过触摸去感受\n                    找参考\n                        \n                            如 billfish、pixcall 等整理素材\n                            寻找照片、模型参考或实拍素材\n                        \n                    \n                \n            \n            抓色时可以开始留意颜色位置及颜色间的相互影响，全部在暗部的颜色可以参考旁边的颜色确定明度，色相在二分调色时调整\n            复杂二分绘制逻辑：整体到细节，先大面积铺，再细化，重点关注投影和暗部\n            精致度判断：关掉线稿仍能看出结构，第二天可与答案对照\n            额外技巧：\n                \n                    高饱和轮廓：\n                        \n                            操作：使用 Ps 描边功能，使物体更加整体，与外轮廓加粗原理相同\n                            作用：\n                                \n                                    提出主体\n                                    整理轮廓\n                                    增加信息\n                                \n                            \n                        \n                    \n                    五官技巧：\n                        \n                            眼睛：\n                                \n                                    高光：眼睛上方\n                                    透光：下方提亮\n                                    渐变：眼睛内部可做渐变\n                                    虹膜：虹膜可做拉丝\n                                    形状：不拘泥于圆形，可随意更改\n                                    颜色：对比色增加吸引力\n                                \n                            \n                            睫毛：高光、透肤色处理\n                            腮红：正片叠底，明度 95 以上（甚至 100），可加线条\n                            “藏龙卧虎”画法：龙图加胖虎\n                        \n                    \n                \n            \n        \n    \n    未来指路\n        \n            风格选择：\n                \n                    薄、过渡明显：漫画风\n                    厚、过渡模糊：偏写实\n                \n            \n            厚重感绘制技巧：\n                \n                    正常模式下用 19 号笔刷吸色轻涂，再吸中间的并涂上，如此反复。不要使用喷枪！\n                    注意圆弧形的、软的交界线可做过渡，但硬边缘与投影不要过渡，暂时可以认为朝光源的部分要过渡\n                    光源离物体远时、转折较软时交界线较虚，反之较实\n                \n            \n            一些主观处理\n                \n                    布料的三角可用于暗示厚度，是否处理可自行决定\n                    明显背光面不一定要画暗部，可自行决定\n                    可通过观察其他老师的处理手法来学习\n                \n            \n        \n    \n\n\n另外，二分好看与否的关键点在 L4，今天的内容只是关注投影和夹缝这些较简单的部分。\n","categories":["绘画"],"tags":["绘画","色彩","二分"]},{"title":"斑斓之镇L6笔记","url":"/2025/04/09/%E6%96%91%E6%96%93%E4%B9%8B%E9%95%87L6%E7%AC%94%E8%AE%B0/","content":"知识点\n    本周目标：认识环境光\n        \n            光的种类\n                \n                    直射光：画面中最强烈、最显眼的光源。在有直射光的情况下，其他光照可以忽略。\n                    环境光：也称“锅盖光”，是一种均匀、无方向性的基础光照。\n                    \n                        天光：带有天空蓝色调的光，通常从头顶照射而下，尤其在四周被树木或建筑遮挡时更为明显。\n                        反光：直射光照射到地面或其他物体后反射产生的次级光线。\n                    \n                \n            \n            亮部来源于直射光，能被看到的暗部当作环境光处理\n            如果物体放在地面上有反光，那么明暗交界线是最暗的地方，否则一般不是最暗的。除此之外，还跟材质有一定关系。\n        \n    \n    练习原因\n        \n            【客观】丰富颜色\n            理解【客观光源】规律\n            【画家之眼】再升级\n        \n    \n    \n        让图片更好地融入环境\n        光影处理方法：\n        首先，在白色物体上找到阴影的颜色，正片叠底到人物上压暗。用魔棒或套索工具进行选区操作，再用“颜色减淡”模式绘制光照效果。建议使用颜色饱和度约为 1/3、明度约为 50% 的色彩。如果选区边框影响视线，可按 Ctrl+H 隐藏选区线。\n        如果场景中存在环境光，建议至少添加一个简单的色块来表现光源。\n        另外，添加一些类似“头皮屑”的细小色块，也能增强画面的层次感与真实感。\n        光系统并不需要做两次二分，只是为了练习我们才用原来的图。\n    \n    最终步骤：正片叠底二分整体压暗、亮部暗部塑造面、火腿片之类的级边过渡、反选颜色减淡打光、高光、柔光图层用喷枪刷透光、天光反光\n\n","categories":["绘画"],"tags":["绘画","色彩"]},{"title":"斑斓之镇L5笔记","url":"/2025/04/05/%E6%96%91%E6%96%93%E4%B9%8B%E9%95%87L5%E7%AC%94%E8%AE%B0/","content":"知识点\n    本周目标：认识塑造面\n        \n            【塑造】：描绘立体感的过程就叫做【塑造】\n                \n                    亮中暗和暗中暗就是塑造面的一种\n                    “亮中亮”实际上就是“高光”，“暗中暗”实际上是“反光”\n                    塑造的过程不要破坏大的素描关系，添加的塑造面要跟原本的面明度接近，明暗一定要拉开，否则就会有所谓的素描很“脏”的感觉\n                    暗中暗是在阴影里面找结构，而不是用亮部的原理去推算暗部，所以不要到处画投影。可以多参考，一般是通过反光、小结构、虚实关系什么的来刻画，并不会到处画投影\n                \n            \n            名词辨析\n                \n                    【调子】：指画面中黑白明度的层次变化，是一种平滑、连续的过渡过程。\n                    【色阶】：指明度的分级变化，是一种不连续、分段的变化方式。\n                \n            \n        \n    \n    练习原因\n        \n            增加【立体感】\n            区别【层次关系】\n        \n    \n    \n        塑造的原理与技巧\n        原理：塑造的关键在于光照角度的处理。其本质目的是为了区分结构和层次关系，因此我们无所谓哪一部分更亮，但我们必须保证所有部分统一。\n        如果别人质疑为何亮面不是靠近交界线的部分更暗时，可以用“反光板”的概念来忽悠他。\n        技巧（详见色彩正课）：\n        \n            可以主观添加塑造面，以增强结构的区分度。\n            层叠法：在处理堆叠的多个物体时，可以只处理上层的尖端部分，不考虑光源，这样很容易区分层次关系。\n            夹高光：使用19号笔刷绘画时，可以把高光部分留出来，自然能表现出物体的形状。\n        \n    \n    练习方法\n        \n            白模练习：分辨二分与塑造面为主，同样分区域正片叠底画即可\n            色彩临摹步骤再次更新\n                \n                    塑造面：新建正片叠底图层，饱和度5左右，明度大概90~95，先画形状，有需要再调色，可以用19号笔来做过渡。可以用Ctrl选区选出图层并在固有色上选区，在上面做塑造就不会涂出去了，也可以最后选区再删\n                    图层顺序：顺序依次是高光、二分、亮中暗、暗中暗。\n                \n            \n        \n    \n    藏色技巧\n        \n            微弱的藏色：\n                \n                    保持素描关系：颜色本身也有素描变化，饱和度越高，越深，明度越低，越深。可以用L值（拾色器下按Ctrl+Shift+Y去除颜色叠加，再点L值），也可以用饱和度图层校准\n                    颜色搭配要正确：亮面偏暖暗面偏冷\n                    形状要正确\n                    一般选用带压感或材质的笔刷少量多次地将新的颜色混入旧颜色中，边缘可以用中间色来过渡，也可以用【外发光】图层\n                \n            \n            提神的藏色：多用于明暗交界线部分，一般是吸亮面颜色拉高饱和度\n        \n    \n\n","categories":["绘画"],"tags":["绘画","色彩"]},{"title":"破晓之秋抓型总结","url":"/2025/03/20/%E7%A0%B4%E6%99%93%E4%B9%8B%E7%A7%8B%E6%8A%93%E5%9E%8B%E6%80%BB%E7%BB%93/","content":"嫖的破晓之秋第零期，不得不说不仅素材质量高，而且讲的课也让我学到了不少，至少现在我抓型基本上算是熟练了。\n首先是自己的经验：\n\n打框：我习惯只打一二级框，第三级省略，在细化时硬画。一级框注意不要看成一个整体，拆成1+3+n比较好（但也不必那么严格，反正画的舒服就行），这样会让负型比较简单，而且要注意一级框最好不要超过六边形，优先采用D形或六边以下多边形概括。另外，可以试着往水平竖直、平行线、直角上面去靠，方便抓型。二级框要注意不要被原有的线条局限住，关键在于区分大结构，这样可以避免太碎失去整体型准，形状也尽可能简单一些。\n抓型：我的经验是整体大型&gt;线条斜率=高度关系&gt;小局部（长度），一定要时刻关注大型，不然很容易跑偏。还有一些小技巧，比如曲线先关注端点，接近水平竖直的线可以去对比一个小三角形或者小矩形，毕竟我们对图形比长度敏感许多。\n细化：与抓型类似，注意外轮廓的csi就行。而且小结构不要太纠结，没必要，效率实在是太低，而且也抓不准，真的。\n\n然后是第四阶段的笔记：\n在前面三个阶段，我们都没有去处理光影（当然我是抓了一些明显的闭塞的，虽然就像老师说的一样只是抓型没有思考），现在抓型已经基本熟练，可以考虑处理暗部光影了（不仅仅是抓型，还要去思考为什么好看）。\n\n光影图形的产生（理论篇）：\n单纯抓暗部和暗中暗的话，直接正片叠底画就行。\n光影的分类：厚度、投影、闭塞\n\n厚度：物体因实际厚度产生的灰面过渡和暗面加深，是塑造体积的关键层级。\n投影：物体阻挡光源后，在周围表面形成的暗部区域。投影的形状、虚实和颜色由光源性质（强/弱、点光源/平行光）和物体形态决定。光源越强/集中，投影边缘越清晰（如正午阳光）；光源越柔和（如阴天），投影边缘越模糊。投影形状需符合透视（如圆柱体的投影为椭圆形），根据这个。\n闭塞（AO）：物体在结构凹陷或紧密接触处，因环境光被完全阻挡形成的极暗区域。AO能强化物体的结构细节和重量感。常见于褶皱深处、物体交叠处（如手指缝隙）、衣物与皮肤接触面。通常为与环境一致的低饱和度深色，避免使用纯黑以免死板。根据构成原理，例图中的光影有大中小的区分，这种层次感使得画面更具趣味性。为了实现这种层次感，光源的选择非常关键。在美式卡通中，为了体现层级关系和遮挡关系，通常会通过涂黑的方式来区分不同的区域。通过将一些形状组合并涂黑，能够有效地形成大中小的光影层次，使画面更具层次感和立体感。\n\n\n光影图形的处理技巧（实战篇）\n事实：同时兼顾光影的正确性和构成的大中小非常困难\n因此我们要去理解光影的由来:\n比如男生头发上的阴影表示头发的厚度，也表示向下弯曲；而女生头发上面没有阴影，说明头发比较薄，有轻盈感。又比如剑术师衣服下面的阴影是两个三角形而不是矩形，暗示了褶皱，体现了衣服的实际结构。\n\n如何高效练习（辅助篇）\n目的、流程、类比、复习\n\n创作延伸方向\n\n\n从抓型谈创作\n\n我们会分析抓型原因，抓取外形特征图形\n如果没有原因，直接进行创作\n会开始迷茫，不知道画什么或者怎么起手\n回头看刚通过抓型分析的图形，如果有了这些图形，就可以发散出创作内容了\n\n\n\n\n为什么起步阶段创作很难\n\n作画顺序和练习顺序的不一致导致的思路不通\n练习：原图 -&gt; 分析 -&gt; 成品\n作画：脑海的想法 -&gt; 分析 -&gt; 成品\n\n\n\n\n那我怎么培养图形感预备创作呢？\n\n练习的过程中同时积累记忆\n这也是为什么同人的作品创作起来更容易，因为有依据的\n\n\n快快快的秘诀！\n\n练习和创作的流程对上\n反复操作，熟能生巧\n练习的熟练度会让创作更快\n创作卡住的地方，让我的练习更有目的，循环前进\n\n\n\n","categories":["绘画"],"tags":["绘画","抓型"]},{"title":"用于优化体验的简单启动项py脚本","url":"/2025/04/22/%E7%94%A8%E4%BA%8E%E4%BC%98%E5%8C%96%E4%BD%93%E9%AA%8C%E7%9A%84%E7%AE%80%E5%8D%95%E5%90%AF%E5%8A%A8%E9%A1%B9py%E8%84%9A%E6%9C%AC/","content":"这两天突然觉着开机后的有些操作过于繁琐重复，于是给电脑写了几个脚本来偷懒。\nVMware 强制管理员模式运行众所周知 VMware 跟 Win11 适配的不是很好，在12代以上的大小核架构中不会使用大核来运行，这会导致在虚拟机中的一些键盘操作变得很慢。解决方法之一就是运用“管理员模式”打开 VMware。但即使从快捷方式设置了每次以管理员模式运行，每次还要关闭提示页面，某种程度上会让人感觉有点烦躁。因此第一个脚本就是让电脑每次以管理员模式运行 VMware。\n操作步骤如下：\n\n（可选）安装 pywin32 宏包 我们的脚本中可以用到 win32com.client 来访问 Windows 的 COM 接口（Office 自动化、任务计划、注册表等），所以可以安装 pywin32 宏包。 使用国内镜像源下载即可。 pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pywin32\n 用 pywin32 宏包可以设置任务计划程序，不过权限问题很麻烦，我更加倾向于用系统提供的gui界面进行设置。\n设置任务计划程序 在计算机管理——任务计划程序中，新建任务，取一个好听的名字（我取的叫 VMwareAdminLaunch）\n \n 在操作中新建一个动作，打开程序，选择自己程序所在的地址。\n \n 然后在条件中取消“仅在计算机使用交流电源时启动”，否则离电不能运行。\n \n\npy脚本 最后我们的py脚本内容如下，其实就是调用命令行，creationflags=subprocess.CREATE_NO_WINDOW保证了命令行不弹窗： import subprocessdef run_silent_task(taskName):    subprocess.Popen(        [&quot;schtasks&quot;, &quot;/run&quot;, &quot;/tn&quot;, taskName],        creationflags=subprocess.CREATE_NO_WINDOW    )if __name__ == &quot;__main__&quot;:    run_silent_task(&quot;VMwareAdminLaunch&quot;)\n\n\nClash我真没想到 Clash 自己的最小化也有bug，会导致鼠标一直闪烁，我不得不自行实现打开并隐藏。\n同样主要分为两个操作步骤\n\n设置任务计划程序 同样新建任务，这里不需要用管理模式运行。\n \n 设置一个触发器，但要注意开机时启动会有一些bug，我们一般采用登录时启动。然后！因为 Clash 在登录时那一会gui界面没加载好的时候跟系统不兼容，所以启动会失败，所以我们要延迟10秒运行。\n \n 在操作中新建一个动作，打开我们的脚本程序。\n \n 同样在条件中取消“仅在计算机使用交流电源时启动”。\n \n\npy脚本 我们启动后在gui界面查找名称进行匹配，然后进行隐藏即可，可以根据需求自己设置弹窗提示。 import subprocessimport timeimport win32guiimport win32confrom win10toast import ToastNotifiermyexe_path = r&#x27;&quot;E:\\Clash.for.Windows\\Clash for Windows.exe&quot;&#x27;myexe_name = &quot;clash for windows&quot;def find_exe(exe_name):    &quot;&quot;&quot;查找exe窗口句柄&quot;&quot;&quot;    def callback(hwnd, hwnds):        if win32gui.IsWindowVisible(hwnd):            title = win32gui.GetWindowText(hwnd)            if title.lower() == exe_name: # 匹配程序标题，这里采用完全匹配                hwnds.append(hwnd)        return True        hwnds = []    win32gui.EnumWindows(callback, hwnds)    return hwndsdef hide_window(hwnd):    for _ in range(10):        win32gui.ShowWindow(hwnd, win32con.SW_HIDE)        if not win32gui.IsWindowVisible(hwnd):            return True        time.sleep(0.1)    return False  # 超时未成功def main():    # 启动程序    toaster = ToastNotifier()    subprocess.Popen(myexe_path)        # 等待几秒让程序完全启动    try_num = 500    for _ in range(try_num):        time.sleep(0.01) # 查找并隐藏exe窗口        exe_windows = find_exe(myexe_name)        if exe_windows:            for hwnd in exe_windows:                hide_window(hwnd)                print(f&quot;已隐藏exe窗口 (句柄: &#123;hwnd&#125;)&quot;)            toaster.show_toast(&quot;Clash 已自动启动！&quot;, &quot;愿此生尽兴，赤诚善良&quot;, duration = 0.3, icon_path = None, threaded = True)            break    else:        print(&quot;未找到exe窗口，请检查程序是否正常启动&quot;)if __name__ == &quot;__main__&quot;:    main()\n\n\nWallPaper担心在外面用壁纸会社死？我们在连接电源时才开壁纸引擎即可。\n我们只需要在条件中打开“仅在计算机使用交流电源时启动”，其他选项保持不变，因为本来就不会弹窗甚至不需要脚本来执行嘿嘿嘿。\n\nSteam最近知道了“着色器预缓存”这个设置对游戏的启动速度影响超级大，也有人说是加速器的影响，但我测试下来无论如何关掉这个设置对启动速度的提升都是巨大的。\n但是我总是担心可能以后遇到的游戏需要这个功能，所以我写了个脚本在凌晨更新缓存：\n\n设置任务计划程序 同样新建任务，设置一个触发器，因为目前看来我玩的游戏更新频率不高，所以每周一凌晨3点启动，其余操作不变。\n \n\npy脚本 我们修改 steam 启动项的配置文件，用 re 库进行匹配替换，然后打开 steam  静置 10min 让其自动更新。\n import subprocessimport timeimport osimport resteamPath = r&quot;E:\\steam\\steam.exe&quot;configPath = r&quot;E:\\steam\\config\\config.vdf&quot;def modifyShaderCache(enable: bool):    if not os.path.exists(configPath):        print(&quot;[ERR] config.vdf 不存在&quot;)        return    with open(configPath, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:        content = f.read()    newValue = &quot;0&quot; if enable else &quot;1&quot;    modifiedContent, count = re.subn(        r&#x27;(&quot;DisableShaderCache&quot;\\s+)&quot;[01]&quot;&#x27;,        r&#x27;\\1&quot;&#123;&#125;&quot;&#x27;.format(newValue),        content    )    if count == 0:        print(&quot;[WARN] 未找到 DisableShaderCache 字段，不做修改&quot;)    else:        with open(configPath, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:            f.write(modifiedContent)        print(f&quot;[OK] 修改 DisableShaderCache = &#123;newValue&#125;&quot;)def launchSteam():    subprocess.Popen(steamPath)def closeSteam():    subprocess.call([&#x27;taskkill&#x27;, &#x27;/F&#x27;, &#x27;/IM&#x27;, &#x27;steam.exe&#x27;],                    stdout=subprocess.DEVNULL,                    stderr=subprocess.DEVNULL)def autoUpdate():    print(&quot;[1] 启用 Shader 缓存&quot;)    modifyShaderCache(enable=True)    print(&quot;[2] 启动 Steam&quot;)    launchSteam()    print(&quot;[3] 等待 10 分钟进行更新&quot;)    time.sleep(600)    print(&quot;[4] 关闭 Steam&quot;)    closeSteam()    print(&quot;[5] 禁用 Shader 缓存&quot;)    modifyShaderCache(enable=False)    print(&quot;[Done] 自动更新流程完成 🎉&quot;)if __name__ == &quot;__main__&quot;:    autoUpdate()\n\n","categories":["工具"],"tags":["Python","脚本"]},{"title":"绘画原创能力培养指南","url":"/2025/02/14/%E7%BB%98%E7%94%BB%E5%8E%9F%E5%88%9B%E8%83%BD%E5%8A%9B%E5%9F%B9%E5%85%BB%E6%8C%87%E5%8D%97/","content":"绘画原创能力培养指南核心训练思路元素分解 → 结构记忆 → 重组创新\n分步训练方法1️⃣ 元素拆分记忆法\n局部聚焦训练\n每日集中记忆1-3个局部结构（如：20种袖口设计/15种鼻型表现）\n建立分类素材库（五官特征/服饰细节/动态造型等）\n\n\n\n2️⃣ 结构化背诵技巧\n几何解构训练\n将复杂图形分解为简单几何体组合，先记外轮廓，然后再补充结构\n记录各部位连接逻辑（如：衣褶形成机理走向规律）\n\n\n记忆量控制\n单次记忆内容控制在A6纸可视范围内\n每个元素记忆时间≤15分钟\n\n\n\n3️⃣ 重组创作流程\n元素拼图法\n试着随机组合记忆元素（如：A角色发型+B服装款式）\n添加过渡结构衔接元素\n\n\n变形训练\n对记忆元素进行比例调整（放大/缩小/拉伸）\n也可以尝试不同风格转换（Q版↔写实）\n\n\n动态重组\n改变元素空间关系（旋转/镜像/叠加）\n结合不同透视角度重组（转角度）\n\n\n\n注意事项\n避免完整临摹超过A5尺寸的作品（收益不高）\n优先记忆通用性强的结构元素\n保持每日15分钟元素重组练习\n建立个人”元素词典”随时记录灵感\n限时速写（3-5分钟）可以强化组合能力\n\n\n核心思想：把创作看作”用记忆元素拼乐高”，应当先确保每个积木块的熟悉度，再追求整体造型的美观度。\n\n","categories":["绘画"],"tags":["绘画","原创","默写"]},{"title":"网页脚本开发常识","url":"/2025/04/08/%E7%BD%91%E9%A1%B5%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91%E5%B8%B8%E8%AF%86/","content":"网页脚本开发常识整理一、基础准备1. 浏览器开发者模式开发网页脚本时，离不开浏览器开发者工具：\n\n打开方式（Chrome / Edge / Firefox）：\n\n快捷键：F12 或 Ctrl+Shift+I\n或右键网页空白处 → 选择“检查”\n\n\n常用面板说明：\n\nElements：查看和修改网页结构\nConsole：查看脚本输出、调试报错、手动执行 JS\nNetwork：查看请求与资源加载\nSources：查看脚本、设置断点调试\n\n\n\n\n2. 安装用户脚本管理器可以安装以下插件之一来编写和运行用户脚本：\n\nTampermonkey（油猴）：最常用、功能齐全  \nViolentmonkey：开源、速度快、兼容性好  \n\n安装后，可直接创建 .user.js 脚本或从网络导入脚本。\n\n二、权限配置常识1. @match 与 @include 的用法\n@match 规定脚本在哪些网页运行  \n注意不是正则表达式，但可以用 * 做通配符  \n\n示例：\n// 匹配所有百度搜索结果页// 正确写法：@match        https://www.baidu.com/s*\n\n2. 允许访问文件网址如果脚本运行在 file:// 页面（本地 HTML），需要打开该权限：\n\n打开 chrome://extensions/\n找到 Tampermonkey → 详情\n开启 允许访问文件网址（Allow access to file URLs）\n\n\n3. @grant 权限声明用于启用特定 API 功能（例如网络请求、剪贴板等）：\n@grant        GM_xmlhttpRequest@grant        GM_setClipboard\n\n三、实用脚本推荐✅ 油猴脚本推荐地址： https://greasyfork.org/zh-CN/scripts/421603功能： 显示当前网站所有可用的脚本。\n✅ CSDN优化与美化地址： https://greasyfork.org/zh-CN/scripts/471071功能： 移除页面广告，优化排版结构，自动展开文章内容，解除复制限制，全面提升阅读流畅度与使用体验。\n✅ 知乎增强地址： https://greasyfork.org/zh-CN/scripts/419081功能： 移除广告干扰，自动展开回答内容，支持快捷键操作，快速搜索所需信息。\n✅ 知乎美化地址： https://greasyfork.org/zh-CN/scripts/412212功能： 优化知乎界面，支持宽屏与暗黑模式，屏蔽广告，自动隐藏顶栏，显示更清爽。\n✅ 全网页面精简地址： https://greasyfork.org/zh-CN/scripts/428960功能： 屏蔽主流网站广告，优化页面结构，自动展开完整内容，屏蔽登录弹窗干扰。\n✅ GitHub增强地址： https://greasyfork.org/zh-CN/scripts/412245功能： 提升下载速度，优化代码高亮显示，扩展快捷键功能，支持文件目录树展示。\n✅ 搜索引擎优化地址： https://greasyfork.org/zh-CN/scripts/14178功能： 去除搜索重定向，显示 Favicon，高亮关键词，支持单列双列切换与自动翻页，界面更清爽高效。\n✅ 网页限制解除地址： https://greasyfork.org/zh-CN/scripts/28497功能： 通用型脚本，解除复制、剪切、选中文本和右键菜单限制，支持多数网站。\n✅ 网盘自动填写访问码地址： https://greasyfork.org/zh-CN/scripts/29762功能： 自动识别并填写网盘提取码，免手动复制，支持记录来源和历史访问，畅通无阻。\n✅ GPT历史问题栏地址： https://scriptcat.org/zh-CN/script-show-page/1972功能： 为 ChatGPT 页面添加侧边栏目录，自动汇总问题并支持快速导航。\n","categories":["工具"],"tags":["脚本"]},{"title":"高级搜索语法","url":"/2025/02/13/%E9%AB%98%E7%BA%A7%E6%90%9C%E7%B4%A2%E8%AF%AD%E6%B3%95/","content":"搜索标题中包含关键词语法：intitle:关键词说明：搜索结果中标题必须包含指定关键词示例：intitle:经济学基础适用引擎：Google、Bing、百度（部分支持）注意事项：  \n\n冒号后无空格  \n支持多关键词（intitle:关键词1 intitle:关键词2）\n\n\n搜索URL路径中包含关键词语法：inurl:关键词说明：搜索结果URL中必须含关键词示例：inurl:login适用引擎：Google、Bing、百度（部分支持）注意事项：  \n\n可搜索路径/参数中的关键词  \n区分大小写（部分搜索引擎）\n\n\n搜索特定文件格式语法：filetype:扩展名 或 ext:扩展名说明：精准查找PDF、Word等格式文件示例：人工智能 filetype:pdf适用引擎：  \n\nGoogle：filetype:pdf  \n百度：filetype:pdf 或 ext:pdf支持格式：pdf/doc/xls/ppt等\n\n\n排除干扰内容语法：-排除词说明：过滤包含指定关键词的结果示例：人工智能 -游戏适用引擎：所有主流搜索引擎注意事项：  \n\n减号前需留空格  \n不支持排除短语（需用引号包裹）\n\n\n指定网站范围语法：site:域名说明：限定搜索结果来源网站示例：科技发展 site:baidu.com适用引擎：所有主流搜索引擎扩展用法：  \n\n搜索子目录：site:baidu.com/docs  \n排除子站：-site:zhidao.baidu.com\n\n\n搜索多个可能关键词语法：OR 或 |说明：搜索包含任意一个关键词的结果示例：苹果手机 OR 三星手机适用引擎：  \n\nGoogle：必须大写OR  \n百度：支持|符号注意事项：需与其他运算符配合使用\n\n\n搜索精确短语语法：&quot;精确短语&quot;说明：搜索包含完全匹配的短语示例：&quot;深度学习的应用&quot;适用引擎：Google、Bing、百度注意事项：引号内的内容必须完全匹配，区分大小写。\n\n搜索指定语言的网页语法：lang:语言代码说明：仅搜索指定语言的网页示例：深度学习 lang:en适用引擎：Google、Bing支持语言：en（英语）、zh（中文）、fr（法语）、de（德语）等。\n搜索相关词汇（已过时）原语法：~关键词说明：曾用于搜索同义词/近义词现状：  \n\nGoogle：已停用（2013年后失效）  \n替代方案：使用自然语言（如教育 相关资源）建议：改用语义搜索或人工扩展关键词\n\n\n","categories":["工具"],"tags":["工具","搜索","语法"]},{"title":"斑斓之镇L2笔记","url":"/2025/03/24/%E6%96%91%E6%96%93%E4%B9%8B%E9%95%87L2%E7%AC%94%E8%AE%B0/","content":"知识点\n    本周目标：光影二分\n        \n            二分是一种绘画技巧，通过一束直射光将物体概括为【亮面】和【暗面】（包括暗部和投影）。\n            二分的形状取决于光照方向和物体的结构，光源要保持统一。\n            观察要点：\n                \n                    优先看投影，其次看亮暗比例。\n                    判断主光源方向，避免被反光迷惑。\n                \n            \n            适合的练习素材：光源单一，避免柔光。\n        \n    \n    练习原因\n        \n            可以暗示物体结构。\n            帮助整理绘制逻辑。\n        \n    \n    练习方法\n        \n            二分抓型时只需接近形状即可，图层属性选【正片叠底】。避免遗漏暗面，画完后对照检查，注意【光源方向】。\n            正片叠底也适用于画黑丝等半透明物体。\n            色彩临摹步骤更新\n                \n                    剪影+二分：填充剪影后，新建图层正片叠底画二分，注意要拉开黑白关系。\n                    固有色及细节：固有色图层放在二分图层下面，颜色准确度可适当放宽，以熟悉流程为主。\n                    二分调色：使用魔棒在固有色区域选择颜色，回到二分图层，用 Ctrl-U 调整二分颜色，准确度可适当放宽（注意如果正片叠底直接抓色难度会很大）。\n                    细化收尾：细节查漏补缺即可。\n                    额外技巧\n                        \n                            高光：出现在比较光滑的、需要有光泽的表面上，一定程度上能反映光源状态，提神效果显著，甚至可以像 ask 老师那样使用对比色。\n                            头发透肤色：新建柔光图层，用皮肤颜色轻喷在头发上。\n                        \n                    \n                \n            \n        \n    \n    额外练习\n        \n            判断光源方向。\n            试试区分交界线和投影。\n            自查方法\n                \n                    找参考\n                    使用 3D 模型辅助。\n                \n            \n        \n    \n    其他说明\n        \n            二分可以帮助整理画面，制造简繁对比。\n            从临摹到创作，速写到写生，都可应用此流程。\n            二分选色提高饱和度，降低明度。\n        \n    \n\n","categories":["绘画"],"tags":["绘画","色彩","二分"]},{"title":"tenten团练6小知识点整理","url":"/2025/05/17/tenten%E5%9B%A2%E7%BB%836%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86/","content":"\n先用直线概括整体形态，再用曲直对比增加趋势，使之更贴近原图轮廓。接着对提炼出的多边形进行夸张处理，要注意构成。\n圆柱有透视的时候，靠近观察者的一端弧度较小，远离的一端弧度较大。\n圆柱的侧边线实际上与椭圆轮廓相交，但由于前缘的遮挡，交点上方的部分不可见。视觉上，这些侧边线看起来像是从椭圆的可见轮廓上，长轴两侧稍微下方“冒”出来的。\n蜈蚣线：圆柱转方块时，就找一个侧面，再连接两边的端点。注意越远离视平线，夹角越尖锐。\n透视正方体中，越短的线条收缩越强烈。但无论如何，Y字形和外轮廓的角不能小于90°。\n面片法：以矩形作为对角线切面，左侧根据相应的角度画辅助线（1/4-1/3的位置最合适，1/3则显得不够有趣）作为方块中距离我们最近的边，再画出对应的对称边（当然需要注意透视，不过影响很小），这样可以比较快速地画出相对准确的方块。注意透视比较大的时候需要进行长度的收缩。\n女性的胸腔比例通常为 4:3:2，男性为 4:4:2。对于身形较为纤细的女性，横向比例可适当缩减至约 4:2.5:2，此时腰部的间距需相应增大。\n胸腔与骨盆（含腰部）长度比为 1:1，腰部只占一小半。二者不必完全连接，因为中间是软骨结构。\n胸腔与骨盆之间的夹角约为 140° 时动态感比较强。\n人体角度比较平的时候，很难判断仰视或俯视，根据经验判断即可，也可以根据动势调整。应该专注于提炼和优化动作，只要是圆柱体，比例合理，角度大致在 140° 左右，就没问题。\n胸腔盆骨：1.找外轮廓宽度，根据比例推算圆柱长度，添加胸腔剖面矩形。2.复制胸腔矩形，调整方块角度大致呈140°作为骨盆矩形，中心轴点对齐（代表腰部转折，但顶胯等动作也可以不对齐，因为中间是软骨结构）。3.调整骨盆宽度，划分出骨盆和腰部，女生的骨盆一般会比胸腔宽一些。4.根据矩形作出圆柱，注意透视比较大的时候需要进行长度的收缩。\n胸腔盆骨2：1.画出夹角140°的矩形作为胸腔和骨盆的外轮廓，注意比例。2.调整矩形的大小和角度，胸腔方块中线对准锁骨中心小凹陷的位置，骨盆方块的中心对准裆部底面。3.用面片法做出体块，男生我们可以以乳头稍微靠外一点的位置作为胸腔的转折分界点，女生就要稍微估计一下；而骨盆的转折点则位于髂前上棘处，也就是胯骨两侧凸起的部位。4.如果觉得作为对角线跟原图不平行，那么也不一定要连到矩形顶点，可以适当调整。\n手臂关节球：正常状态下，从胸腔的顶视角来看，应位于胸腔侧面的中后部，而非正中央。它连接在锁骨的末端，既能随锁骨前后移动，也能在耸肩时随之上抬。从正视角看，尽管我们常将胸腔简化为一个方块，但其真实结构更接近鸡蛋形状，因此手臂关节球会部分嵌入这个方块：大约三分之一在方块内，三分之二在外，整体位置略高于胸腔方块的上缘。手臂可概括为一个圆柱体，通过关节球连接于躯干，其长度大致等于胸腔高度，宽度约等于胸腔宽度的三分之一。当手臂抬起角度小于90°时，锁骨几乎不发生位移，关节球位置保持稳定；而当抬起角度超过90°，锁骨则会以其中点为轴明显向上旋转，带动关节球一同上移，但与水平线夹角不能超过45度。\n大腿关节球（大转子）：首先建立骨盆的方块：① 在骨盆方块的侧面，找到偏上方的中心位置，连接 A1 至 A2；② 接着连接至正面底部 1/4 处的 B1 与 B2，绘制两个圆弧，形成内裤的轮廓。这两个圆弧表示的是大腿与骨盆衔接处大转子的一个截面，大转子就是这个长方体的外接球，我还是认为一定要过弧端点。\n大腿圆柱：代表大转子位置的球体可画可不画（毕竟后面衔接的时候要画），但要理解大腿运动与关节球之间的关系。无论站立还是抬腿，大腿圆柱都应沿球体外侧运动，不能穿过球体或骨盆方块。也就是说，大腿应位于骨盆前侧，避免与方块发生挤压。\n头部方块：可以用六个小方块构建，上方四个、下方两个，整体呈哨子形状。首先找到额头顶部（即美人尖位置），连接至下巴底部，确定面部中线；再找到眉尾，从眉尾向下画一条与中线平行的竖线，确定面部的平面。以此为基础，扩展出一个 3:2:2 的长方体：以眉尾和鼻底作为正面的分界线，耳根作为侧面的分界线，将其划分为八个小方块，最后去掉脖子处的两个下方小方块即可。\n骨盆结构：骨盆顶面形如括号，正面形如水杯，背面形如羊角。括号弧顶贴齐方块边缘线，杯底在距底部约1/4处，宽度约1/3，羊角的棱形部分从1/4处开始，最好向外翘起一些，也就是说顶点不要在中线上。括号与杯口的连接就是所谓的髂前上棘，要有一些弧度，稍微往下转一点。\n通用圆柱方块衔接：一般都是侧面加两个小半圆夹住方块（实际上是肌肉的形状），正面凹进去，两条线是为了强调厚度。\n骨盆与大腿的衔接：大腿圆柱在大腿关节球上运动形成各种下肢的动作，但还需要肌肉将骨盆和大腿衔接到一起，起到这个作用的肌肉就是臀部的肌肉群。如果把臀部看成一个整体，那么可以从骨盆距顶部约1/3位置出发，画一条与骨盆高度相当长度的弧线连接到大腿后外侧，凸起部分大约在骨盆方块底部，对应点位连线即可。然后再将臀部一分为二，先从骨盆下方棱形的底部连接到臀部凸处，再向两侧延伸，分别连线到两边大腿后外侧，勾勒出臀部外侧轮廓；再从大转子凸起位置连线到两条轮廓线，形成臀部肌肉的轮廓，也对应内裤的边线。大腿的部分是正常的圆柱方块衔接。\n大腿小腿衔接：大腿方块要在小腿方块后面，连起来才会好看。腿部都是靠上1/3处凸起，大腿前面凸起，小腿后面凸起。大腿、小腿与膝盖衔接的位置同样是正常的圆柱方块衔接。压缩时，小腿长度不怎么变，主要改变大腿的形状。膝盖跟小腿动，剖面形状没有什么要求，弧线可以，突出侧面也可以。\n小腿结构：小腿靠上1/3凸起，但末端比较细，没有多余的肌肉。因此小腿的凸起在2/3处结束比较合适，剩下的部分用方块概括即可。\n脚部衔接：侧面画一个小菱形把脚和小腿固定到一起即可。\n胸腔结构：胸腔整体像一个躺平的鸡蛋，一端较尖，一端较钝，前侧较扁，后侧较圆。由于“躺平”的姿态，胸腔在前面靠下1/3处和侧面中部（约1/2处）有明显的凸起。胸腔口位于中部靠后，与颈部相连。胸腔下方则形似一个倒置的水杯：正面“杯底”位于下1/3处，宽度约占整体的1/3；背面则在下1/4处，宽度更宽一些。注意，“杯口”两端应落在方块底部的平面上。\n肩颈关系：肩带形似一个衣架，但它可以绕中心点（胸锁关节附近，在胸腔前面一点）转动。连接时，衣架两端的那两条直线，也就是锁骨和肩胛骨的外侧部分，会穿过关节球（肩部球体）的顶部。从脖子中部出发，向衣架两端后方连线，再向衣架曲线转为直线的转折点连线，这几条线共同勾勒出斜方肌的轮廓。三角肌的形状可以类比为被纵向切去一半的陶罐。它的“瓶口平面”对应的是斜方肌所在的倾斜面，构成上缘；中部是三角肌最外凸的位置；底部则连接手臂。可以用这三个水平截面——瓶口、最凸处、底部——作为参考，用三条轮廓线连接它们，就能勾勒出三角肌的外形。\n胸部：女性胸部形如水滴，大约由三段弧线构成，其中靠近身体的一段弧线方向相反；男性将弧线改成比较硬的转折即可。从三角肌中部连线到胸部下缘，可以勾勒出胸大肌的轮廓。\n腰腹：两个杯子相互对应，中间是中空的，用来放置人体的脏器。肚脐眼刚好也在胸腔和骨盆开口中间的位置，画腰部时，如果是男生就直接连接胸腔骨盆的外轮廓；如果是女生，从胸腔下部1/3处连接胸腔骨盆后，再在中间收缩，形成像漏斗的形状即可，不收缩会显得腰很粗。腹外斜肌上面宽下面窄。\n切糕法：将这些躯干方块分类整理后可以发现，各个角度的排列组合起来会形成类似甜甜圈或摩天轮的圆环结构。所以我们可以在这个“圆盘”上切出需要的角度区段，不过要注意“圆盘“的半径不要太大，不然方块变形会很严重。然后借助面片法找到侧面轮廓，绘制俯视/仰视的箭头，这样可以概括绝大多数动态，这就是切糕法。我们的目标不是照搬原图，而是用自己的体系归纳出连贯的体块关系。因为人体的活动性极强，所以我们之前的方块建模只是近似表达，虽然直线清晰易懂，但过于僵硬，难以覆盖各种姿态变化（尤其是大透视或者特别侧面的角度），而且不好看。在这样带有弧度的方块中要切分胸腔骨盆，就不用追求特别精准的点位了，注意形态和转折位置的相似即可。但是结构不能变形，因为方块扭转只是为了表现腰部的扭转。另外要注意女性骨盆较宽，会超出骨盆方块。\n时钟法：如果我们严格按照参考画方块人，比例看起来会很壮，不够美观，所以很多画师画人体时会根据参考做一些转角度变化、比例的变化，让动态的运动趋势更强，看起来更好看。当动态侧面更多的时候，我们也可以按照2D转3D同样的思路，复制侧面的图形，形成躯干体块，同时我们控制挤出面片的厚度，改变胸腔骨盆的方块比例，突出角色的体型特征。挤出面片的方向还可以像时钟一样旋转，向各个角度挤出，甚至不一定是全部往一个方向，这样我们得到的方块也就实现了转角度的变化。但用这个方法的时候，如果有左右扭转，也就是胸腔盆骨朝向不一样的时候，强行套用可能导致腰部长度失真，此时需要适当地调整。\n裙摆结构：裙子基本结构是“上小下大”的圆台形（类似台灯）。上方贴合腰部，不易起褶；下方宽松，容易受力产生褶皱。设计好底面图形后，把最大转折点连接到腰部，就能画出自然的裙摆。\n裙摆花边：花边注意单一图形的大中小节奏的划分即可，无需强调两两间的大小差异，否则会导致裙摆看起来缝的不整齐。\n\n","categories":["绘画"],"tags":["绘画"]},{"title":"CS143-Week1：Introduction","url":"/2025/07/27/CS143-Week1%EF%BC%9AIntroduction/","content":"编程语言与编译器：结构、演进与成本权衡解释器与编码器解释器是实时运行的：它在程序执行过程中逐行读取输入、进行处理，所有操作都是程序运行的一部分。而编译器则不同，它在程序运行前将源代码转换为可执行文件，程序运行时由这个可执行文件读取数据并处理得到结果。某种意义上来说，编译器在这个流程中是离线的。\n最早出现的解释器是一种“快速编码器”，它能够显著提高程序员的编写效率。然而，这种方式会降低程序的运行速度，并占用一定的内存资源——在当时看来，这种开销是相当可观的。随后，人们提出了“公式翻译”的思路，即将数学公式翻译成机器能够处理的形式，从而解决效率与资源占用之间的矛盾。由此诞生了著名的“公式翻译计划”，也就是后来的 Fortran 计划，Fortran 计划大获成功。\nCompiler 5 个部分的简单介绍\n  \n    \n        编译阶段\n        输入（Input）\n        输出（Output）\n        备注\n    \n  \n  \n    \n      词法分析（Lexical Analysis）\n      源代码文本\n      词法单元（tokens）\n      将源代码切分为 tokens，并标注其类别。\n    \n    \n      语法分析（Parsing）\n      token 序列\n      抽象语法树（AST，Abstract Syntax Tree）\n      用树结构表示程序的语法结构。\n    \n    \n      语义分析（Semantic Analysis）\n      AST\n      带注解的语法树\n      由于完整的语义理解过于困难，编译器通常只在 AST 上进行有限的语义检查，如检查类型不一致等错误。\n    \n    \n      优化（Optimization）\n      中间表示（IR）\n      优化后的 IR\n      如常量折叠、死代码删除等，提升程序效率。\n    \n    \n      代码生成（Code Generation）\n      IR\n      汇编代码或其他目标代码\n      也可以生成高级语言或自然语言，视编译器设计而定。\n    \n  \n\n\n如表中所言，语义分析可能非常困难。比如在下面 “even worse” 的例子中，最多可能存在三个不同的 Jack。这也同样是编译器在分析 for 循环中的变量绑定（variable binding）时常见的语义难题之一 —— 同名变量最多可能对应多个不同的实体，给准确理解程序含义带来了巨大挑战。因此，编程语言一般会设定非常严格的规则来避免这个问题。\n\n  \n  语义分析很困难的例子\n\n\n优化也是一个相当棘手的问题。为了提升性能或减少内存使用，我们通常会尝试对中间表示进行优化。但这件事远没有看起来那么简单。例如，我们可能认为 X = Y * 0 可以简单地优化为 X = 0。这在 X 和 Y 都是整数的情况下确实成立，但如果是浮点数，且 Y = NaN，根据浮点数运算标准，X 的值应为 NaN，此时这种优化就会引入错误。\n其他部分与人类对翻译的理解大致一致，但对编译器而言，实现这些部分依然并非易事。\n在 Fortran 时代，词法分析、语法分析、优化和代码生成都被视为较为复杂的任务，而语义分析相对简单。如今，得益于自动化工具的支持，词法分析和语法分析已变得相当成熟；相比之下，语义分析的复杂度显著上升，优化过程则日益庞大且精细，而代码生成反而成为编译流程中相对较小的一部分。不难看出，随着时代的发展，编译器各阶段的复杂性发生了显著变化。\n编程语言设计与使用中的资源权衡问题1. 为什么存在如此多的编程语言？\n不同应用领域对语言的需求不同。\n语言设计目标之间可能存在冲突（如性能 vs. 可读性）。\n\n2. 为什么还不断有新语言诞生？\n程序员培训（Programmer Training） 是编程语言的主要成本，因此在已有语言上演进功能的代价很高。\n创建新语言往往比改造旧语言更具可控性与创新空间。\n\n3. 什么是好的编程语言？\n没有统一标准，不同背景下定义不同。\n常见考量包括：可读性、可维护性、性能、安全性、工具链支持等。\n\n\n相比之下，改进编译器 反而相对更容易一些：可以在不改变语言表面语法的前提下，提升性能或添加工具支持。\n\nCool 语言：为课程设计的语言我们的课程项目是构建一个完整的编译器，具体来说，将把 Cool 语言翻译成 MIPS 汇编语言。\n课程的代码作业主要涵盖编译器的五个模块，其中四个为核心作业内容，第五个模块（编译器优化）为附加部分。除此之外，作业还包括 Cool 语言的基础程序设计。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143"]},{"title":"CS143-Week0：实验环境配置","url":"/2025/07/26/CS143-Week0%EF%BC%9A%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","content":"本来想学 143，找了一通找不到资料，没搞明白到底要干啥，加上压力比较大就打算换南大的编译原理，然后……终于有时间了发现南大的 OJ 炸了……行吧，又打算开始淦 CS143 了。\n环境配置配置跟着课程网站上面搞就可以，可以参考这位大佬写的教程，截至 2025.07.27 仍可使用。\n注意为了使用课程提供的代码，我们需要使用老版本的flex，可以在这里下载，然后正常的安装流程即可。\n再正常安装 bison，配置环境变量，然后在命令行输入 coolc，即可看到 cool 编译器的输出：Class Main is not defined.Compilation halted due to static semantic errors.\n至此环境配置完成。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143"]},{"title":"CS143-PA1：Cool-Language","url":"/2025/07/30/CS143-PA1%EF%BC%9ACool-Language/","content":"代码实现Cool 语言跟 Java 相当相似，语法简单清晰，强调类型和类结构。PA1 要求实现一个简单的栈机器，目的是熟悉语言，但有几个需要注意的地方：\n\n每个类方法都由表达式定义，求值结果即为方法的返回值。因此，常见的写法是在大括号中嵌套代码块，代码块内部用 ; 分隔表达式。类方法定义结束后，需在闭合大括号 &#125; 之后添加分号 ;。\n\nif、while 等控制结构本质上也是表达式，具有返回值，并且结构比较严格。如果要包含多个表达式作为分支体或循环体，需使用代码块 &#123;&#125; 包裹，写法上与类方法类似。\n\n局部变量必须使用 let 关键字进行定义，不能直接赋值给未声明的变量。\n\n\n实现比较简单，我们用 StackNode 类来实现栈，每个节点储存命令信息和下一个节点的地址。注意 Cool 语言强制属性为 private，方法为 public，因此只能通过方法来访问属性。\nclass StackNode&#123;   command: StackCommand;   next: StackNode;   init(co:StackCommand, ne:StackNode): StackNode&#123;      &#123;         command &lt;- co;         next &lt;- ne;         self;      &#125;   &#125;;   getCommand(): StackCommand &#123;      command   &#125;;   getNext(): StackNode &#123;      next   &#125;;   setNext(node: StackNode): StackNode &#123;      next &lt;- node   &#125;;   putOnTop(co: StackCommand): StackNode &#123;      let newNode: StackNode in &#123;         newNode &lt;- (new StackNode).init(co, self);         newNode;      &#125;   &#125;;&#125;;\n然后实现命令，用 StackCommand 作为模板，每个命令或是返回数字，或是返回符号，或是执行命令。class StackCommand&#123;   execute(node:StackNode): StackNode&#123;      let err: StackNode in&#123;         (new IO).out_string(&quot;Undefined Execution!&quot;);         err;      &#125;   &#125;;   getNumber(): Int &#123;      0   &#125;;   getChar(): String &#123;      &quot;Called from base class&quot;   &#125;;&#125;;\n分别实现三种命令，注意 if 指令要完整。\nIntCommand inherits StackCommand &#123;   number: Int;   init(num: Int): SELF_TYPE&#123;      &#123;         number &lt;- num;         self;      &#125;   &#125;;   execute(node:StackNode): StackNode&#123;      node   &#125;;   getNumber(): Int &#123;      number   &#125;;   getChar(): String &#123;      (new A2I).i2a(number)   &#125;;&#125;;class PlusCommand inherits StackCommand &#123;   init(): SELF_TYPE&#123;      self   &#125;;   execute(node:StackNode): StackNode&#123;      let n1: StackNode &lt;- node.getNext(),         n2: StackNode &lt;- n1.getNext(),         sum: Int,         ret: StackNode in&#123;            if (not (isVoid n1)) then               if (not (isVoid n2)) then&#123;                  sum &lt;- n1.getCommand().getNumber() + n2.getCommand().getNumber();                  ret &lt;- (new StackNode).init((new IntCommand).init(sum), n2.getNext());               &#125;               else                  0               fi            else               0            fi;            ret;      &#125;   &#125;;   getChar(): String &#123;      &quot;+&quot;   &#125;;&#125;;class SwapCommand inherits StackCommand &#123;   init(): SELF_TYPE&#123;      self   &#125;;   execute(node:StackNode): StackNode&#123;      let n1: StackNode &lt;- node.getNext(),         n2: StackNode &lt;- n1.getNext(),         ret: StackNode in&#123;            node &lt;- n1;            node.setNext(n2.getNext());            n2.setNext(node);            n2;      &#125;   &#125;;   getChar(): String &#123;      &quot;s&quot;   &#125;;&#125;;\n最后实现 main 函数，根据要求进行调用即可：class Main inherits A2I &#123;   stackTop: StackNode;   printStack(): Object &#123;      let node: StackNode &lt;- stackTop in &#123;         while (not (isvoid node)) loop         &#123;            (new IO).out_string(node.getCommand().getChar());            (new IO).out_string(&quot;\\n&quot;);            node &lt;- node.getNext();         &#125;         pool;      &#125;   &#125;;   pushCommand(command: StackCommand): StackCommand &#123;      &#123;         if (isvoid stackTop) then &#123;            let nil: StackNode in &#123;               stackTop &lt;- (new StackNode).init(command, nil);            &#125;;         &#125; else &#123;            stackTop &lt;- stackTop.putOnTop(command);         &#125; fi;         command;      &#125;   &#125;;   executeStack(inString: String): Object &#123;      &#123;         if (inString = &quot;+&quot;) then         &#123;            pushCommand((new PlusCommand).init());         &#125;         else            if (inString = &quot;s&quot;) then               pushCommand((new SwapCommand).init())            else               if (inString = &quot;d&quot;) then                  printStack()               else                  if (inString = &quot;x&quot;) then                     -- stop                     &#123;                        (new IO).out_string(&quot;stop!\\n&quot;);                        abort();                     &#125;                  else                     if (inString = &quot;e&quot;) then                        let node: StackNode &lt;- stackTop in &#123;                           if (not (isvoid node)) then                              stackTop &lt;- node.getCommand().execute(node)                           else                              0                           fi;                        &#125;                     else                        pushCommand((new IntCommand).init((new A2I).a2i(inString)))                     fi                  fi               fi            fi         fi;      &#125;   &#125;;   main() : Object &#123;      let inString: String in &#123;         while (true) loop         &#123;            (new IO).out_string(&quot;&gt;&quot;);            inString &lt;- (new IO).in_string();            executeStack(inString);         &#125;         pool;      &#125;   &#125;;&#125;;\n小结代码没啥复杂度，写的目的单纯是为了熟悉 Cool 语言，重头戏还在后头嘞~\n现在看来写这玩意对后面是真的没啥用。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143"]},{"title":"CS143-Week2：Lexical Analysis & Finite Automata","url":"/2025/07/30/CS143-Week2%EF%BC%9ALexical-Analysis-Finite-Automata/","content":"词法分析与正则语言基础简介词法分析的主要目标是：\n\n将源代码分割成若干个词法单元（token），每个 token 包含类别和对应的内容；\n为后续语法分析阶段提供结构化的 token 序列。\n\nToken 的类别包括：\n\nIdentifier（标识符，例如变量名）  \nInteger（整数）  \nNumber（数字）\nKeyword（关键字，如 if, while, class 等）  \nOperator（运算符，如 +, -, *, /, = 等）  \nWhitespace（空白字符，如空格、制表符、换行符）\n‘(‘、 ‘)’、 ‘;’、 ‘=’\n……\n\n具体实现：\n\n词法分析器通常从左至右扫描源码文本，一次识别一个 token。  \n为了识别下一个合法的 token，分析器可能需要 向前查看（lookahead），但应尽量减少其长度以提高效率。\n\n例一：Fortran 里的向前查看\n\n\n\n\n\n  \n  例二：C++ 的 bug\n\n\n正则语言我们通常使用 正则语言（regular languages） 来描述每个 token 类别所包含的字符串集合。\n正则语言由五种基本表达式构成：\n\n两个基础表达式：\n\n单个字符（single character）\n空串（epsilon）\n\n\n三个组合表达式：\n\n并集（union）\n连接（concatenation）\n迭代（iteration，也称为闭包）\n\n\n\n正则表达式就是定义在有限字母表 $\\sigma$ 上的基本表达式构成的集合，一般记作 $\\Sigma^*$。\n形式语言形式语言是定义在有限字母表 $\\sigma$ 上的任意字符串构成的集合，不难看出正则表达式是一种形式语言。\n映射函数将句法映射到语义，其优势在于：\n\n便于区分句法和语义两个概念；\n可以将概念的表达方式作为一个独立问题处理。例如：罗马数字和阿拉伯数字表达的是同样的数量，但大多数人使用罗马数字做数学运算会感到困难。这说明概念表达方式的选择会影响理解与计算的难易程度；\n表达式和意义之间不是一一对应的关系，多个表达式可能对应同一个意义。\n\n正则匹配算法正则表达式非常适合用于词法分析，但单纯的匹配判断还不够。在词法分析中，正则匹配算法不仅需要判断字符串是否符合某个模式，还必须准确识别它具体匹配的是哪一个正则表达式，以支持多模式的区分和识别。\n匹配算法如下：\n\n  \n  匹配算法\n\n\n但我们可能会面临几个模式都匹配的情况，这时候一般遵循两种原则：\n\n选择匹配长度最长的模式  \n根据预设的优先级选择模式\n\n如果没有匹配的模式，解决方法通常是：\n\n编译器一般会直接报错  \n但通常不会在词法分析阶段报错，因此会定义一个兜底匹配规则  \n注意兜底规则的优先级应设置为最低\n\n有限自动机基本定义有限自动机是一种用于实现语言规范的数学模型，它是将语言的定义形式（如正则表达式）具体“实现”为可运行的程序逻辑的基础结构。\n一个有限自动机由五个组成部分构成：\n\n输入字母表（Alphabet）：允许的输入符号集合，通常记作 $\\sigma$。\n状态集合（states）：一个有限的状态集合，通常记作 $S$。\n初始状态（start State）：状态机开始时所处的状态，记作 $s_0 \\in S$。\n接受状态集合（Accepting states）：用于判断输入是否被接受的状态集合，记作 $F \\subseteq S$。\n状态转移函数（Transition Function）：定义在每个状态接收某个输入后应转移到哪个状态，记作 $\\delta: S \\times \\Sigma \\rightarrow S$（对 DFA）或 $\\delta: S \\times \\Sigma \\rightarrow 2^S$（对 NFA）。\n\n接受的两个条件是输入已读完和停止状态为接受状态，否则输入将被拒绝。\n常用的可视化表示如下：\n\n  \n  可视化表示\n\n\n\nDFA &amp; NFA核心区别\nDFA：确定性有限自动机  \n\n每个状态对每个输入符号有且仅有一个确定的下一状态。  \n运行速度快，结构简单，适合直接实现。  \n状态数目相对较大。\n\n\nNFA：非确定性有限自动机  \n\n状态对同一输入可以有多个可能的下一状态，甚至允许ε-转换。\n状态数目较少，图结构更紧凑，甚至比对应 DFA 小指数级。  \n运行时存在多个并行路径选择，因此可能进入多个状态，只要有一个是接受状态输入就会被接受。\n\n\n\nε-转换NFA 的关键设计之一是ε-转换，即无需读取输入字符也能从一个状态跳转到另一个状态。这使得每个实际输入符号的转换可以分解为多个步骤，便于简化自动机结构。\n\n  \n  NFA 的例子\n\n\n表达能力NFA、DFA 和正则表达式三者在表达语言的能力上是等价的，它们都能够描述和识别正则语言。\n\n它们只是描述方式不同，但本质表示的语言集合一致。\n\n实现正则语言-&gt;NFA对于每一类正则语言，我们都定义一个对应的 NFA，然后用$\\varepsilon$-转换按照组合规则把所有对应的 NFA 连接起来即可。\n\n  \n  $\\varepsilon$和单个字符\n  \n  并集和连接\n  \n  迭代\n\n\nNFA-&gt;DFA$\\varepsilon$-闭包：从某个状态出发，只通过$\\varepsilon$-转换，能够到达的所有状态集合。子集构造法子集构造法是一种将 NFA 转换为等价的 DFA 的方法。其核心思想是，用 NFA 状态的集合来表示 DFA 的一个状态，以此消除非确定性。\n假设我们有一个 NFA，其五元组为：\n\nS：NFA 的状态集合\nΣ：输入字母表\nδ：NFA 的转移函数，允许 $\\varepsilon$-转换\nS₀：初态\nF：终态集合\n\n现在我们来构造等价的 DFA，其五元组为：\n\nS’：DFA 的状态集合，每个状态都是 NFA 状态的一个子集\nΣ：输入字母表，与 NFA 相同\nδ’：DFA 的转移函数\nS₀’：DFA 的初态\nF’：DFA 的终态集合\n\n1. 确定 DFA 的初态DFA 的初态 $S_0’$ 是 NFA 初态 $S_0$ 的 $\\varepsilon$-闭包。\nS_0' = \\varepsilon\\text{-closure}(\\{S_0\\})2. 确定 DFA 的转移函数 $\\delta’$对于 DFA 中的任意一个状态 C (它是一个 NFA 状态集合) 和一个输入符号 a $\\in$ $\\Sigma$，DFA 的转移函数 $\\delta’$ 定义如下：\n\n第一步：计算 Move(C, a)  从 C 中的每个状态 s 出发，经过输入符号 a 所能到达的所有状态的集合。\n\\text{Move}(C, a) = \\bigcup_{s \\in C} \\delta(s, a)\n第二步：计算 $\\delta’(C, a)$  新的 DFA 状态是 Move(C, a) 的 $\\varepsilon$-闭包。\n\\delta'(C, a) = \\varepsilon\\text{-closure}(\\text{Move}(C, a))  如果这个新的状态集合 $\\delta’(C, a)$ 尚未在 S’ 中，我们就把它添加到 S’ 中，并继续处理它。\n\n\n3. 确定 DFA 的终态集合 $F’$DFA 的终态集合 $F’$ 包含所有至少包含一个 NFA 终态的 DFA 状态。\nF' = \\{ C \\in S' \\mid C \\cap F \\neq \\emptyset \\}4. 确定 DFA 的状态集合 $S’$$S’$ 是在上述过程中所有通过 $\\varepsilon$-闭包和 $\\delta’$ 产生的，且可从 $S_0’$ 到达的状态的集合。\nNFA/DFA-&gt;词法分析器DFA 的二维矩阵表示DFA 的转移函数是单值的，因此可以直接用如下形式：\ndelta[state][symbol] = next_state\n示例：设 $\\Sigma = {a, b}$，状态集合 $Q = {0, 1}$\n\n\n\n\n\na\nb\n\n\n\n\nq₀ (0)\n1\n0\n\n\nq₁ (1)\n1\n0\n\n\n\n\nNFA 的二维矩阵表示NFA 的转移函数是多值的（可能到多个状态），因此我们可以用一个集合矩阵来表示：\ndelta[state][symbol] = &#123;next_state_1, next_state_2, ...&#125;\n示例：设 $\\Sigma = {a, b}$，状态集合 $Q = {0, 1, 2}$\n\n\n\n\n\na\nb\n\n\n\n\nq₀ (0)\n{0, 1}\n∅\n\n\nq₁ (1)\n∅\n{2}\n\n\nq₂ (2)\n∅\n∅\n\n\n\n\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","词法分析","正则表达式"]},{"title":"CS143-Week3：Parsing & Top-Down Parsing","url":"/2025/08/04/CS143-Week3%EF%BC%9AParsing-Top-Down-Parsing/","content":"语法分析基础简介语法分析的主要目标是：\n\n判定有效性并构建语法树： 判断输入的 Token 序列是否符合源语言的语法规则（即是否为一个有效的句子）。如果有效，则成功构建出对应的语法分析树（Parse Tree）或抽象语法树（AST），为后续的语义分析和代码生成提供结构化基础。\n鲁棒地处理语法错误： 当输入序列存在语法错误时，能够以优雅地进行错误恢复，尽可能地继续分析后续代码，报告有意义的错误信息，并尝试构建部分正确的语法树，以提升编译器的用户体验和诊断能力。\n\n事实上，有的编译器并不区分词法分析和语义分析，但大多数编译器仍然选择分开。因为正则表达式相当适合处理词法分析，解析过程再单独处理比较方便。\n上下文无关文法不是所有的 Token 序列都是程序，我们的语法分析需要能够识别有效的程序，并为无效的程序提供错误信息。因此，我们需要一种方法来识别有效的 Token 序列，并设计一种算法来区别有效和无效的 Token 序列。\n在大多数编程语言中，语法结构通常具有递归性，例如一个表达式中可以嵌套另一个表达式，正则表达式的表达能力不足以对它进行处理。一方面，递归结构的次数是动态变化的，所需要的状态数也随之改变，正则表达不了这种动态可变的状态数；另一方面，递归可能会死循环，这更加超出了正则表达式的能力范围。因此，我们需要一种表达能力更强的形式化工具——上下文无关文法（Context-Free Grammars, CFGs），它能自然地描述递归结构。\nCFG 语法CFG 包含四个组成部分：\n\n终结符号集合（Terminal symbols）：文法中用于生成最终字符串的符号集合，通常记作 $T$。这些符号不会被进一步替换，例如字母、数字或标点符号。\n\n非终结符号集合（Non-terminal symbols）：文法中的变量，用于表示语法结构，通常记作 $N$。它们可以被替换为终结符号或其他非终结符号的组合。\n\n开始符号（Start symbol）：文法推导开始的非终结符，通常记作 $S \\in N$。\n\n产生式规则集合（Production rules）：一组替换规则，描述非终结符如何被替换为其他符号，通常形式为 $X \\rightarrow Y_1,Y_2,\\cdots,Y_n$，其中 $X \\in N$，$Y_1,Y_2,\\cdots,Y_n \\in (N \\cup T)^*$。\n\n\nCFG 语言设 $G$ 是一个以 $S$ 为起始符号的上下文无关文法。则 $G$ 所生成的语言 $L(G)$ 定义为：\n\n$ L(G) = \\{ a_1 a_2 \\cdots a_n \\mid a_i \\in T \\cap S \\Rightarrow^* a_1 a_2 \\cdots a_n \\} $\n\n\n在编程语言中，这里的 $a_i$ 通常对应于 Token 的类型。对于一个编程语言的有效 Token 序列，需要满足以下两个核心要求：\n\n可推导性 (Derivability): 该 Token 序列必须能够从文法的起始符号 $S$ 开始，通过反复应用文法中的产生式规则推导出来。这确保了序列在语法结构上是正确的。\n终结符合法性 (Terminal Validity): 序列中的每一个元素（即每一个 Token）都必须属于该 CFG 预先定义的终结符集合。这保证了序列中的基本构成单元是语言所允许的。\n\n推导推导是指从文法的起始符号开始，通过依次应用一个或多个产生式规则，逐步将非终结符替换为其他符号序列，最终生成一个由终结符组成的字符串的过程。\n这个推导过程可以直观地表示为一棵语法分析树（Parse Tree）。具体来说：\n\n树的根节点对应起始符号。\n当推导过程中应用一条产生式规则 $X \\rightarrow Y_1,Y_2,\\cdots,Y_n$ 来替换某个非终结符 $X$ 时，就在树中将 $X$ 作为父节点，并为其创建 $n$ 个子节点，依次对应规则右部的符号 $Y_1,Y_2,\\cdots,Y_n$。\n\n例如，表达式 $ID * ID + ID$ 的语法分析树如图所示：\n\n  \n  语法分析树\n\n\n虽然推导方式可能多种多样，但我们通常只关心最终生成的语法分析树是否相同，具体的推导过程并不重要。为了方便，我们一般使用最左推导或最右推导这两种标准方法。\n歧义文法如果一个文法对于某些句子能够生成多棵不同的语法分析树，那么该文法就是有歧义的。解决文法歧义的方法主要有两种：一是重写文法，从根本上消除歧义；二是允许歧义文法存在，通过引入运算符优先级和结合性规则，在语法分析时确定唯一的解析方式。\n歧义到非歧义文法的转换通常无法自动化，往往需要手动完成，因此在实践中有时难以完全避免。然而，歧义并不一定是文法设计的缺陷。例如，通过引入运算符优先级和结合性规则来处理原本存在歧义的结构，可以在保持文法简洁的同时，显著提升语言的易用性和表达的自然性。\n注意：我们需要谨慎使用优先级和结合性等声明，因为它们可能引发连锁反应，对语法分析的结果产生非预期的影响，导致解析器选择错误的解析路径。因此，每次修改这类声明后，都必须对文法进行全面的测试，以验证其正确性并确保语法分析行为符合预期。\n错误处理在程序开发和编译过程中，可能会出现多种类型的错误，通常可以在不同的阶段被检测到：\n\n\n\n\n错误类型 (Error Kind)\n示例 (Example)\n检测阶段/工具 (Detected by …)\n\n\n\n\n词法错误\n$ (无效字符)，12ab (无效的字面量)\n词法分析器\n\n\n语法错误\n.. +*%.. (无效的符号序列)\n语法分析器\n\n\n语义错误\nint x; y = x + &quot;hello&quot;; (类型不匹配)\n语义分析器/类型检查器\n\n\n正确性错误\n程序逻辑错误，如死循环、算法实现错误、计算结果不符合预期\n测试人员/用户\n\n\n\n\n错误处理器应满足以下要求：\n\n准确清晰地报告错误：提供明确、易懂的错误信息，帮助用户准确定位问题所在。\n快速从错误中恢复：在检测到错误后，能迅速采取策略恢复解析过程，尽可能继续分析后续代码，以发现更多潜在错误。\n不影响正确代码的编译效率：错误处理机制的设计应高效，确保在处理合法、无错误的代码时，不会显著增加编译时间或消耗过多资源。\n\n在语法分析的错误处理中，主要有三种策略，工程实践中通常采用前两种：\n\n恐慌模式：在检测到语法错误后，跳过输入流中后续的若干 Token（例如，直到遇到分号 ; 或右大括号 &#125; 等预定义的同步符号），然后尝试从下一个“安全”的位置恢复并继续语法分析。该方法实现简单、高效，能够快速从错误中恢复，有助于在一次编译过程中发现并报告多个错误。例如，在 Bison 等解析器生成工具中，可通过 error 标记来实现此类错误恢复机制。\n错误产生式：在文法中显式地加入一些特殊的产生式规则，用于匹配常见的、可预见的编程错误模式（例如，省略变量与常量间的乘号或漏掉两个表达式之间的运算符）。这使得错误输入也能被“合法”地解析，便于生成针对性的错误信息。但这种方法会增加文法本身的复杂性。\n自动局部/全局纠错：该方法试图自动推断出最可能的、正确的输入序列（例如，通过插入、删除或替换符号），并基于此进行后续分析。虽然在理论上很吸引人，但由于实现复杂、计算开销大且纠错结果可能不准确，加上现代编译器的编译速度已足够快，目前在实际工程中应用较少。\n\n抽象语法树抽象语法树（AST） 是对语法分析树的精简和抽象。语法分析树包含了文法推导的全部细节，信息较为冗余，而后续的编译阶段（如语义分析、优化、代码生成）并不需要这些全部信息，所以需要简化。\nAST 通过以下方式简化结构：\n\n省略无关符号：如括号 ()、分号 ; 等仅用于语法分隔但不影响语义的终结符。\n合并单产规则路径：将只有一个子节点的非终结符节点与其父节点或子节点合并，消除冗余的中间层级。简化后，会得到一棵结构更加简单清晰的树，能够更直接地反映程序的语法结构和层次关系：\n\n\n  \n  抽象语法树\n\n\n递归下降解析简介递归下降解析是一种简单的自顶向下的语法分析算法。\n\n核心思想：从文法的起始符号开始，将语法结构视为一棵潜在的树，解析过程类似于对该树进行深度优先遍历，按照产生式规则从前往后地尝试匹配输入的 Token 序列。\n解析过程：\n如果某个产生式的选择匹配失败，则进行回溯，即撤销之前的操作，恢复状态，并尝试该非终结符的其他备选产生式。\n如果匹配成功，则输入指针向前移动一个或多个 Token。\n\n\n构建结果：该算法最终会构建出一棵语法分析树，其中所有的 Token 都位于树的叶节点上。\n\n实现定义\n$TOKEN$：表示某种类型的 Token。\n全局指针 $next$：指向输入 Token 序列中的下一个待处理的 Token。\n\n辅助函数我们需要三个辅助函数：\n\n$term(TOKEN \\, tok)$：检查当前 $next$ 指针指向的 Token 是否与给定的终结符 $tok$ 匹配。  bool term(TOKEN tok) &#123;    return *next++ == tok;&#125;\n$S_n()$：检查非终结符 $S$ 的第 $n$ 个产生式规则是否匹配。\n$S()$：尝试 $S$ 的所有备选产生式规则。它会依次尝试 $S_1()$, $S_2()$, …，一旦某个规则匹配成功就返回 $true$；如果所有规则都失败，则返回 $false$。\n\n通过这三个函数的配合——term 进行终结符匹配，S_n 实现具体产生式匹配，S 管理选择与回溯——即可实现对语法结构的递归下降解析。\n\n  \n  一个具体例子\n\n\n看例子可能会清晰一些，就是利用递归实现拆分，但会有一些问题，比如 $int * int$ 匹配完第一个 $int$ 就会退出，本质上是因为匹配一旦成功就不会回溯。为了解决这个问题，我们需要更加精细的回溯机制，也就是说，即使某条路径部分成功，我们也需要能够回退并尝试其他更完整的匹配路径。实现这样的机制并不困难，但在此不作展开。\n左递归问题左递归文法是指文法中存在某个非终结符 $S$，使得可以通过一系列非空推导，从 $S$ 推导出以 $S$ 自身开头的符号串，即存在推导过程 $S \\Rightarrow^+ S\\alpha$（其中 $\\alpha$ 是任意符号串）。尽管从文法推导的角度看，$\\alpha$ 是有限的，但会导致解析函数在未消耗任何输入的情况下无限地调用自身，这对解析器来说是致命的。\n左递归会带来两个主要问题：\n\n无限死循环：在自顶向下的解析器（如递归下降）中，直接为左递归产生式编写函数会导致函数无限递归调用自身，从而引发栈溢出或无限循环。这个问题相对容易识别，也容易通过消除左递归来解决。\n解析顺序问题：在自底向上解析过程中，虽然输入符号是从左到右依次读取的，但归约操作却是从最右边的子树开始，逐步向左进行。这种“从右向左”的归约顺序与“从左到右”的输入顺序不一致，很不直观，增加了理解和调试的难度。解决方案：\n\n左递归问题是可解的，并且有成熟的算法可以自动消除直接和间接左递归。然而在实践中，开发者更倾向于通过引入新的非终结符和右递归规则来手动消除左递归。例如，将左递归规则：A → A α | β转换为等价的右递归形式：A  → β A&#x27;A&#x27; → α A&#x27; | ε\n之所以常采用手动方式，一方面是因为对于常见的语法结构（如表达式），手动转换模式固定且易于理解；另一方面，手动方法提供了更大的灵活性，可以根据实际需求定制解决方案。所以一般都采用手动消除的方法。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","语法分析","抽象语法树","语法分析树","递归下降解析"]},{"title":"CS143-Week4：Bottom-Up Parsing","url":"/2025/08/06/CS143-Week4%EF%BC%9ABottom-Up-Parsing/","content":"预测解析简介预测解析是一种无需回溯的自顶向下的语法分析算法。\n\n核心思想：为文法的每个非终结符设计一个确定的解析过程，根据当前输入的 Token 预测应使用的产生式规则，从而直接选择正确的分支进行匹配，避免回溯。\n解析过程：\n构建预测分析表\n对每个非终结符，预先计算其 FIRST 集（所有产生式右部能推导出的第一个终结符的集合）和 FOLLOW 集（在某些句型中可能紧跟该非终结符的终结符集合）。\n对于每个产生式 $S \\to \\alpha$：\n对每一个 $a \\in \\text{FIRST}(\\alpha)$ 且 $a \\neq \\varepsilon$，将产生式 $S \\to \\alpha$ 填入分析表的 $M[S, a]$ 位置。\n如果 $\\varepsilon \\in \\text{FIRST}(\\alpha)$，则对每一个 $b \\in \\text{FOLLOW}(S)$，将产生式 $S \\to \\alpha$ 填入分析表的 $M[S, b]$ 位置。\n\n预测分析表的例子\n\n\n\n\n\n解析输入串\n初始化分析栈，栈底为 $ {$} $，其上为文法起始符号；\n每次查看栈顶符号 $X$ 和当前输入符号 $a$：\n若 $X$ 是终结符且 $X = a$，则弹出栈顶，读取下一个输入符号；\n若 $X$ 是非终结符，查找分析表 $M[X, a]$：\n若存在对应产生式 $X \\to \\alpha$，则弹出 $X$，并将 $\\alpha$ 的符号从右到左依次压入栈；\n若查表为空或无定义，则报错（语法错误）；\n\n\n重复上述过程，直到栈为空且输入符号流结束（即均到达 $ {$} $），表示解析成功。\n\n\n\n\n\n\n构建结果：成功时构建出一棵语法分析树，所有 Token 位于叶节点，且解析过程是线性的，无回溯开销。\n要求：文法必须是 LL(1) 文法。\n\nLL(1)文法概念LL(1) 文法是一种适用于自顶向下语法分析的 CFG，其名称中的“LL”表示从左到右扫描输入并构造最左推导，“1”表示分析时只需查看一个输入符号即可确定使用哪个产生式。这类文法要求无左递归、无二义性，并且每个非终结符的所有候选产生式的 FIRST 集互不相交，若某产生式可推出空串，则其 FIRST 集与 FOLLOW 集也不相交。\n由于 LL(1) 文法具有确定性，可以构造无冲突的预测分析表，使得语法分析过程高效且无需回溯，因此广泛被应用于编译器设计中，尤其适合处理结构清晰的语言构造。但并非所有文法都能转化为 LL(1) 文法，复杂语言可能需要更强的分析方法。\n左因子分解若 $S \\to \\alpha\\beta_1 \\mid \\alpha\\beta_2$，且 $\\alpha$ 是非空终结符串，则 $\\text{FIRST}(\\alpha\\beta_1) \\cap \\text{FIRST}(\\alpha\\beta_2) \\neq \\emptyset$，无法通过下一个输入符号唯一确定使用哪个产生式。我们可以通过提取公共左因子来解决这个问题。\n设公共左因子为 $\\alpha$，引入新非终结符 $S’$：\n\n原式：$ S \\to \\alpha\\beta_1 \\mid \\alpha\\beta_2 \\mid \\cdots \\mid \\alpha\\beta_n $\n改写为：  $ S \\to \\alpha S’ $  $ S’ \\to \\beta_1 \\mid \\beta_2 \\mid \\cdots \\mid \\beta_n $\n\n改写后的形式消除了原非终结符 $S$ 所带来的预测冲突。此时，$\\text{FIRST}(\\beta_1), \\text{FIRST}(\\beta_2), \\dots$ 应两两不相交；如果某个 $\\beta_i$ 可导出空串（即 $\\beta_i \\Rightarrow^* \\varepsilon$），则还必须确保 $\\text{FOLLOW}(S’)$ 与其他各 $\\text{FIRST}(\\beta_j)$ 也无交集，从而满足 LL(1) 文法的判定条件。\nFIRST &amp; FOLLOW 集FIRST 集的确定\n定义：对于一个符号串 $\\alpha$（可以是非终结符、终结符或它们的组合），$FIRST(\\alpha)$ 是所有可以从 $\\alpha$ 开始推导出的字符串的第一个终结符的集合。如果 $\\alpha$ 能够推导出空串 $\\varepsilon$，则 $\\varepsilon$ 也属于 $FIRST(\\alpha)$。\n算法步骤：\n\n如果 $x$ 是终结符，则 $FIRST(x) = {x}$。\n对于非终结符 $A$ 的每个产生式 $A \\to \\alpha_1 \\alpha_2 \\dots \\alpha_n$：\n将 $FIRST(\\alpha_1)$ 中除去 $\\varepsilon$ 的元素加入 $FIRST(A)$；\n如果 $\\varepsilon \\in FIRST(\\alpha_1)$，则继续将 $FIRST(\\alpha_2)$ 中除 $\\varepsilon$ 的元素加入 $FIRST(A)$，依此类推；\n如果所有 $\\alpha_i\\ (i=1,2,\\dots,n)$ 都满足 $\\varepsilon \\in FIRST(\\alpha_i)$，则将 $\\varepsilon$ 加入 $FIRST(A)$。\n\n\n\n\n\nFOLLOW 集的确定\n定义：$FOLLOW(A)$ 是所有在某个句型中紧跟在非终结符 $A$ 后面的终结符的集合。如果 $A$ 可以出现在句子的末尾，则输入结束符号 ${$}$（表示输入结束）也属于 $FOLLOW(A)$。\n算法步骤：\n\n初始化： $ FOLLOW(S) = \\{ \\$ \\} $ ，其中 $S$ 是文法的开始符号。\n对于每个产生式 $A \\to \\alpha B \\beta$：\n将 $FIRST(\\beta)$ 中除 $\\varepsilon$ 的元素加入 $FOLLOW(B)$；\n如果 $\\varepsilon \\in FIRST(\\beta)$ 或 $\\beta \\Rightarrow^* \\varepsilon$，则将 $FOLLOW(A)$ 中的所有元素加入 $FOLLOW(B)$。\n\n\n如果存在产生式 $A \\to \\alpha B$ 或 $A \\to \\alpha B \\beta$ 且 $\\beta \\Rightarrow^* \\varepsilon$，重复步骤 2，直到所有 $FOLLOW$ 集稳定为止。\n\n\n\n自底向上解析简介自底向上解析 是一种常见的语法分析方法，广泛用于现代编译器中，适合处理复杂语言的语法结构。\n它的基本思路是从输入的 Token 序列开始，一步步把它们组合成更大的语法单位，比如表达式、语句，最终还原出整个程序的结构。整个解析过程主要靠两个动作来推进：\n\n移进（Shift）：把当前输入的一个单词读进来，放到一个临时的存储区域（叫分析栈），等待后续处理。\n归约（Reduce）：当发现栈顶的一些符号正好符合某个语法规则的右边部分，就用这个规则的左边非终结符来代替它们。比如发现“表达式 + 项”可以归约为“表达式”，这就是一次归约。\n\n\n  \n  自底向上解析示例\n\n\n自底向上分析是语法推导的逆过程，具体对应最右推导的反向执行。也就是说，归约的顺序与最右推导的展开步骤相反，因此在归约过程中，被归约部分的右侧总是由尚未处理的终结符构成。\n在自底向上解析过程中，最关键的是找到当前可以归约的部分，这个部分称为“句柄”。句柄代表了下一步应当应用的语法规则。\n一个重要事实是：句柄总是位于分析栈的顶部，而不会隐藏在栈的中间或底部。或者说，句柄的右端位置是不减的。这是因为自底向上分析对应的是最右推导的逆过程，若句柄的右端位置回退，将与最右推导的顺序相冲突。但这并不意味着一旦在栈顶出现了可归约的结构就需要归约，由于上下文的限制，有些符号串虽然形式上匹配某个产生式的右部，但并不是此时应归约的句柄，贸然归约可能导致分析错误。\n还有一个重要的性质是：在分析过程中可能出现的所有合法前缀构成的集合是一个正则语言。进一步地，每一个合法前缀都唯一对应一组可能的语法位置，我们用 LR 项（如 E → .(T)、E → (.T)）来表示这些位置，其中“点”表示当前正在尝试匹配的语法规则已经识别到了哪一步。\n之所以构成正则语言，是因为：\n\n文法的产生式是有限的；\n每个产生式可以扩展为一组 LR 项（如 E → .(T)、E → (.T)、E → (T.)、E → (T).）；\n所有这些项的集合是有限的，而“移进”和“归约”操作对应于项之间基于输入符号的转移。\n\n于是，我们可以构造一个有限状态自动机，每个状态是一个项集，表示当前可能所处的所有语法位置；每条边由一个文法符号标记，表示在读入该符号后，自动机将转移到另一个状态。以文法 $ E \\to (T) $ 为例，状态转移如下：\n\n\n\n\n状态\n输入符号\n动作\n\n\n\n\n$\\{ E \\to \\cdot(T) \\}$\n(\n移进，进入状态 $\\{ E \\to ( \\cdot T) \\}$\n\n\n$\\{ E \\to ( \\cdot T) \\}$\nid\n移进，进入状态 $\\{ E \\to (T \\cdot ) \\}$\n\n\n$\\{ E \\to (T \\cdot ) \\}$\n)\n归约，使用产生式 $ E \\to (T) $\n\n\n\n\n从而我们能提前构造出这个自动机（也就是生成 LR 分析表），用查表的方式快速决定每一步该做什么。这使得解析过程从可能的 $O(n^2)$ 甚至更慢，变成确定性的 $O(n)$，大大提高了效率。\n在实现上，自底向上解析通常使用一个栈来保存已经处理的符号和状态，再配合一张分析表来决定每一步该做什么。分析表告诉解析器：在某个状态下，看到某个输入符号时，应该移进、归约、接受还是报错。整个过程是自动推进的，不需要回溯。\n相比自顶向下的方法，自底向上解析更强大。它可以处理左递归文法，不需要对文法做额外的变换，比如消除左递归或提取左因子。这使得它可以更自然地描述编程语言中的常见结构，比如连续的加减乘除表达式。正因为这些优点，自底向上解析成为工业级编译器的主流选择。许多语法生成工具，比如 Yacc 和 Bison，都是基于这种思想实现的。\n\n递归下降解析就像普通的递归版线段树，直观自然但依赖系统调用栈，控制不够灵活；而自底向上解析则类似于 zkw 线段树，利用文法的结构性质（如最右推导、句柄总在栈顶），将原本隐式的递归过程转化为显式的迭代操作，通过手动维护分析栈和查表驱动的方式，把复杂的递归逻辑“展平”，不仅避免了函数调用开销，还提升了效率与表达能力。所以，当问题具有良好的结构规律时，我们或许总能够将递归转化为迭代，用数据结构模拟控制流，从而提升性能或化简算法。\n\n解析冲突在构造自底向上解析器时，可能会遇到某些状态中存在多个合法动作的情况。我们将其称为解析冲突，根据动作类型的不同，冲突分为两类：\n1. 移进-归约冲突（Shift-Reduce Conflict）\n定义：在某个分析状态中，既可以移进（shift）下一个输入符号，也可以对栈顶内容进行归约（reduce），且两种操作都可能导向一个合法的最终解析结果。\n是否严重：相对不那么严重，有时是语言设计中的自然歧义，可以通过优先级规则或编译器提示解决。\n常见例子：\n\n悬空 else：if (cond1) if (cond2) S1; else S2;\n这个 else 应该属于外层 if 还是内层 if？移进：继续看是否还有后续结构归约：把内层 if 语句归约为完整语句→ 出现冲突。\n表达式中的运算符优先级：如 id + id * id，若文法未明确优先级，可能在 + 后不确定是移进 * 还是先归约左侧。\n\n\n解决方法：\n\n在解析器生成器（如 Yacc/Bison）中声明运算符优先级和结合性。\n默认策略：通常“移进”优先于“归约”，这能解决大多数实际问题。\n\n\n\n2. 归约-归约冲突（Reduce-Reduce Conflict）\n定义：在某个分析状态中，栈顶内容可以被归约为两个或多个不同的非终结符，即存在多个归约动作都合法。\n是否严重：非常严重，通常表明文法设计存在问题，如歧义、结构混乱或命名冲突。\n常见例子：\n\n两个不同非终结符有相同的右部：Func → id &#x27;(&#x27; ArgList &#x27;)&#x27;FuncCall → id &#x27;(&#x27; ArgList &#x27;)&#x27;\n当解析器看到 id(...) 时，无法判断是归约为 Func 还是 FuncCall。\n类型系统或作用域相关的歧义文法。\n\n\n解决方法：\n\n重构文法，消除歧义，确保每个句柄唯一对应一个产生式。\n归约-归约冲突通常不能靠优先级解决，必须修改文法。\n\n\n\n句柄识别在自底向上语法分析中，句柄的识别是整个过程的核心。然而，一个严峻的事实是：目前并不存在适用于所有 CFG 的高效算法来直接识别句柄。句柄的正确选择依赖于全局归约路径，而盲目尝试所有可能的归约会带来指数级开销，显然不可行。\n但幸运的是，存在一系列有效的启发式方法来“猜测”当前栈顶是否为句柄。这些方法基于语法规则的局部特征和输入符号进行判断，能够在许多实际场景中快速做出正确决策。更进一步，对于一大类精心设计的上下文无关文法（如 LL、LR 文法），这些启发式策略总是能准确识别句柄。因此，虽然通用句柄识别是困难的，但在实际编程语言的文法约束下，我们依然能够构建出强大而高效的解析器。\n\n  \n  各种 CFG 文法的关系\n\n\n在 LR 分析中，分析栈中的内容是由产生式右部的前缀构成的合法前缀。这些前缀虽然尚未完整匹配，但结构是语法允许的，并且最终都会归约为相应的非终结符。句柄识别的目标，就是在这些合法前缀中找到已经完整匹配的某个产生式右部。\n关键在于：这些部分右部是以嵌套方式组织的。当前归约出的非终结符，恰好作为上一层产生式右部中“尚未匹配部分”的开头，从而填补其结构的“缺失后缀”。因此，合法前缀本身就隐含了语法的层次嵌套关系。\n句柄，就是分析栈顶刚刚完成匹配的那个产生式右部，在 LR 项中对应形如 A → α · 的项。一旦识别出这样的项，且当前输入符号允许归约，就可以将其归约为左部非终结符，从而自底向上逐步构建出语法树，具体算法如下：\n\n扩展文法（添加起始标记）为原始文法 $ G $ 添加一个新的开始产生式：$ S’ \\to S $其中 $ S $ 是原开始符号，$ S’ $ 是新引入的起始符号。➤ 目的：唯一标识整个输入已被接受（当归约到 $ S’ \\to S $ 时，分析成功）。\n\n构造项作为 NFA 状态如前所述，我们定义项表示一个产生式的分析进度，形式为：$ A \\to \\alpha \\cdot \\beta $其中点 $ \\cdot $ 表示当前已识别到哪一部分。➤ 所有项的集合构成 NFA 的状态，包括新增产生式 $ S’ \\to S $ 对应的项。\n\n构建移进转移对于当前项 $ E \\to \\alpha \\cdot X \\beta\\,$，其中 $ X $ 是一个终结符：➤ 添加一条按 $ X $ 标记的转移：  \n\nE \\to \\alpha \\cdot X\\beta \\xrightarrow{X} E \\to \\alpha X \\cdot \\beta➤ 这表示当输入符号为 $ X $ 时，执行“移进”操作：  \n\n压栈：将终结符 $ X $ 压入符号栈，同时将新状态（对应 $ E \\to \\alpha X \\cdot \\beta \\,$ 所在的项集）压入状态栈；  \n继续分析：推进分析进度。\n\n\n构建 ε-转移对于当前项 $ E \\to \\alpha \\cdot X\\beta \\,$，表示我们已经识别了 $ \\alpha $，现在需要构造一个非终结符 $ X $，以便继续完成 $ E $ 的推导。  \n因此，对于每个产生式 $ X \\to \\gamma $，添加一条 ε-转移：\n\nE \\to \\alpha \\cdot X\\beta \\xrightarrow{\\varepsilon} X \\to \\cdot \\gamma➤ 这表示：为了完成 $ E $，接下来需要生成一个 $ X $，因此必须提前准备 $ X $ 的所有可能推导方式。➤ 这里不会压入状态栈或符号栈，因为没有输入符号。\n\n识别句柄当某个项的形式为：$ A \\to \\alpha \\cdot $（点在右部末尾）➤ 表示栈中已完整匹配 $ \\alpha $，它就是当前可归约的句柄。➤ 若当前输入符号属于 $ A $ 的合法展望符（如 $FOLLOW(A)$），则执行归约。\n\n执行归约当识别出句柄 $ \\alpha $ 并决定归约时：\n\n弹出分析栈：将栈顶对应 $ \\alpha $ 的所有符号和状态对依次弹出（每个符号对应一个状态）；\n确定新状态：此时栈顶状态为 $ s$，查表获取\n\n\\text{goto}[s, A] = s'表示当前状态 $s$ 接受非终结符 $A$ 后应跳转至的新状态 $s’$；\n\n压栈：将归约得到的非终结符 $A$ 与状态 $s’$ 一起压入栈；\n继续分析：进入下一轮移进或归约判断。\n\n\n\nSLR咕咕咕\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","语法分析","预测解析"]},{"title":"Hexo 数学公式的转义 BUG","url":"/2025/08/06/Hexo-%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E7%9A%84%E8%BD%AC%E4%B9%89-BUG/","content":"在使用 Hexo 编写数学公式时，可能会遇到这样一个奇怪现象：\n\n在行内公式中，\\&#123; 和 \\&#125; 无法正常显示花括号 &#123;&#125;。\n\n例如：SET(S) = \\&#123; \\$ \\&#125; 渲染成 $ SET(S) = { $ } $  → ❌ 花括号不显示SET(S) = \\\\&#123; \\$ \\\\&#125; 渲染成 $ SET(S) = \\{ \\$ \\} $ → ✅ 正常显示\n原因分析这是由于 Hexo 的渲染流程中存在 多层解析，导致 转义层级冲突：\n\nHexo 使用 Markdown 渲染器先处理文本  \n\n这些渲染器有时会将 \\&#123; 中的反斜杠提前处理或忽略。\n特别是当渲染器对 LaTeX 支持不完整时，\\&#123; 可能未被正确传递给 MathJax/KaTeX。\n\n\nMathJax/KaTeX 需要 \\&#123; 来显示 &#123;  \n\n在 LaTeX 中，&#123; 是分组符号，要显示字面量 &#123; 必须使用 \\&#123;。\n但如果 \\&#123; 没有完整传入 MathJax，它就无法识别。\n\n\n\n解决方案：双重转义\n写 \\\\&#123; 时，Markdown 渲染器会将 \\\\ 解析为字面量 \\，输出 \\&#123;。\n然后 MathJax 接收到 \\&#123;，正确渲染为 &#123;。\n\n","categories":["DEBUG"],"tags":["DEBUG","Latex"]},{"title":"CS143-PA3：Parsing","url":"/2025/08/10/CS143-PA3%EF%BC%9AParsing/","content":"\n前排提醒：本文采用 C++ 实现，如果使用 java 建议参考其他文章。\n\n语法分析准备工作本次作业的目标是：使用 Bison 实现一个可以将 Token 序列转换为 AST 的语法分析器。\n在 assignments/PA3 目录下执行命令：\nmake parser\n会生成一个名为 parser 的可执行文件，可以通过运行 ./myparser test.cl 来对指定文件进行词法分析。这里的 myparser 是一个 csh 脚本，如果用的是 bash 的话需要将开头的 csh 改成 bash，或者直接运行\n./lexer test.cl | ./parser\n在编译过程中，Bison 生成的 cool-parse.cc 负责语法分析的主要实现；parser-phase.cc 提供程序入口，负责驱动并测试语法分析器；cool-tree.aps 定义 AST 结构，并自动生成 cool-tree.h 与 cool-tree.cc 以支持树节点的构造与处理，剩下的 tokens-lex.cc、dumptype.cc 和 handle_flags.cc 等文件为辅助代码，不需要修改。\n这里所用到的 Bison 是一种语法分析器生成工具，它能够根据上下文无关文法规则自动生成语法分析器。其作用是将 .y 文件转换为 C/C++ 源码（如 cool-parse.cc），并作为库函数与其他源码一起编译。目前我们通过 parser-phase.cc 来调用生成的语法分析器代码，后续可能会通过编译器的其他阶段（如语义分析器）来调用。\nBison 的使用可以通过阅读 Bison 的官方文档 以及 handouts 目录下的相关 PDF 来了解，比如 PA3 的作业说明里面有相关介绍。\n回到 PA3，我们的核心任务是完善 cool.y 文件，使其能够正确地进行语法分析。\nBison 简单介绍文件结构概述Bison 文件由三部分组成，每个部分之间用 %% 隔开：\ndefinitions%%rules%%user code\n1. definitions（定义区）这一部分用于声明语法分析器所需的各种信息，类似于 C 文件的头部。在这里可以：\n\n声明终结符：告诉 Bison 所有词法单元（由 Flex 提供）；\n声明非终结符的属性类型：通过 %type 指定每个非终结符使用 union 中的哪个成员；\n定义属性的联合体：统一表示所有语法树节点或值的类型；\n指定起始符号（可选）；\n包含头文件、定义宏或声明全局变量（用 %&#123; ... %&#125; 包裹）。\n\n常用声明语法：\n\n%union：定义所有可能的属性类型，类型不同储存用到的字段也不同（通常是语法树节点指针）：\n%union &#123;    int           int_val;    char*         string_val;    Program       program;    Expression    expr;    ···&#125;\n\n%token：声明终结符，可带类型（即使用 union 中的哪个字段），还可手动指定终结符数字编号：\n%token &lt;int_val&gt;  INTEGER%token &lt;string_val&gt; IDENTIFIER STRING_CONST%token IF THEN ELSE FI /* 手动指定编号*/%token INHERITS 263 LET 264 LOOP 265 POOL 266 THEN 267 WHILE 268  \n\n%type：声明非终结符储存的使用的字段：\n%type &lt;program&gt; program%type &lt;expr&gt;    expression if_expr while_expr%type &lt;stmt&gt;    statement assign_stmt block_stmt\n\n%start：指定文法的开始符号（默认为第一条规则的左部）：\n%start program\n\n\n\n注意：所有带属性的终结符和非终结符都必须用 %token 或 %type 声明储存使用的字段，否则 Bison 不知道如何存储它们的值，会导致运行时错误。\n\n2. rules（语法规则区）这是 Bison 文件的核心部分，我们在这里定义 CFG，描述语言的语法结构。\n每条规则的形式如下：\n非终结符: 产生式右部    &#123; 动作代码 &#125;        | 产生式右部    &#123; 动作代码 &#125;        ;\n\n非终结符：必须在 %type 中声明过（如果有属性）；\n产生式右部：由终结符、非终结符或其他符号组成；\n&#123; 动作代码 &#125;：当该规则被归约时执行的 C/C++ 代码，通常用于构造语法树节点。\n\n示例：expression: expression &#x27;+&#x27; expression          &#123; $$ = plus($1, $3); &#125;  // $1 是左 expression，$3 是右 expression，$$ 是当前 expression        | IDENTIFIER          &#123; $$ = identifier($1); &#125;        | INTEGER          &#123; $$ = integer_const($1); &#125;        ;\n重要规则：\n每条规则必须以 ; 结尾；\n$1, $2, …, $n 表示右部第 1 到第 n 个符号的属性值；\n$$$$ 表示当前非终结符的属性值（即归约后的结果）；\n动作代码必须用 &#123;&#125; 括起来，且不能与规则在同一行（除非缩进，一般另起一行）；\n多条规则可以用 | 连接，表示“或”的关系。\n\n3. user code（用户代码区）这一部分用于编写辅助函数、语法树构造函数、错误处理函数等 C/C++ 代码。\n可以在这里定义：\n\n语法树节点的构造函数（如 plus(), identifier()）；\n错误报告函数（如 yyerror(const char *msg)）；\n工具函数、内存管理逻辑等。\n\n例如：\nvoid yyerror(const char *msg) &#123;    fprintf(stderr, &quot;Parse error at line %d: %s\\n&quot;, lineno, msg);&#125;int main() &#123;    yyparse();    return 0;&#125;\n\n注意：yyerror 是 Bison 自动生成调用的错误处理函数，必须实现。\n\n属性与语义值Bison 支持带属性的文法符号，用于 AST 或传递信息。\n\n所有属性通过 %union 统一管理；\n每个符号的属性值通过 $$$$, $1, $2 等访问；\n属性类型必须与 %token 或 %type 声明一致，否则会导致类型错误或程序崩溃。\n\n\n类型错误可能导致程序在运行时崩溃（如把指针存到整数字段）。\n\n错误处理基本原理\n特殊 token error\n\n由 Bison 自动定义，用于错误处理，不需要在文法中声明。\n当出现语法错误时，解析器会生成该 token。\n如果当前上下文有匹配 error 的规则，解析器就能继续工作。\n\n\n错误恢复流程\n\n发生语法错误 → 生成 error token。\n弹出状态栈（丢弃部分语义上下文）直到找到可接受 error 的状态。\n移入 error token。\n如果下一个 token 解释器无法接受 → 丢弃输入 token，直到找到可接受的 token。\n继续按照匹配的错误规则执行。\n\n\n常见恢复策略\n\n跳过当前语句stmt: error &#x27;;&#x27;  /* 错误时跳过直到 &#x27;;&#x27; */\n跳过到匹配的闭合符primary:  &#x27;(&#x27; expr &#x27;)&#x27;| &#x27;(&#x27; error &#x27;)&#x27;;\n\n\n\n\n注意事项\n规则动作错误规则和普通规则一样，可以有动作代码。\n\n错误消息抑制\n\n避免错误雪崩：恢复后，如果连续 3 个 token 没有被成功移入，不会输出新错误。\n宏 yyerrok;：立即恢复错误消息输出。\n宏 yyclearin;：清除当前 lookahead token，让扫描器重新提供一个 token。\n\n\n状态检测\n\nYYRECOVERING()：判断当前是否在错误恢复状态（1 表示正在恢复）。\n\n\n\nCool 语言的 AST 包为了将 Token 序列转换成 AST，我们肯定要了解 Cool 语言的 AST 的定义。（怎么这么多要了解的东西）\nCool 语言的 AST 代码由 cool-tree.aps 文件中的规范自动生成。虽然这些代码结构简单、规则统一，但由于缺乏注释，阅读和理解起来并不直观。接下来，我们将参考 handouts/cool-tour 第六节的内容，对其结构进行分析和理解。\nAPS 简介Cool 语言的抽象语法在 APS 中定义。在 APS 术语中，抽象语法树的各种节点（如 let、+ 等）被称为构造器。AST 的格式由一组 门类（phyla） 描述，每个门类包含一个或多个构造器，用于表示特定类型的语法结构。\n门类本质上就是类型，它是我们根据功能对构造器进行分组后确定的。例如，将表达式 AST 的构造器与类 AST 的构造器区分开来。门类的定义位于 cool-tree.aps 文件的开头。module COOL[] begin  phylum Program;  phylum Class_;  phylum Classes = LIST [Class_];  phylum Feature;  phylum Features = LIST [Feature];  phylum Formal;  ···\n从定义可以看出，门类分为两种类型：“正常”门类和“列表”门类。正常门类关联有构造器，列表门类则定义有一组固定的列表操作。\n每个构造器都接受带有明确类型的参数，并返回带有明确类型的结果。参数类型可以是先前定义的门类或任何普通的 C++ 类型。实际上，门类的声明会被 APS 编译器转换成对应的 C++ 类声明。例如：\nconstructor class_(name : Symbol; parent: Symbol; features : Features; filename : Symbol) : Class_;\n此声明指定 class_ 构造函数接受四个参数：\n\nSymbol（类型标识符）用于类名  \nSymbol（类型标识符）用于父类  \nFeatures（由 Feature 构成的列表）  \nSymbol 用于存放类定义的文件名\n\nclass_ 构造函数返回类型为 Class_ 的 AST 节点。在 cool.y 中，使用示例如下：\nclass : CLASS TYPEID INHERITS TYPEID IS optional_feature_list END &#x27;;&#x27;    &#123; $$ = class_($2, $4, $6, stringtable.add_string(curr_filename)); &#125;\n该构造函数会用四个参数作为子节点构建一个 Class_ 树节点。由于参数类型已声明，C++ 类型检查器会强制确保仅将构造函数用于适当类型的参数。\n在阅读代码时需要注意：相同的名称在不同上下文中可能表示不同实体。例如：\n\nCLASS：终端符号  \nclass：非终端符号  \nclass_：构造器  \nClass_：门类\n\n它们的含义完全不同。此外，在 cool.y 的联合声明中还有 class_ 成员，含义又不同。大多数情况可通过大小写区分，但并非总是如此，因此阅读代码时需特别注意每个符号的角色。\nAST 列表对每个普通门类 X，APS 都会对应地定义一个列表门类 Xs，其类型为 List [X]（除了 Classes 是 Class_ 的列表）。APS 为列表型门类提供了一组专用的操作，用于构建和访问列表结构。常用列表操作函数有：| 函数名                | 功能说明                     ||——————————-|—————————————-|| nil_Classes()       | 返回一个空的 Classes 列表         || single_Classes(Class_) | 根据单个 Class_ 元素创建长度为1的列表 || append_Classes(Classes, Classes) | 拼接两个 Classes 列表             || Class_nth(int index)    | 选取列表中第 index 个元素          || int len()           | 返回列表长度                   |\n列表还提供了一个简单的迭代器，包含以下方法：\n\nfirst()：返回列表第一个元素的索引  \nmore(index)：当 index 不是最后一个元素时返回 true，否则返回 false  \nnext(index)：返回列表中 index 的下一个元素的索引\n\nAST 类层次结构Cool 的 AST 采用面向对象的类继承机制组织节点类型，整体结构如下：\n\n除列表外，所有 AST 类均派生自基类 tree_node。  \n所有列表都是 tree_node 类型的列表。  \ntree_node 类及 AST 列表模板定义在 tree.h 中。\n\ntree_node 类\n定义了抽象语法树节点所需的基本信息，除去特定构造函数特有的数据。  \n包含受保护成员 line_number，表示该 AST 节点对应的源代码行号，用于编译器生成精准的错误提示信息。  \n提供的重要成员函数包括：  \ndump：以 pret 格式打印 AST。  \nget_line_number：访问节点对应的行号。\n\n\n\n门类\n每个门类是直接从 tree_node 派生的类。  \n门类的主要作用是将相关构造函数归类，不增加额外功能。\n\n构造器类\n每个构造器类都派生自对应的门类。  \n每个构造器类定义了一个同名函数，用于构建对应的 AST 节点。  \n构造器类自动定义了 dump 函数，用于打印节点信息。\n\nAST 构造器类属性tree 包中每个类定义都包含若干属性。每个构造器类都会为其组成部分定义对应的属性，属性名称与构造器中的字段名一致，且仅对该构造器类及其派生类的成员函数可见。例如，class_constructor 类具有以下四个属性：\n\nSymbol name;\nSymbol parent;\nFeatures features;\nSymbol filename;\n\n为 AST 类添加成员函数能够有效提升代码可读性和开发效率。所有扩展均可通过直接编辑 cool-tree.h 等头文件完成，无需修改自动生成的 APS 定义。\n实现\n在开始之前，建议先阅读 handouts/cool-manual 的第十一、十二节，分别详细介绍了 Cool 的优先级与语法结构。同时，推荐仔细阅读 cool-tree.asp 文件，其中定义了所有可用的构造器。\n\n我们先根据优先级和属性确定各个非终结符储存的字段和各个符号的优先级：%type &lt;program&gt; program%type &lt;classes&gt; class_list%type &lt;class_&gt; class%type &lt;feature&gt; feature%type &lt;features&gt; dummy_feature_list%type &lt;formal&gt; formal%type &lt;formals&gt; formal_list%type &lt;case_&gt; branch%type &lt;cases&gt; branch_list%type &lt;expression&gt; expr dispatch static_dispatch let_expr let_cond case_expr%type &lt;expressions&gt; expr_list actual%right ASSIGN%left NOT%nonassoc LE &#x27;&lt;&#x27; &#x27;=&#x27;%left &#x27;+&#x27; &#x27;-&#x27;%left &#x27;*&#x27; &#x27;/&#x27;%left ISVOID%left &#x27;~&#x27;%left &#x27;@&#x27;%left &#x27;.&#x27;%nonassoc LET\n然后根据语法结构对应的 AST 的构造函数来写就行，然后根据错误要求处理一下错误就行：program :  class_list    &#123; SET_NODELOC(@1); ast_root = program($1); &#125;;class_list :    class        &#123; $$ = single_Classes($1);        parse_results = $$; &#125;    | class_list class        &#123; $$ = append_Classes($1, single_Classes($2));        parse_results = $$; &#125;    ;class :    CLASS TYPEID &#x27;&#123;&#x27; dummy_feature_list &#x27;&#125;&#x27; &#x27;;&#x27;        &#123; $$ = class_($2, idtable.add_string(&quot;Object&quot;), $4,                    stringtable.add_string(curr_filename)); &#125;    | CLASS TYPEID INHERITS TYPEID &#x27;&#123;&#x27; dummy_feature_list &#x27;&#125;&#x27; &#x27;;&#x27;        &#123; $$ = class_($2, $4, $6, stringtable.add_string(curr_filename)); &#125;    | error    ;dummy_feature_list :    &#123; $$ = nil_Features(); &#125;    | feature &#x27;;&#x27;        &#123; $$ = single_Features($1); &#125;    | dummy_feature_list feature &#x27;;&#x27;        &#123; $$ = append_Features($1, single_Features($2)); &#125;    ;feature :    OBJECTID &#x27;:&#x27; TYPEID        &#123; $$ = attr($1, $3, no_expr()); &#125;    | OBJECTID &#x27;:&#x27; TYPEID ASSIGN expr        &#123; $$ = attr($1, $3, $5); &#125;    | OBJECTID &#x27;(&#x27; &#x27;)&#x27; &#x27;:&#x27; TYPEID &#x27;&#123;&#x27; expr &#x27;&#125;&#x27;        &#123; $$ = method($1, nil_Formals(), $5, $7); &#125;    | OBJECTID &#x27;(&#x27; formal_list &#x27;)&#x27; &#x27;:&#x27; TYPEID &#x27;&#123;&#x27; expr &#x27;&#125;&#x27;        &#123; $$ = method($1, $3, $6, $8); &#125;    | error    ;formal_list :    &#123; $$ = nil_Formals(); &#125;    | formal        &#123; $$ = single_Formals($1); &#125;    | formal_list &#x27;,&#x27; formal        &#123; $$ = append_Formals($1, single_Formals($3)); &#125;    ;formal :    OBJECTID &#x27;:&#x27; TYPEID        &#123; $$ = formal($1, $3); &#125;    ;branch_list :    &#123; $$ = nil_Cases(); &#125;    | branch        &#123; $$ = single_Cases($1); &#125;    | branch_list branch        &#123; $$ = append_Cases($1, single_Cases($2)); &#125;    ;branch :    OBJECTID &#x27;:&#x27; TYPEID DARROW expr &#x27;;&#x27;        &#123; $$ = branch($1, $3, $5); &#125;    ;expr :    OBJECTID ASSIGN expr        &#123; $$ = assign($1, $3); &#125;    | dispatch    | static_dispatch    | IF expr THEN expr ELSE expr FI        &#123; $$ = cond($2, $4, $6); &#125;    | WHILE expr LOOP expr POOL        &#123; $$ = loop($2, $4); &#125;    | WHILE expr LOOP error    | &#x27;&#123;&#x27; expr_list &#x27;&#125;&#x27;        &#123; $$ = block($2); &#125;    | let_expr    | case_expr    | NEW TYPEID        &#123; $$ = new_($2); &#125;    | ISVOID expr        &#123; $$ = isvoid($2); &#125;    | expr &#x27;+&#x27; expr        &#123; $$ = plus($1, $3); &#125;    | expr &#x27;-&#x27; expr        &#123; $$ = sub($1, $3); &#125;    | expr &#x27;*&#x27; expr        &#123; $$ = mul($1, $3); &#125;    | expr &#x27;/&#x27; expr        &#123; $$ = divide($1, $3); &#125;    | &#x27;~&#x27; expr        &#123; $$ = neg($2); &#125;    | expr &#x27;&lt;&#x27; expr        &#123; $$ = lt($1, $3); &#125;    | expr LE expr        &#123; $$ = leq($1, $3); &#125;    | expr &#x27;=&#x27; expr        &#123; $$ = eq($1, $3); &#125;    | NOT expr        &#123; $$ = comp($2); &#125;    | &#x27;(&#x27; expr &#x27;)&#x27;        &#123; $$ = $2; &#125;    | OBJECTID        &#123; $$ = object($1); &#125;    | INT_CONST        &#123; $$ = int_const($1); &#125;    | STR_CONST        &#123; $$ = string_const($1); &#125;    | BOOL_CONST        &#123; $$ = bool_const($1); &#125;    | error    ;dispatch :    OBJECTID &#x27;(&#x27; actual &#x27;)&#x27;        &#123; $$ = dispatch(object(idtable.add_string(&quot;self&quot;)), $1, $3); &#125;    | expr &#x27;.&#x27; OBJECTID &#x27;(&#x27; actual &#x27;)&#x27;        &#123; $$ = dispatch($1, $3, $5); &#125;    ;static_dispatch :    expr &#x27;@&#x27; TYPEID &#x27;.&#x27; OBJECTID &#x27;(&#x27; actual &#x27;)&#x27;        &#123; $$ = static_dispatch($1, $3, $5, $7); &#125;    ;actual :    &#123; $$ = nil_Expressions(); &#125;    | expr        &#123; $$ = single_Expressions($1); &#125;    | actual &#x27;,&#x27; expr        &#123; $$ = append_Expressions($1, single_Expressions($3)); &#125;    ;expr_list :    expr &#x27;;&#x27;        &#123; $$ = single_Expressions($1); &#125;    | expr_list expr &#x27;;&#x27;        &#123; $$ = append_Expressions($1, single_Expressions($2)); &#125;    | error    ;let_expr :    LET OBJECTID &#x27;:&#x27; TYPEID IN expr        &#123; $$ = let($2, $4, no_expr(), $6); &#125;    | LET OBJECTID &#x27;:&#x27; TYPEID ASSIGN expr IN expr        &#123; $$ = let($2, $4, $6, $8); &#125;    | LET OBJECTID &#x27;:&#x27; TYPEID &#x27;,&#x27; let_cond        &#123; $$ = let($2, $4, no_expr(), $6); &#125;    | LET OBJECTID &#x27;:&#x27; TYPEID ASSIGN expr &#x27;,&#x27; let_cond        &#123; $$ = let($2, $4, $6, $8); &#125;    ;let_cond :    OBJECTID &#x27;:&#x27; TYPEID IN expr        &#123; $$ = let($1, $3, no_expr(), $5); &#125;    | OBJECTID &#x27;:&#x27; TYPEID ASSIGN expr IN expr        &#123; $$ = let($1, $3, $5, $7); &#125;    | OBJECTID &#x27;:&#x27; TYPEID &#x27;,&#x27; let_cond        &#123; $$ = let($1, $3, no_expr(), $5); &#125;    | OBJECTID &#x27;:&#x27; TYPEID ASSIGN expr &#x27;,&#x27; let_cond        &#123; $$ = let($1, $3, $5, $7); &#125;    ;case_expr :    CASE expr OF branch_list ESAC        &#123; $$ = typcase($2, $4); &#125;    ;\n不知道为啥评测程序好像有 bug……我无论是换谁的程序都判不出来。嗯，所以我找了份大佬的程序对拍，拍过了(^_^)\n哦，现在我知道了，原来是它用的脚本跟我的 Shell 不匹配……把 grading 目录下的 myparser 的 csh 也改成 bash 就行了\n小结PA3 同样很简单，有一堆只要了解接口的东西要看，但都不是很复杂。有一说一，过于自动化的程序导致了课程内容与作业略有一点脱节，课上讲的解析器原理在作业中完全没有体现，有一点遗憾，不过后面的作业应该会好很多。\n现在可以贴通关截图哩：\n\n  \n  通关截图\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","语法分析","抽象语法树"]},{"title":"CS143-Week5：Semantic Analysis and Type Checking","url":"/2025/08/12/CS143-Week5%EF%BC%9ASemantic-Analysis-and-Type-Checking/","content":"语义分析基础在语义分析阶段，Coolc 会执行多种检查，包括：\n\n所有标识符均已在当前可见的作用域中声明\n类型检查\n继承关系合法\n类只能定义一次\n类中的方法只能定义一次\n保留标识符未被滥用以及其他语义相关的检查……\n\n为了完成这些任务，编译器通常会对 AST 进行一次或多次遍历。其中，大多数检查（例如变量是否已声明、类型是否匹配）可以在一次递归遍历 AST 的过程中完成。这种遍历方式遵循“边向下走，边处理”的原则，整个过程可以分为三个阶段：\n\n先处理当前节点的一部分例如，当遇到类或方法时，先将它的名字记录到符号表中，以便后续查找。\n\n然后处理子节点递归地分析内部的语句或表达式，例如依次检查函数体中的每一行代码。\n\n最后处理收尾工作并返回在完成子节点分析后，还需要做一些后续检查，例如确认函数返回值类型是否正确，或清理作用域（退出函数后，局部变量将不再可用）。\n\n\n作用域与符号表作用域作用域（Scope）是指一个声明在程序中可见并可被访问的代码范围。\n在语义分析中，我们会根据作用域，将标识符的使用与其对应的声明进行匹配。\n静态作用域与动态作用域\n静态作用域（Static Scoping）由程序的文本结构决定，与程序运行时的行为无关，大多数编程语言（包括 Cool）都采用静态作用域。\n\n动态作用域（Dynamic Scoping）由程序运行时的调用栈决定，与代码的书写结构无关，早期的 Lisp 和 SNOBOL 使用动态作用域，但许多语言（如 Lisp）后来转向以静态作用域为主。\n\n\nCool 中引入标识符绑定的语法结构在 Cool 语言中，以下语法结构会引入新的标识符绑定：\n\n类声明：引入类名\n方法定义：引入方法名\nLet 表达式：引入对象标识符\n形式参数：引入对象标识符\n属性定义：引入对象标识符\nCase 表达式：引入对象标识符\n\n符号表为了支持函数作用域以及嵌套作用域，符号表通常采用栈来实现。\n每个作用域对应栈中的一个层级：\n\n新的局部作用域（如函数体、if 语句块等）开启时，压入一个新层；\n作用域结束时，弹出该层。\n\n这样可以正确处理变量的声明与查找，支持同名变量在不同作用域中的隔离。\n常用操作\n\n\n\n操作\n说明\n\n\n\n\nenter_scope()\n开启一个新的嵌套作用域（在栈顶压入一个新作用域）。\n\n\nadd_symbol(x)\n将标识符 $x$ 添加到当前作用域（栈顶作用域）中。\n\n\nfind_symbol(x)\n查找标识符 $x$：从当前作用域开始，向外层逐层查找（返回找到的符号或 $null$）。\n\n\ncheck_scope(x)\n判断标识符 $x$ 是否在当前作用域（栈顶作用域）中定义（返回 $true$ 或 $false$）。\n\n\nexit_scope()\n退出当前作用域（弹出栈顶作用域，回到外层作用域）。\n\n\n\n\n例子&#123;  let x: Int &lt;- 5 in ...        -- enter_scope(), add_symbol(x)  &#123;    let y: Bool &lt;- true in ...  -- enter_scope(), add_symbol(y)    ...                         -- 可访问 x 和 y  &#125;                             -- exit_scope() → y 被移除  ...                           -- 只能访问 x&#125;                               -- exit_scope() → x 被移除\n类名与局部变量不同，类名具有全局性，并且允许前向引用：\n\n一个类可以在另一个尚未定义的类之前被使用。\n\n例如：class A inherits B &#123; ... &#125;  -- B 还没定义class B &#123; ... &#125;             -- 后面才定义\n因此我们无法在单遍扫描中完成类名的检查。\n解决方案：多遍扫描第一遍：收集类名\n遍历所有类声明，提取类名；\n将类名注册到全局类符号表中；\n不进行继承检查或方法分析。\n\n第二遍及以后：执行语义检查\n检查继承关系（如父类是否存在）；\n验证方法重写、属性类型、方法调用等；\n此时所有类都已“可见”，可安全解析跨类引用。\n\n类型类型在编程语言中，类型可以理解为“值的集合”以及“可对该值执行的操作”的组合。类则是类型概念的一种现代扩展，将数据与行为封装在一起。类型检查的核心目标是确保每个操作仅作用于其支持的类型之上，防止非法操作。\n不同语言对类型的支持程度各异：例如汇编语言几乎没有类型系统，而高级语言通常具备严格的类型机制。\n按类型可以把语言分为三种：\n\n静态类型语言类型检查在编译阶段完成或几乎全部完成。代表语言：C、Java、Cool。\n\n动态类型语言类型检查在程序运行时完成或几乎全部完成。代表语言：Python、Lisp。\n\n无类型语言不进行类型检查。代表：机器码。\n\n\n在编程语言设计中，静态类型与动态类型各有优劣。静态类型语言会在编译阶段进行类型检查，能够提前捕捉大量编程错误，并避免运行时的类型检查开销；而动态类型语言则更加灵活，开发者无需在编写代码时显式声明类型，因而在快速原型开发中更为高效，但类型错误往往只能在运行时发现。\n现实中，这两种类型系统正相互借鉴：静态类型语言通常允许通过特定机制绕过严格的类型检查——例如 C 语言中的指针类型转换（如 (int*) 或 (void*)），或 Java 中的强制类型转换与 sun.misc.Unsafe 类；动态类型语言也逐渐引入可选的静态类型检查（如 Python 的 type hints），以提升性能或辅助调试。对于这种折中方式是否合理，观点不一——有人认为它融合了双方的优点，也有人认为它可能兼具两者的缺点。我们将在 Week 6 中更加详细地区分这两种类型系统。\n类型检查概念区分\n类型检查（Type Checking） 是在程序的类型信息完整且明确的前提下，验证其是否符合语言类型规则的过程。  \n\n类型推导（Type Inference） 则是在类型信息不完整或未显式标注时，通过上下文自动推断并补全缺失的类型。  \n\n\n两者是不同的概念：前者侧重“验证”，后者侧重“推断”。但在日常讨论中，常被混用或统称为“类型处理”。\n推理规则在编译器实现中，类型检查依赖于推理规则——即形如 “如果条件 A 和条件 B 成立，那么结论 C 成立” 的逻辑规则。这些规则用来描述表达式的类型是如何根据其子表达式的类型推导出来的。例如，如果 $E_1$ 的类型是 $Int$，$E_2$ 的类型也是 $Int$，那么 $E_1 + E_2$ 的类型是 $Int$。\n推理规则通常以符号形式书写：\n\n$\\wedge$ 表示逻辑“与”\n$\\rightarrow$ 表示“如果…那么…”\n$x : T$ 表示“x 的类型是 T”\n$\\vdash e: T$ 表示“可证明 e 的类型是 T”\n$O[T/x]$ 表示将“类型环境 O 中的 x 类型设置为 T”\n\n一个健全的类型系统意味着：如果编译器能证明表达式 $e$ 的类型是 $T$，那么在运行时 $e$ 的值一定会是类型 $T$。我们只希望使用健全的规则来推导类型，否则就会出现类型不一致的运行时错误。\n类型检查通常直接在 AST 上进行。每个 AST 节点对应一条类型规则，节点的类型由其子节点的类型推导而来：\n\n先递归检查并推导子节点的类型（假设条件成立的部分）\n根据类型规则推导当前节点的类型（得出结论）\n\n这种检查是自底向上完成的，最终可以证明整个程序的类型正确性。\n类型环境类型环境（Type Environment） 是一个将对象标识符映射到类型的函数，用于为当前作用域中的自由变量提供类型信息。\n\n自由变量 是指在当前表达式或作用域中未定义，但在外层作用域中已声明的变量。\n在类型检查或类型推导过程中，仅依靠局部语法规则无法确定自由变量的类型。此时，必须依赖类型环境来查找其类型绑定。\n\n例如，对于如下推理规则：\n\n\\frac{x \\, is \\, a \\, variable}{\\vdash x : ?} \\tag{Var}我们无法仅从规则本身得知 $x$ 的类型。此时，类型环境提供了上下文信息，如 $x : Int$，从而完成类型解析。\n在类型检查过程中，类型信息的流动具有明确的方向性：\n\n类型环境由上而下传递：从 AST 的根节点逐层传递到子节点，为每个子表达式提供当前作用域内的变量类型信息；\n表达式类型由下而上返回：每个子表达式的类型根据其结构和环境推导得出，并向上传递给父节点，最终完成整个程序的类型验证。\n\n这种“上下结合”的机制，确保了类型推导既具有上下文敏感性，又能保持局部推理的可行性。\n特殊结构的类型处理比如，在 Cool 语言中，某些控制结构的类型规则需要特别设计。例如：\n\n$loop$ 表达式的返回类型被定义为 $Object$。\n\n原因是：循环体可能一次都不执行（如条件不满足），因此无法保证返回一个具体类型的值。将其类型设为 $Object$ 是一种保守但安全的设计，避免了类型不一致或未定义的问题。\n子类型为了支持继承与多态，我们需要用到子类型（Subtyping）关系来描述类型之间的继承与兼容性，记 T_1 \\leq T_2，表示类型 T_1 是 T_2 的子类型。其基本性质包括：\n\n自反性：T \\leq T\n传递性：若 S \\leq T 且 T \\leq U，则 S \\leq U\n继承关系：若类 C 继承自类 D，则 C \\leq D\n\n子类型的应用规则1. 静态类型检查编译器检查变量的静态类型，保证对变量的操作合法。\n2. 兼容性在变量赋值、属性初始化或 $let$ 绑定中，允许将子类型值赋给父类型变量：\n\n若表达式 e 的类型为 T_1，且 T_1 \\leq T_0，则 e 可用于类型为 T_0 的上下文中。\n\n适用场景：\n\n变量赋值\n属性初始化\n$let$ 表达式中的初始化\n\n3. if 表达式的类型if e₀ then e₁ else e₂ fi 的类型为 $lub(T_1, T_2)$，即 $e_1$ 和 $e_2$ 类型的最小上界，且 $e_0$ 必须为 $Bool$ 类型。\n4. case 表达式的类型case e₀ of ... esac 的类型为 $lub(T_1’, T_2’, …, T_n’)$，即所有分支结果类型的最小上界。\n最小上界（Least Upper Bound, lub）$lub(S, T)$是满足以下条件的类型 $U$：\n\n$S \\leq U$ 且 $T \\leq U$（$U$ 是上界）\n对任意 $U’$，若 $S \\leq U’$ 且 $T \\leq U’$，则 $U \\leq U’$（$U$ 是最小的）\n\n在 Cool 语言中，$lub(S, T)$ 对应继承树中 $S$ 和 $T$ 的最近公共祖先。\n方法的类型检查在 Cool 中，对象标识符（变量）和方法标识符（函数名）属于不同的命名空间，这意味着在同一个作用域中，可以同时存在一个对象 $foo$ 和一个方法 $foo$，它们互不冲突。\n为了支持方法的类型检查，类型系统引入了一个额外的方法环境 $M$，专门用于存储方法的签名信息。\n虽然对象环境 $O$ 与方法环境 $M$ 都是类型系统的一部分，但它们的性质差异明显：$O$ 是动态变化的“局部”信息，随着作用域的进入与退出而更新；而 $M$ 是固定的“全局”信息，一旦类定义完成就保持不变，用于全局方法调用的类型检查。\n方法环境方法环境 M 是一个映射，用于描述类中方法的签名：\n\nM(C, f) = (T_1, \\ldots, T_n, T_{n+1})表示在类 C 中，存在方法 f，其参数类型依次为 T_1 \\ldots T_n，返回类型为 T_{n+1}。换句话说：\n\nf(x_1:T_1,\\cdots,x_n:T_n):T_{n+1}方法调用的类型规则就像我们在语法分析里面写过的那样，方法调用分为普通调用（Dispatch）和静态调用（Static Dispatch）两种。\n普通调用如果对象 e_0 的类型为 T_0，并且在 T_0（或其父类）中存在方法 f，其签名为\n\nM(T_0, f) = (T_1, \\ldots, T_n, T_{n+1})那么当调用 e_0.f(e_1, \\ldots, e_n) 时，需要满足：\n\n每个实参 e_i 的类型 T_i' 必须是形参类型 T_i 的子类型（T_i' \\leq T_i）\n调用表达式的整体类型为返回类型 T_{n+1}\n\n静态调用在 Cool 中，可以显式指定调用的目标类，例如：\n\ne_0 @ T.f(e_1, \\ldots, e_n)这里 T 必须是 e_0 的类型的一个父类。类型检查规则与普通调用类似：\nM(T, f) = (T_1, \\ldots, T_n, T_{n+1})其中：\n\n每个实参 T_i' \\leq T_i\n整体类型仍为 T_{n+1}\n\n当前类在涉及 SELF\\_TYPE 的场景下，仅凭 O（对象环境）和 M（方法环境）还不够。因为 SELF\\_TYPE 的含义依赖于方法所在的类，所以还需要引入 当前类 C 作为上下文。\n因此，Cool 的完整类型环境为：\n\n对象环境 O：记录对象标识符到类型的映射\n方法环境 M：记录方法签名\n当前类 C：用于解释 SELF\\_TYPE\n\n一条类型推理语句的形式为：\n\nO, M, C \\vdash e : T","categories":["CS143"],"tags":["Linux","编译原理","CS143","语义分析","类型检查"]},{"title":"CS143-Week6：Cool Type Checking & Runtime Organization","url":"/2025/08/16/CS143-Week6%EF%BC%9ACool-Type-Checking-Runtime-Organization/","content":"Cool 的类型检查静态类型与动态类型静态类型（Static Typing） 是一种编译时的类型系统，变量或表达式的类型在编译阶段就已经确定，编译器会在此时进行类型检查，我们之前讲的就是这种类型系统。这种方式能够提前发现错误，但也可能拒绝一些在运行时实际上可以正确执行的程序。换句话说，静态类型刻画的是变量或表达式在所有可能执行路径下所能具有的类型集合（编译期约束）。\n动态类型（Dynamic Typing） 在这里有两层含义：  \n\n静态类型语言中的运行时对象类型：变量的静态类型固定，但它所引用的对象在运行时可能是静态类型的子类，决定运行时行为，这就是所谓的动态类型。例如在 Java 中：\nAnimal a = new Dog(); // 变量 a 的静态类型是 Animal，动态类型是 Doga = new Cat();        // 动态类型变为 Cat，但静态类型仍是 Animal\n\n动态类型语言中的变量绑定类型：变量本身没有固定类型，运行时绑定什么对象，类型就是什么，类型检查完全在运行时进行。例如 Python：\nx = 5      # 运行时类型是 intx = &quot;hi&quot;   # 运行时类型变为 str\n\n\n区别：静态类型语言变量的静态类型固定，也即类型检查时类型固定，但运行时对象类型可变化（向下转型受限）；动态类型语言变量没有固定类型，完全由运行时决定。\n类型系统的健全性保证了静态类型与动态类型的一致性：对于任意表达式 $E$，其运行时的动态类型（对象类型）始终是其静态类型的子类型，从而确保编译期推导出的类型在运行时是安全的。子类型安全要求子类只能增加属性或方法，并允许方法重定义，但方法的类型签名必须保持不变。这样，所有对类型 $C$ 对象合法的操作，也同样适用于其子类型 $C’ &lt; C$ 的对象，包括属性访问和方法调用，从而保证了子类型的安全性和多态的正确性。\n$SELF\\_TYPE$$SELF\\_TYPE$ 是一种特殊的类型标记，表示方法或属性的返回类型与调用对象的动态类型一致。  \n\n静态视角：在编译期，SELF_TYPE 是占位类型，用于静态类型检查，表示返回类型依赖于调用对象。  \n动态视角：在运行时，SELF_TYPE 的实际类型由调用对象的动态类型决定，从而支持多态行为。\n\n它既保证了类型安全（编译期检查可通过），又允许返回类型根据运行时对象动态变化，类似“动态类型的占位符”。\n操作规则1. 替换原则在类型检查时，SELF\\_TYPE_C 可以安全地替换为类 $C$。  \n\n因为 SELF\\_TYPE_C 表示“与调用对象动态类型一致的类型”，它必然是类 $C$ 的某个子类型。  \n所以在静态检查阶段，用 $C$ 来代替 SELF\\_TYPE_C 可以保证安全。  \n\n2. 子类型关系设 $T, T’$ 是除 SELF_TYPE 外的任意类型。\n\n同类 SELF_TYPE 比较\n\nSELF\\_TYPE_C \\leq SELF\\_TYPE\\_C\n注意：不同类的 SELF\\_TYPE 不能比较，例如 SELF\\_TYPE_A 和 SELF\\_TYPE_B 没有可比关系。\n\n\nSELF_TYPE 和普通类型比较\n\n$SELF\\_TYPE_C \\leq T$ 当且仅当 $C \\leq T$换句话说，SELF\\_TYPE_C 可以被看作是 $C$ 的任意子类型，所以它在子类型规则里表现得和 $C$ 一样。\n\n\n普通类型与 SELF_TYPE 比较\n\nT \\leq SELF\\_TYPE_C 永远为假。因为 SELF\\_TYPE_C 可能是 $C$ 的任意子类，$T$ 不一定能涵盖所有可能性。\n\n\n\n3. 最小上界当我们在条件表达式 (if/case) 中需要合并不同分支的类型时，就会用到最小上界。\n规则如下：\n\n$lub(SELF\\_TYPE_C, SELF\\_TYPE_C) = SELF\\_TYPE_C$  \n\n两个相同类的 SELF_TYPE，lub 还是它本身。\n\n\n$lub(SELF\\_TYPE_C, T) = lub(T, SELF\\_TYPE_C) = lub(C, T)$  \n\n把 SELF_TYPE 先替换成 $C$，再做 lub。\n\n\n$lub(T, T’)$  \n\n如果没有 SELF_TYPE，照普通的 lub 规则。使用限制虽然 SELF_TYPE 很有用，但并非所有位置都可以使用。规则如下：\n\n\n\n1. 类继承声明\n不允许：class T inherits T&#39; &#123; ... &#125;\nT 和 T&#39; 不能是 SELF_TYPE。  \n因为 SELF_TYPE 不是一个具体类名，它只是一个占位符，不能用来定义类层次结构。\n\n2. 属性声明\n允许：x : SELF_TYPE\n属性类型可以是 SELF_TYPE，表示这个属性与当前对象的动态类型一致。\n\n3. let 绑定\n允许：let x : SELF_TYPE in E\n局部变量的类型可以是 SELF_TYPE，和属性一样，绑定时类型与 self 一致。\n\n4. 对象创建\n允许：new SELF_TYPE\n这样创建的对象类型与当前 self 的动态类型一致，而不是固定为某个类。  \n这是 SELF_TYPE 的重要用途之一。\n\n5. 静态调用\n不允许：e @ T.m(...) 中的 T 不能是 SELF_TYPE。  \n静态分派要求编译器在编译时就能确定确切的类，以找到正确的方法实现。  \nSELF_TYPE 在编译时不代表具体类，所以不能出现在这里。\n\n6. 方法定义\n参数类型：不能用 SELF_TYPE。  \n\n例如：comp(x : SELF_TYPE) : Bool &#123; ... &#125; 是非法的。  \n原因：如果子类继承这个方法，SELF_TYPE 会指向不同的类，导致参数类型不一致，破坏类型安全。  \n\n\n返回类型：可以用 SELF_TYPE。  \n\n例如：clone() : SELF_TYPE &#123; ... &#125; 是合法的。  \n这表示返回值与调用对象的动态类型一致，符合多态的预期。\n\n\n\n类型检查中的错误恢复和语法分析一样，类型检查也需要考虑错误恢复。与语法错误不同，类型错误的位置通常更容易定位，而且没有必要跳过大段代码。关键问题是：当一个表达式没有合法类型时，应该给它什么类型？\n1. 最简单的做法：赋予 Object将所有类型错误的表达式临时赋值为 Object 类型是一种暴力但好用的方法。\n\n好处：因为 Object 是所有类的根类型，后续的类型检查仍然可以继续进行。  \n缺点：可能过于宽松，有时会掩盖错误。\n\n2. 更精细的做法：引入 No_type我们可以定义一个特殊的类型 No_type，专门表示“类型检查失败”的结果。  \n\n规则：No_type ≤ C 对所有类型 C 都成立。\n\n这样，No_type 在需要任何类型的地方都可以暂时充当，所有操作都允许接受 No_type 作为输入，但其结果也会是 No_type。也就是说，错误会“传播”，不会被掩盖。\n示例：let y : Int &lt;- x + 3\n如果 x 未定义，则 x 的类型为 No_type，因此 x + 3 的结果类型也是 No_type。编译器会报告错误，但仍能继续分析后续代码。\n3. 实际实现考虑如果引入 No_type，类层次结构就不再是树，而是一个“几乎全连接”的结构（因为 No_type 是所有类的子类型），实现起来会比较复杂。  \n因此，在我们做玩具编译器的时候，用 Object 作为错误恢复类型已经足够。但在“真实”编译器里，更常见的做法是使用类似 No_type 的特殊机制来追踪错误。\n运行时系统在完成了词法分析、语法分析、语义分析三大步骤后，我们的前端编译器已经确认了程序的合法性，接下来就是属于后端编译器的内容——优化和代码生成。\n在了解代码生成之前，我们需要了解运行时系统……诶，我学过 OS，嘿嘿。所以运行时系统就略过了。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","语义分析","自类型","运行时系统"]},{"title":"CS143-PA2：Lexical Analysis","url":"/2025/08/01/CS143-PA2%EF%BC%9ALexical%20Analysis/","content":"\n前排提醒：本文采用 C++ 实现，如果使用 java 建议参考其他文章。\n\n词法分析准备工作本次作业的目标是：使用 Flex 实现一个可以将 Cool 源代码转换为 Token 序列的词法分析器。\n在 assignments/PA2 目录下执行命令：\nmake lexer\n会生成一个名为 lexer 的可执行文件，可以通过运行 ./lexer test.cl 来对指定文件进行词法分析。\n在编译过程中，cool-lex.cc 是由 Flex 根据 cool.flex 自动生成的，包含词法分析的主要实现；lextest.cc 提供程序入口（main 函数），主要负责命令行输出；其余文件都是辅助代码。\n这里所用到的 Flex 是一种工具，它能够根据正则表达式规则自动生成词法分析器。其作用是将 .flex 文件转换为 C 语言代码（如 cool-lex.cc），并作为库函数与其他源码一起编译。目前我们通过 lextest.cc 来调用生成的词法分析器代码，后续我们可能会通过其它模块（如语法分析器）来调用。\nFlex 的使用可以通过阅读 Flex 的官方文档 以及 handouts 目录下的相关 PDF 来了解，比如 PA2 的作业说明里面就有相关介绍。\n回到 PA2，我们的核心任务是完善 cool.flex 文件，使其能够正确地进行词法分析。\n项目提供了一个名为 test.cl 的测试用例，以及一个功能完整的、能够正确进行词法分析的标准 lexer。标准 lexer 位于 bin 目录下，其输出格式与我们希望实现的目标一致，我们的目标就是让自己的 lexer 输出与标准 lexer 的输出完全一致。\n找了一圈在知乎找到了评分脚本……只需将 &lt;num&gt; 替换成对应的作业编号，然后用 wget 就可以下载对应的 Perl 评分脚本：wget https://courses.edx.org/asset-v1:StanfordOnline+SOE.YCSCS1+3T2020+type@asset+block@pa&lt;num&gt;-grading.pl\nFlex 简单介绍文件结构概述Flex 文件由三部分组成，每个部分之间用 %% 隔开：\ndefinitions%%rules%%user code\n1. definitions（定义区）这一部分的作用类似于 C 文件的头部。在这里可以：\n\n包含头文件（如 #include &lt;stdio.h&gt; 等），为后续 C 代码或动作代码做准备；\n定义全局变量、结构体 或 宏（如 #define），以便在整个词法分析器中使用；\n定义正则表达式别名，这是 Flex 特有的功能，可以通过简单的名字表示复杂的正则表达式，提高可读性和复用性，例如：\nDIGIT   [0-9]ID      [a-zA-Z_][a-zA-Z_0-9]*\n\n\nC 语言的部分可以用 %&#123; 和 %&#125; 包裹，或者让代码缩进，但缩进的格式很难控制，所以最好还是写在 %&#123; 和 %&#125; 内部。\n下面是一个简单的例子：\n%&#123;#include &lt;stdio.h&gt;int lineno = 1;#define MAX_ID_LEN 256%&#125;DIGIT     [0-9]LETTER    [a-zA-Z]ID        &#123;LETTER&#125;(&#123;LETTER&#125;|&#123;DIGIT&#125;)*\n定义区的内容对后续的规则区和用户子程序区都可以起作用。\n2. rules（规则区）这是我们主要实现的地方，我们在这里编写正则表达式，用于识别源代码中的各种 token，例如标识符、关键字、数字、注释等。\n每个正则表达式后面跟一个用 &#123;&#125; 括起来的代码块：\n正则表达式    &#123; 动作代码 &#125;\nFlex 会在输入文本中查找匹配的模式，当匹配到某个正则表达式时，就执行其对应的代码。\nFlex 的格式比较严格，需要注意：\n\n正则表达式必须写在新的一行的行首，前面不能有空格或制表符，否则这些空格会被当作正则表达式的一部分；\n正则表达式与后面的代码块之间必须有至少一个空格，否则大括号 &#123; 会被当作正则表达式的一部分，导致识别错误；\n多行注释在开头应添加缩进。\n\n3. user code（用户代码区）这一部分对应于 C 文件中定义函数的部分。可以在这里定义：\n\n工具函数\n重复使用的逻辑\n比较完整的功能\n\n总而言之，就是方便进行封装的地方。\n状态量（Start Condition）Flex 提供了一种非常方便的机制，被称作状态量（Start Condition），它允许词法分析器根据上下文动态改变行为。简单来说，状态量使词法分析器在不同状态下对相同代码执行不同的匹配，只匹配与当前状态相关的正则表达式，忽略其他规则。这种机制极大增强了灵活性，使得处理多行注释、字符串，甚至在单一文件中混合多种语言（如 HTML 中的 JavaScript）等复杂场景变得轻松。利用状态量，词法分析器能够根据上下文智能调整解析策略，从而优雅地解决复杂的词法分析问题。\n状态量的声明在 Flex 的定义区用 %s 或 %x 声明状态量：\n\n%s 表示inclusive（包含）状态，当前状态及 INITIAL 状态下的规则都有效。\n%x 表示exclusive（排他）状态，只有在该状态时，定义的规则才有效。\n\n例如：\n%x COMMENT%s STRING\n状态量的使用1. 在规则中限定状态状态量用尖括号 &lt;&gt; 包裹，放在正则表达式前，表示该规则只在对应状态时生效：\n&lt;COMMENT&gt;&quot;*)&quot;    &#123; BEGIN(INITIAL); &#125;\n表示：只有在 COMMENT 状态下，遇到 *)，才执行该动作。\n2. 状态切换用 BEGIN(STATE_NAME) 切换状态：\n&quot;(*&quot;     &#123; BEGIN(COMMENT); &#125;&lt;COMMENT&gt;&quot;*)&quot; &#123; BEGIN(INITIAL); &#125;\n这样当遇到 (* 时进入 COMMENT 状态，遇到 *) 时回到初始状态。\n任务目标\n在开始之前，建议先阅读 handouts/cool-manual 的第十节，详细介绍了 Cool 的词法结构。同时，推荐仔细阅读 .flex 程序所用到的头文件，从 include/PA2/cool-parse.h 文件中可以了解需要使用的 token 类型以及用于传递语义值的变量定义，include/PA2/stringtab.h 则展现了符号表的结构。\n\n在词法分析中，我们需要处理 Cool 语言的以下几类成分，并根据它们的特性进行不同的处理：\n1. 固定关键字这些是 Cool 语言中预定义的、由固定字符串组成的词汇，例如：\n\nif\nfi\nelse\n\n当词法分析器匹配到这些字符串时，应直接生成对应的 token（例如 IF、FI、ELSE），通常不需要记录额外信息，可以在 handouts/cool-manual 的第十节找到所有关键字。唯一需要特殊处理的是 true 和 false，需要记录其值。\n2. 各种符号在 Cool 中，存在多种符号，包括运算符（如 +、-）和标点符号（如 ;、&#123;）等。其中，一些符号由两个字符组成，如 &lt;=，这类符号通常会被定义为单独的 token 类型。而其他单字符符号则直接使用它们的 ASCII 值作为 token 类型（这也解释了为什么 Bison 的 token 编号不是从 0 开始）。对于不属于 Cool 语言规范的非法字符（如 [、]、&gt; 等），词法分析器需要将其识别并报告为错误。\n3. 可忽略的成分这些成分在词法分析阶段会被识别，但不会生成任何 token，即需要被忽略。\n\n空白字符（包括空格、制表符等）\n注释（包括单行注释和多行注释）\n换行符：虽然不生成 token，但需要用于更新当前的行号。我们使用全局变量 curr_lineno，在每次匹配到 \\n 时计数，方便后续的错误报告与调试。\n\n4. 类型名与变量名这类成分需要根据其模式和上下文进行识别：\n\n类型名（Type ID）：例如类名 CellularAutomaton，通常以大写字母开头。\n变量名（Object ID）：例如属性名 population_map，通常以小写字母开头。\n\n5. 字面量这类词汇不仅需要生成 token，还需要记录其具体内容或数值。\n\n整数：需要记录其整数值。\n字符串：需要记录字符串的具体内容。\n\n\n详细规范请参考 handouts/PA2.pdf 和 handouts/cool-manual.pdf，这些文档提供了完整的语言描述和词法规则。\n\n实现固定关键字根据 include/PA2/cool-parse.h 中的定义，我们可以直接返回对应关键字的大写形式。需要注意的是，true 和 false 必须以小写字母开头进行匹配；其他关键字则对大小写不敏感。另外，true 和 false，需要记录其值，返回 BOOL_CONST 类型。CLASS         [Cc][Ll][Aa][Ss][Ss]ELSE          [Ee][Ll][Ss][Ee]FI            [Ff][Ii]IF            [Ii][Ff]IN            [Ii][Nn]INHERITS      [Ii][Nn][Hh][Ee][Rr][Ii][Tt][Ss]ISVOID        [Ii][Ss][Vv][Oo][Ii][Dd]LET           [Ll][Ee][Tt]LOOP          [Ll][Oo][Oo][Pp]POOL          [Pp][Oo][Oo][Ll]THEN          [Tt][Hh][Ee][Nn]WHILE         [Ww][Hh][Ii][Ll][Ee]CASE          [Cc][Aa][Ss][Ee]ESAC          [Ee][Ss][Aa][Cc]NEW           [Nn][Ee][Ww]OF            [Oo][Ff]NOT           [Nn][Oo][Tt] /* true 和 false 的宏定义，首字母必须是小写 */TRUE_KW       t[Rr][Uu][Ee]FALSE_KW      f[Aa][Ll][Ss][Ee]\n在规则区直接返回即可：&#123;CLASS&#125;       &#123; return (CLASS); &#125;&#123;ELSE&#125;        &#123; return (ELSE); &#125;&#123;FI&#125;          &#123; return (FI); &#125;&#123;IF&#125;          &#123; return (IF); &#125;&#123;IN&#125;          &#123; return (IN); &#125;&#123;INHERITS&#125;    &#123; return (INHERITS); &#125;&#123;ISVOID&#125;      &#123; return (ISVOID); &#125;&#123;LET&#125;         &#123; return (LET); &#125;&#123;LOOP&#125;        &#123; return (LOOP); &#125;&#123;POOL&#125;        &#123; return (POOL); &#125;&#123;THEN&#125;        &#123; return (THEN); &#125;&#123;WHILE&#125;       &#123; return (WHILE); &#125;&#123;CASE&#125;        &#123; return (CASE); &#125;&#123;ESAC&#125;        &#123; return (ESAC); &#125;&#123;NEW&#125;         &#123; return (NEW); &#125;&#123;OF&#125;          &#123; return (OF); &#125;&#123;NOT&#125;         &#123; return (NOT); &#125;/* true 和 false 的规则，使用专门的宏 */&#123;TRUE_KW&#125;     &#123;  yylval.boolean = 1;  return BOOL_CONST;&#125;&#123;FALSE_KW&#125;    &#123;  yylval.boolean = 0;  return BOOL_CONST;&#125;\n各种符号首先处理三个两个字符组成的符号，跟关键字一样地传递即可：DARROW          =&gt;ASSIGN          &lt;-LE              &lt;=%%&#123;DARROW&#125;\t\t&#123; return (DARROW); &#125;&#123;ASSIGN&#125;        &#123; return (ASSIGN); &#125;&#123;LE&#125;            &#123; return (LE); &#125;\n然后处理非法字符和控制字符，记录字符，返回 ERROR：[\\[\\]\\&#x27;&gt;_\\0\\\\!#$%^&amp;\\|`?] &#123;    // invalid chars    yylval.error_msg = yytext;    return (ERROR);&#125;[\\x00-\\x1F\\x7F] &#123;  // unprintable  yylval.error_msg = yytext;  return (ERROR);&#125;\n接着处理空白字符，直接忽略即可，注意换行虽然属于空白字符但不能忽略：[ \\t\\f\\r\\v]     &#123;&#125;\n换行要更新 curr_lineno：\\n              &#123;++curr_lineno;&#125;\n最后处理剩下的合法字符，直接返回字符的 ASCII 码即可：.               &#123;    return yytext[0];&#125;\n注释空白字符已经在上一部分解决，这里主要解决注释的问题。单行注释容易解决，直接进行匹配就行，注意.不会匹配换行符和 EOF：--.*           &#123;&#125;\n多行注释会复杂一些，特别是允许嵌套的情况下，无法使用单个正则表达式完成匹配（否则可以用 \\(\\*([^*]|\\*+[^*)])*\\*+\\) 进行匹配）。因此，我们需要借助 Flex 提供的状态量（Start Condition）语法糖，来处理这种上下文无关的语言结构。\n我们定义一个排他状态 COMMENT，用 now_status 来计数注释的嵌套，注意注释内部碰到换行要计数，碰到终止符要报错：\\(\\*          &#123;  now_status = 1;  BEGIN(COMMENT);&#125;\\*\\)          &#123;  yylval.error_msg = &quot;Unmatched *)&quot;;  return (ERROR);&#125;&lt;COMMENT&gt;\\(\\* &#123;  now_status++;&#125;&lt;COMMENT&gt;\\*\\) &#123;  now_status--;  if(now_status == 0)    BEGIN(INITIAL);&#125;&lt;COMMENT&gt;\\n   &#123;  ++curr_lineno;&#125;&lt;COMMENT&gt;&lt;&lt;EOF&gt;&gt; &#123;  BEGIN(INITIAL);  yylval.error_msg = &quot;EOF in comment&quot;;  return (ERROR);&#125;&lt;COMMENT&gt;.    &#123;&#125;\n类名与变量名从 include/PA2/stringtab.h 可以看出，类名和变量名被存储在 StringTable&lt;IdEntry&gt; 中。每个这样的符号表都有一个 add_string 方法，调用该方法并传入一个字符串时，会尝试将该字符串添加为一个符号。StringTable 类的实现保证了不会重复添加相同的字符串。\n根据 Cool 语言的语法，我们知道类型标识符以大写字母开头，对象标识符以小写字母开头。\n[A-Z][A-Za-z0-9_]*  &#123;  yylval.symbol = idtable.add_string(yytext, yyleng);  return (TYPEID);&#125;[a-z][A-Za-z0-9_]*  &#123;  yylval.symbol = idtable.add_string(yytext, yyleng);  return (OBJECTID);&#125;\n字面量整数字面量整数字面量和前面一样匹配即可，没什么区别：[0-9][0-9]* &#123;  yylval.symbol = inttable.add_string(yytext, yyleng);  return (INT_CONST);&#125;\n字符串字面量字符串的处理相对比较复杂，我们同样利用状态量。定义状态 STRING，当解析器遇到字符串开始符 &quot; 时，会进入 STRING 状态。在这个状态下，它会开始收集字符到缓冲区中。\n\n常规处理：在 STRING 状态下，如果遇到普通字符，会直接将其添加到缓冲区。当遇到字符串结束符 &quot; 时，则表明一个完整的字符串已经解析完毕，此时会返回一个代表该字符串的 token。\n转义处理：如果解析器遇到转义符 \\，我们让它暂时切换到 ESCAPE 状态。在这个状态下，它会处理各种转义序列，例如 \\n（换行）或 \\t（制表符）。处理完毕后，解析器会返回到 STRING 状态，继续收集字符。\n错误处理：为了确保词法分析的健壮性，我们需要对字符串常量中的各种错误进行处理：\n对于未闭合的字符串（如遇到换行符或文件提前结束），应立即报告错误。\n对于字符串中包含空字符（\\0）或字符串长度超过限制（如超过 1024 字节）的情况，应在整个字符串处理完成后再报告错误。\n\n\n\n我们利用宏定义#define STRING_TOO_LONG (string_buf_ptr &gt;= string_buf + MAX_STR_CONST)\n来判断字符串数组是否过长，如果过长不再继续插入字符。\n\\&quot;          &#123;  string_buf_ptr = string_buf;  BEGIN(STRING);&#125;&lt;STRING&gt;\\&quot; &#123;  *string_buf_ptr = &#x27;\\0&#x27;;  BEGIN(INITIAL);  if(string_has_null == 1)&#123;    yylval.error_msg = &quot;String contains null character&quot;;    return (ERROR);  &#125;  if(STRING_TOO_LONG)&#123;    yylval.error_msg = &quot;String constant too long&quot;;    return (ERROR);  &#125;  yylval.symbol = stringtable.add_string(string_buf);  return (STR_CONST);&#125;&lt;STRING&gt;\\\\ &#123;  BEGIN(ESCAPE);&#125;&lt;STRING&gt;\\n &#123;  BEGIN(INITIAL);  curr_lineno++;  yylval.error_msg = &quot;Unterminated string constant&quot;;  return ERROR;&#125;&lt;STRING&gt;&lt;&lt;EOF&gt;&gt; &#123;  BEGIN(INITIAL);  yylval.error_msg = &quot;EOF in string constant&quot;;  return ERROR;&#125;&lt;STRING&gt;[^\\n\\\\\\&quot;] &#123;  if (yytext[0] == &#x27;\\0&#x27;)    string_has_null = 1;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = yytext[0];&#125;&lt;ESCAPE&gt;n &#123;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = &#x27;\\n&#x27;;  BEGIN(STRING);&#125;&lt;ESCAPE&gt;b &#123;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = &#x27;\\b&#x27;;  BEGIN(STRING);&#125;&lt;ESCAPE&gt;t &#123;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = &#x27;\\t&#x27;;  BEGIN(STRING);&#125;&lt;ESCAPE&gt;f &#123;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = &#x27;\\f&#x27;;  BEGIN(STRING);&#125;&lt;ESCAPE&gt;v &#123;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = &#x27;\\v&#x27;;  BEGIN(STRING);&#125;&lt;ESCAPE&gt;\\n &#123;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = &#x27;\\n&#x27;;  ++curr_lineno;  BEGIN(STRING);&#125;&lt;ESCAPE&gt;&lt;&lt;EOF&gt;&gt; &#123;  BEGIN(INITIAL);  yylval.error_msg = &quot;EOF in string constant&quot;;  return (ERROR);&#125;&lt;ESCAPE&gt;. &#123;  if (yytext[0] == &#x27;\\0&#x27;)    string_has_null = 1;  if(!STRING_TOO_LONG)    *string_buf_ptr++ = yytext[0];  BEGIN(STRING);&#125;\n\n注意：以上内容按模块编写，但并不意味着全部按顺序拼接即可，因为规则是有先后顺序的，写的顺序不对可能导致某些规则永远无法匹配上，具体代码见 GitHub。\n\n小结PA2 并不算困难，在 Flex 的帮助下，只需要写正则表达式的我们没有什么需要动脑子的地方，但是细节真的很多，在一大堆信息里面找有用的信息也并不是一件轻松的事情……话说程序里面居然真的会有空字符啊。\n顺手贴一个通关截图：\n\n  \n  通关截图\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","词法分析","正则表达式"]},{"title":"CS143-PA4：Semantic Analysis","url":"/2025/08/17/CS143-PA4%EF%BC%9ASemantic-Analysis/","content":"\n前排提醒：本文采用 C++ 实现，如果使用 java 建议参考其他文章。\n\n语义分析准备工作本次作业的目标是：实现一个可以给正确的 AST 添加类型注释的语义分析器。\n在 assignments/PA4 目录下执行命令：\nmake semant\n会生成一个名为 semant 的可执行文件，可以通过运行 ./mysemant test.cl 来对指定文件进行词法分析。这里的 mysemant 同样也是一个 csh 脚本，如果用的是 bash 的话也需要将开头的 csh 改成 bash，或者直接运行\n./lexer test.cl | ./parser | ./semant\n在语义分析过程中，semant-phase.cc 提供程序入口，负责驱动并测试语义分析器；cool-tree.aps 定义 AST 结构，并自动生成 cool-tree.h 与 cool-tree.cc 以支持树节点的构造与处理；symtab.h 提供了一个符号表的实现，剩下的 ast-lex.cc 和 ast-parse.cc 等文件为辅助代码，不需要修改。\n回到 PA4，我们的核心任务是完善 semant.h 和 semant.cc 文件，实现正确的类型检查逻辑，并为 AST 节点添加相应的类型注释，同时使用作业提供的方法来报告错误。此外，我们还需要在 cool-tree.h 中为 AST 类添加必要的方法，以支持类型信息的存储、查询与计算。\n需要注意的是，cool-tree.cc 包含了已提供方法的定义以及列表处理函数模板的实例化，但我们不得修改该文件，在 cool-tree.h 中新增的方法，其具体实现必须放在 semant.cc 中。\n同时，还要注意 cool-tree.handcode.h 与 PA3 中提供的版本相比已有调整，应以当前版本为准。\n实现\n在开始之前，建议先阅读 handouts/cool-manual 的第三、八节和第十二节，分别详细介绍了 Cool 的类型和类型规则。同时，推荐仔细阅读所有用到的文件，以便理解程序逻辑。\n\n类的继承关系在进行类型检查之前，我们需要先对类的继承关系进行初步的分析和处理，我们采用两个类来实现这一点。\nClassNode 用于表示单个类节点，而 ClassTable 负责收集所有类声明，构建全局符号表。在此基础上，它依据继承关系构造类继承树，并进行继承合法性检查，包括检测循环继承和对未定义类的继承等错误。class ClassNode : public class__class&#123;  private:    Inheritable inherit_status;    Basicness basic_status;    Reachable reach_status;    ClassNodeP parent_class;    LClassNodeP children;    EnvironmentP environment;  public:    ClassNode(Class_ nd, Inheritable inherit, Basicness basic);    Symbol get_name();    Symbol get_parent();    Symbol get_filename();    void check_main_method();    void set_parent(ClassNodeP par);    void add_children(ClassNodeP now);    void reach_children();    void build_self_feature_tables();    void init_env(ClassTableP table);    void copy_env(EnvironmentP env);    void check_type();    int basic() &#123;return basic_status == Basic;&#125;    int inherit() &#123;return inherit_status == CanInherit;&#125;    int reach() &#123;return reach_status == CanReach;&#125;    ClassNodeP get_parent_class_nd();    method_class* method_lookup(Symbol sym);&#125;;// 继承单纯为了嫖那个查找功能// 呃，我也不知道为什么我不用 mapclass ClassTable : public SymbolTable&lt;Symbol, ClassNode&gt;&#123;  private:    int semant_errors;    LClassNodeP node_head; // 遍历入口    void install_basic_classes();    void install_class(ClassNodeP nd);    void install_classes(Classes classes);    void check_main();    void handle_inherit();    void check_inherit();    void build_inherit_tree();    void check_class_loop();    void build_all_feature_tables();    ostream&amp; error_stream;  public:    ClassTable(Classes);    int errors() &#123; return semant_errors; &#125;    ClassNodeP root();    ostream&amp; semant_error();    ostream&amp; semant_error(Class_ c);    ostream&amp; semant_error(Symbol filename, tree_node *t);&#125;;\n具体来说，我们先将所有的类安装到 ClassTable 中，然后再单独处理继承关系。// 无论如何都得先进一层全局作用域才能添加identerscope();// 先安装基本类install_basic_classes();// 然后安装用户的类install_classes(classes);// 再处理继承关系handle_inherit();\n继承关系的处理也并不复杂，在检查完所有类的继承关系是否合法之后，就可以建立继承树，最后判断有没有环即可。因为 Cool 语言中我们有唯一的树根 Object 类，所以会简单一些，只要看有没有 Object 类到达不了的节点就行了。void ClassTable::handle_inherit() &#123;    // 先检查一手    check_inherit();    // 然后建树    if(errors()) return;    build_inherit_tree();    // 最后判环    check_class_loop();&#125;\n构建特性表特性表的构建需要用到环境，或者说在这个阶段把特性表绑定到环境里面会比较方便。环境包括方法表、属性表、类表和当前类，类表和当前类已经处理完，我们目前需要处理方法表和属性表。\nclass Environment &#123;  private:    SymbolTable&lt;Symbol, method_class&gt; method_table;    SymbolTable&lt;Symbol, Entry&gt; var_table;    ClassTableP class_table; // 引用类表，方便查找    ClassNodeP self_class;  public:    Environment(SymbolTable&lt;Symbol, method_class&gt; met, SymbolTable&lt;Symbol, Entry&gt; var, ClassTableP table, ClassNodeP now_class);    Environment(ClassTableP table, ClassNodeP now_class);    EnvironmentP clone_env(ClassNodeP self);    ostream&amp; semant_error();    ostream&amp; semant_error(tree_node* t);    ClassNodeP lookup_class(Symbol sym);    void method_add(Symbol sym, method_class* method);    method_class* method_lookup(Symbol sym);    method_class* method_probe(Symbol sym); // 嗯，method不需要进出作用域    void var_add(Symbol sym, Symbol var);    Symbol var_lookup(Symbol sym);    Symbol var_probe(Symbol sym);    void var_enterscope();    void var_exitscope();    Symbol get_self_type();    void check_main_method();    int type_leq(Symbol type_a, Symbol type_b);    Symbol type_lub(Symbol type_a, Symbol type_b);&#125;;\n我们从根开始，先初始化环境，然后沿着继承树向下建立特性表。\nvoid ClassTable::build_all_feature_tables() &#123;    root()-&gt;init_env(this);    root()-&gt;build_self_feature_tables();&#125;\n我们每个继承树节点都将本节点的特性加入环境中，然后传递到所有子节点中，注意需要构建新环境，不要直接复制指针。void ClassNode::build_self_feature_tables() &#123;    for(int i = features-&gt;first(); features-&gt;more(i); i = features-&gt;next(i))        features-&gt;nth(i)-&gt;add_to_table(environment);    for(LClassNodeP i = children; i; i = i-&gt;tl()) &#123;        i-&gt;hd()-&gt;copy_env(environment);        i-&gt;hd()-&gt;build_self_feature_tables();    &#125;&#125;\n类型检查重头戏当然是类型检查，不过主要是比较繁琐，加上要处理每种表达式的类型检查，所以写起来比较麻烦。但跟着 Cool 第十二节还是相当清晰的。（不过有几个命名跟类名不一样找了我好久）void ClassNode::check_type() &#123;    for(int i = features-&gt;first(); features-&gt;more(i); i = features-&gt;next(i))        features-&gt;nth(i)-&gt;tc(environment);       for(LClassNodeP i = children; i; i = i-&gt;tl())        i-&gt;hd()-&gt;check_type();&#125;\n小结PA4 难度激增，主要是自由度陡然增大带来的，而且对 C++ 面向对象的要求也比较高（当然可以不面向对象，但那样显然不够工程化，跟接口也不搭）。实现加调试一共花了四天的时间，呃，跟前几个好像没多大差别（看来是前几个 PA 太划水了）。不过回过头看，这次的实现逻辑其实非常清晰，这很大程度上得益于框架提供的完善接口。此外，我也参考了 GitHub 上一些其他同学的代码，其中一些思路清晰、结构清晰的实现对我帮助很大，用三个类来实现的思想也是从中得到的启发。总之，这个 PA 让我受益匪浅，尤其是面向对象现在熟练了很多。\n快乐地贴一个通关截图：\n\n  \n  通关截图\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","语义分析","类型检查"]},{"title":"CS143-PA5：Code generation","url":"/2025/09/20/CS143-PA5%EF%BC%9ACode-generation/","content":"代码生成准备工作本次作业的目标是：实现一个可以将带有类型注释的 AST 翻译为 MIPS 代码的代码生成器。\n在 assignments/PA5 目录下执行命令：\nmake cgen\n会生成一个名为 cgen 的可执行文件，可以通过运行 ./mycoolc test.cl 来对指定文件进行代码生成。这里的 mycoolc 还是个 csh 脚本，如果用的是 bash 的话也需要将开头的 csh 改成 bash，或者直接运行\n./lexer test.cl | ./parser | ./semant | ./cgen\n在代码生成阶段，cgen-phase.cc 提供了编译器驱动，symtab.h 提供了符号表实现，cgen_supp.cc 提供了一些可以用在代码生成器中的辅助函数（事实上我没用到），emit.h 定义了生成 MIPS 指令时常用的宏（这个文件当然可以修改）。其余文件均为辅助代码，无需改动。\n回到 PA5，我们的核心任务是完善 cgen.h 和 cgen.cc 文件，实现面向对象代码的汇编生成。cgen.cc 作为框架，已经事先提供了三个部分：  \n\n构建继承图的函数；  \n输出全局数据和常量的函数；  \n输出 MIPS 指令的函数。\n\n嗯，框架就有 1000 多行呢。不过好在代码生成过程中不需要再检查输入是否错误，因为所有错误的 Cool 程序都已被编译器前端阶段检测到了。但我们仍然需要插入运行时错误检查代码，保证程序在遇到非法操作时能输出错误信息并终止。\n那么接下来，我们将面对的就是最后一个 Assignment，也是最复杂的一个 Assignment，祝你，也祝我自己好运~\n实现\n在开始之前，建议先阅读 handouts/cool-tour 的第七节，详细介绍了 Cool 语言的操作语义和运行时系统。也推荐仔细阅读所有用到的文件，这可能会让你的编码工作简单不少。已经提供的代码或许写法比较奇怪，不过还是建议耐心阅读。\n\n输出全局常量输出常量只需要我们对原有的代码进行一些小的修补即可，参考标准编译器得到的代码我们可以很容易地补全调度指针的信息，比如 Int 的调度指针只需修改 code_def 为以下代码：void IntEntry::code_def(ostream &amp;s, int intclasstag)&#123;  // Add -1 eye catcher  s &lt;&lt; WORD &lt;&lt; &quot;-1&quot; &lt;&lt; endl;  code_ref(s);  s   &lt;&lt; LABEL                                            // label      &lt;&lt; WORD &lt;&lt; intclasstag &lt;&lt; endl                      // class tag      &lt;&lt; WORD &lt;&lt; (DEFAULT_OBJFIELDS + INT_SLOTS) &lt;&lt; endl  // object size      &lt;&lt; WORD &lt;&lt; INTNAME &lt;&lt; DISPTAB_SUFFIX &lt;&lt; endl;       // dispatch table      &lt;&lt; WORD &lt;&lt; str &lt;&lt; endl;                             // integer value&#125;\n我们还需要生成原型对象，开始我觉得跟常量的生成没有太大差别，属性的个数遍历一遍自己的成员表即可。但在 DEBUG 的过程中，我发现原型对象其实并不能简单地全部在属性位置地址赋0，会导致未初始化的属性被使用的情况，此时会报错。我们需要在生成原型的时候就对 Int,String,Bool 三个类型的属性赋初值（0），这样才不会出现初始化调用的方法使用了还未初始化的属性的情况。\nvoid CgenNode::code_prototype_table(ostream &amp;str)&#123;  if(name == Str)  &#123;    str &lt;&lt; WORD &lt;&lt; &quot;-1&quot; &lt;&lt; endl        &lt;&lt; STRINGNAME &lt;&lt; PROTOBJ_SUFFIX &lt;&lt; LABEL        &lt;&lt; WORD &lt;&lt; class_tag &lt;&lt; endl        &lt;&lt; WORD &lt;&lt; (DEFAULT_OBJFIELDS + STRING_SLOTS + 1) &lt;&lt; endl        &lt;&lt; WORD &lt;&lt; STRINGNAME &lt;&lt; DISPTAB_SUFFIX &lt;&lt; endl        &lt;&lt; WORD &lt;&lt; INTCONST_PREFIX &lt;&lt; 1 &lt;&lt; endl;    emit_string_constant(str,&quot;&quot;);     str &lt;&lt; ALIGN;  &#125;  else  &#123;    str &lt;&lt; WORD &lt;&lt; &quot;-1&quot; &lt;&lt; endl        &lt;&lt; name &lt;&lt; PROTOBJ_SUFFIX &lt;&lt; LABEL        &lt;&lt; WORD &lt;&lt; class_tag &lt;&lt; endl        &lt;&lt; WORD &lt;&lt; (DEFAULT_OBJFIELDS + attr_num) &lt;&lt; endl        &lt;&lt; WORD &lt;&lt; name &lt;&lt; DISPTAB_SUFFIX &lt;&lt; endl;    for (LEntryP l = attr_table; l; l = l-&gt;tl())    &#123;        Symbol type_decl = attr_type_table[l-&gt;hd()];        if(type_decl == Int || type_decl == Str || type_decl == Bool)          str &lt;&lt; WORD &lt;&lt; type_decl &lt;&lt; PROTOBJ_SUFFIX &lt;&lt; endl;        else          str &lt;&lt; WORD &lt;&lt; 0 &lt;&lt; endl;    &#125;  &#125;  for(LCgenNodeP l = children; l; l = l-&gt;tl())    l-&gt;hd()-&gt;code_prototype_table(str);&#125;\n输出全局表我们需要输出 class_nameTab、class_objTab和调度表（dispatch tables），前两个差别不大，关键在于调度表。为此，我们需要整理出每个类的方法，然后拼凑出调度表。我们按照继承树进行前序遍历，那么每个类构建调度表前其父类已构建完，我们可以复制过来，然后进行修改即可。\n首先为了之后查找属性和方法方便，我们需要对二者进行分离。我们会先记录属性表，并同时保存每个属性对应的类型，这样在初始化原型对象时，就能更方便地为基本类型赋初值。基本思路是每次复制父类的属性表和类型表，然后直接添加即可。因为属性不能覆写，所以不需要进行额外处理。void CgenNode::build_attr_table(int flag)&#123;  if(name != Object)  &#123;    LEntryP pa_attr_table = parentnd-&gt;get_attr_table();    attr_type_table = parentnd-&gt;get_attr_type_table();    for(LEntryP l = pa_attr_table; l; l = l-&gt;tl())    &#123;      attr_table = new_lnode(attr_table, l-&gt;hd());      attr_num++;    &#125;  &#125;  for(int i = features-&gt;first(); features-&gt;more(i); i = features-&gt;next(i))  &#123;    Feature curr_feature = features-&gt;nth(i);    attr_type_table[curr_feature-&gt;get_name()] = curr_feature-&gt;get_type_decl();    if (curr_feature-&gt;attr_flag() == flag) // 我们 PA5 都在 cool-tree.handcode.h 里面定义，不过 PA4 是 cool-tree.h 里面    &#123;      attr_table = new_lnode(attr_table, curr_feature-&gt;get_name());      attr_num++;    &#125;  &#125;&#125;\n我们用 method_table 来记录当前类能够使用的所有方法，pa_method_table 来记录方法具体来自于哪个类。如果该方法在父类中已经存在则覆写以实现多态，只需修改方法来源即可，否则需要添加进方法表，并且记录方法来源。方法表会稍微麻烦一些，因为允许不加声明地覆写父类的方法，所以我们不得不每次查调度表看有没有这个方法，有就直接覆写，没有就新建。void CgenNode::build_method_table(int flag)&#123;  if(name != Object)  &#123;    method_symbol_table = parentnd-&gt;get_method_symtab();    LEntryP pa_method_table = parentnd-&gt;get_method_table();    for(LEntryP l = pa_method_table; l; l = l-&gt;tl())    &#123;      method_table = new_lnode(method_table, l-&gt;hd());      method_num++;    &#125;  &#125;  for(int i = features-&gt;first(); features-&gt;more(i); i = features-&gt;next(i))  &#123;    Feature curr_feature = features-&gt;nth(i);    if (curr_feature-&gt;attr_flag() == flag) // 这里还是 attr_flag,差点全改了）    &#123;      if(method_symbol_table.count(curr_feature-&gt;get_name()))      &#123;        method_symbol_table[curr_feature-&gt;get_name()] = name; // 只要改调度表名字      &#125;      else      &#123;        method_table = new_lnode(method_table, curr_feature-&gt;get_name());        method_symbol_table[curr_feature-&gt;get_name()] = name;        method_num++;      &#125;    &#125;  &#125;&#125;\n初始化各个类在类的初始化过程中，原型对象的属性已经具备默认初值，因此只需依次调用各属性的初始化代码并将结果保存即可。需要注意的是，如果 Cool 代码中未显式初始化某个属性，编译器会调用 no_expr_class::code，其返回地址为 0，此时我们不能用该结果覆盖已有的初值。void CgenNode::code_init_func(ostream &amp;str, CgenClassTableP curr_class_table, int &amp;label_index)&#123;  str &lt;&lt; name-&gt;get_string() &lt;&lt; CLASSINIT_SUFFIX &lt;&lt; LABEL;  emit_addiu(SP, SP, -16, str);              // 分配栈空间  emit_store(FP, 4, SP, str);                // 保存帧指针  emit_store(SELF, 3, SP, str);              // 保存 self 指针    emit_store(S1, 2, SP, str);                // 保存寄存器  emit_store(RA, 1, SP, str);                // 保存返回地址  emit_addiu(FP, SP, 4, str);                // 设置新帧指针  emit_move(SELF, ACC, str);                 // self = 传入的对象指针  if(name != Object)  &#123;    str &lt;&lt; JAL &lt;&lt; parentnd-&gt;get_name() &lt;&lt; CLASSINIT_SUFFIX &lt;&lt; endl;    int curr_attr_num = parentnd-&gt;get_attr_num() + 3;    for (int i = features-&gt;first(); features-&gt;more(i); i = features-&gt;next(i))    &#123;      Feature curr_feature = features-&gt;nth(i);      if (curr_feature-&gt;attr_flag())      &#123;        curr_feature-&gt;get_init()-&gt;code(str, this, curr_class_table, label_index);  // 生成初始化代码        emit_beqz(ACC, ++label_index, str);        emit_store(ACC, curr_attr_num++, SELF, str);  // 存储到对象的属性槽        emit_branch(label_index, str);        emit_label_def(label_index, str);      &#125;    &#125;  &#125;  emit_move(ACC, SELF, str);        // 返回值 = self  emit_load(FP, 4, SP, str);        // 恢复寄存器  emit_load(SELF, 3, SP, str);  emit_load(S1, 2, SP, str);  emit_load(RA, 1, SP, str);  emit_addiu(SP, SP, 16, str);      // 回收栈空间  emit_return(str);                 // 返回  for(LCgenNodeP l = children; l; l = l-&gt;tl())    l-&gt;hd()-&gt;code_init_func(str, curr_class_table, label_index);&#125;\n各个方法的代码生成首先得注意基本类的方法是不需要我们写的，因此我们只需要生成非基本类的方法代码。我们每次把参数压栈，处理完方法的初始化代码后弹栈然后返回即可。void method_class::code_method(ostream&amp; str, CgenNodeP curr_node, CgenClassTableP curr_class_table, int&amp; label_index)&#123;  str &lt;&lt; curr_node-&gt;get_name() &lt;&lt; &quot;.&quot; &lt;&lt; name &lt;&lt; LABEL;  emit_addiu(SP, SP, -16, str);  emit_store(FP, 4, SP, str);    emit_store(SELF, 3, SP, str);  emit_store(S1, 2, SP, str);  emit_store(RA, 1, SP, str);    emit_addiu(FP, SP, 4, str);   emit_move(SELF, ACC, str);   for (int i = formals-&gt;first(); formals-&gt;more(i); i = formals-&gt;next(i))    curr_node-&gt;add_formal_node(formals-&gt;nth(i)-&gt;get_name());  expr-&gt;code(str, curr_node, curr_class_table, label_index);  emit_load(FP, 4, SP, str);  emit_load(SELF, 3, SP, str);  emit_load(S1, 2, SP, str);  emit_load(RA, 1, SP, str);  emit_addiu(SP, SP, 16, str);  for(int i = formals-&gt;first(); formals-&gt;more(i); i = formals-&gt;next(i))  // 这里要弹栈！！！    emit_addiu(SP, SP, 4, str);  emit_return(str);  // 弹完再返回！！！  curr_node-&gt;remove_formal_node();&#125;\n表达式的代码生成表达式太过复杂，所以我们这里只提一下我在 DEBUG 过程中遇到的一些问题：\n\ntype 是语义分析时得到的静态类型，不要用它去比较两个表达式类型是否相同；\nlet 表达式赋值是跟 assign 无关的，所以 let 里面要单独处理赋值，而且要特别处理 Int,String,Bool 三个类的初始化；\n条件判断、求值都得先取数值，要分清数值和地址的区别；\n调度的时候要特别处理 SELF_TYPE，不能直接用它去找调度指针；\n就算是动态分配也不能通过函数名直接跳到函数，还是得查调度表，不然可能这个函数是继承来的然后没有定义；\n方法要先弹栈再返回；\n最重要的是时刻要注意 load 的地址有没有可能还是 0，如果我写代码的时候时刻注意这一点，有很多地方本该第一次写对的，DEBUG 确实浪费了挺多时间。\n\n小结至此，5 个 PA 全部完成（PA5 我没写垃圾回收，所以可能会爆栈，但已经实现了正确的代码生成），还是蛮不容易的。前三个 PA 就是对着语法规范抄就行，但最后两个 PA 确实相当困难，尤其是 PA5 没参考其他人的代码更显困难，细节相当的多，修改一个地方很可能只多对一个小测试点，这也体现出测试集相当的全面。仅仅是 DEBUG 部分就花了我三天时间，整个 PA 花了一个星期，着实是不容易，不过总算是完成了！这个 PA 让我现在对内存空间有了更加深刻的理解，彻底理解了虚函数和调度，面向对象也熟练了许多，尤其是对汇编的理解大大提升了，从一开始完全不了解到现在能够完成从 AST 到汇编的完整转换，确实是不容易啊o(￣▽￣)ブ\n照例贴一个通关截图：\n\n  \n  通关截图\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","代码生成"]},{"title":"CS143-Week7：Code Generation","url":"/2025/09/20/CS143-Week7%EF%BC%9ACode-Generation/","content":"代码生成代码生成的主要难度在于同时满足正确性与效率。\n我们采用 MIPS 指令集架构（或其模拟器）作为目标平台，以便在真实环境中运行并验证生成的代码。具体而言，通过 MIPS 指令在寄存器和栈上模拟 1-寄存器栈机的运行：寄存器 $a_0$ 作为累加器，用于保存和更新中间结果，而栈则存储在内存中。累加器在逻辑上相当于栈顶，但为避免混淆，我们仍将其与内存部分区分开来。\n计算模式的两个基本假设实际的计算模式相当复杂，为了简化，CS143 有以下两个基本假设：\n\n串行计算假设  \n\n计算按顺序执行，无并发干扰  \n❌ 反例：并发（concurrency）、多线程、异步任务\n\n\n控制流可返回假设  \n\n函数调用后总能返回调用点并继续执行  \n❌ 反例：异常（exception）、call/cc（续体）、非局部跳转（如 longjmp）\n\n\n\nMIPS 架构在进一步阐述代码生成的内容前，我想我们需要对 MIPS 架构有一个基本的了解。MIPS 属于 RISC 架构，运算主要依赖寄存器，而大量数据（如变量、数组、栈帧）则需存放在内存中。所有算术和逻辑指令都只能作用于寄存器，不能直接操作内存。若要与内存交互，必须先用 lw 将数据加载到寄存器中，运算完成后再用 sw 写回内存。\n编译器、操作系统与硬件的关系为了更好地理解 MIPS 汇编代码的生成过程，我们需要明确编译器、操作系统和硬件在整个过程中各自扮演的角色。\n1. 编译器 (Compiler)编译器的任务是将高级语言代码转换为机器码（汇编或二进制）。在这个过程中，编译器需要：\n\n分配寄存器：决定哪些变量或中间结果应存储在寄存器中。\n生成内存访问指令：使用虚拟地址来访问内存中的数据（如变量、数组等）。\n\n视角：\n程序视角：程序能直接感知的主要是一块栈，用于存放局部变量和函数调用信息，但它也可能访问全局变量、堆或指定的内存地址。编译器负责生成对寄存器和这些逻辑内存区域的操作指令，而这些内存在物理上的具体位置及其映射由操作系统和硬件管理。\n\n示例：lw  $t0, 0x1000  # 假设 0x1000 是变量 b 的虚拟地址\n2. 操作系统 (OS)操作系统负责管理多个进程，并提供每个进程独立的虚拟地址空间，以保证隔离和保护。具体职责包括：\n\n地址映射：管理虚拟地址到物理地址的映射（通过页表）。\n进程隔离：确保不同进程的虚拟地址空间互不干扰。\n\n视角：\n裸机/内核程序：虚拟地址 = 物理地址（无需翻译）。\n用户程序：虚拟地址 $\\neq$ 物理地址，需要通过页表翻译成物理地址。\n\n3. 硬件 (CPU + MMU + DRAM)硬件执行实际的指令，操作寄存器，并通过内存管理单元（MMU）查询页表将虚拟地址翻译为物理地址，最终访问实际的物理内存。\n具体职责：\nCPU：执行指令，操作寄存器。\nMMU：将虚拟地址翻译为物理地址。\nDRAM：存储实际的数据。\n\n对比总结编译器、操作系统与硬件在程序执行过程中各司其职：编译器负责生成高效的机器代码，重点关注寄存器分配和虚拟地址空间的布局；操作系统则管理虚拟地址到物理地址的映射，通过页表和 MMU 实现地址翻译，并提供进程间的隔离与保护；而硬件（包括 CPU 和内存系统）只直接识别寄存器和物理地址，最终完成所有数据的存取操作。在无操作系统支持的环境（如裸机或内核代码）中，编译器生成的地址即为物理地址，可直接访问内存；而在有操作系统管理的用户程序中，编译器使用虚拟地址，程序运行时由操作系统配合 MMU 将其动态翻译为物理地址，实现安全、隔离的内存访问。\n常用 MIPS 指令\nlw reg1, offset(reg2)将内存地址 (reg2 + offset) 中的 32 位字加载到寄存器 reg1 中\n\nli reg, imm将立即数 imm 加载到寄存器 reg 中（伪指令，通常汇编为 addiu）\n\nla reg, label将标签 label 的地址加载到寄存器 reg 中（不会访问内存，只是取地址）。\n\nsw reg1, offset(reg2)将寄存器 reg1 中的 32 位字存储到内存地址 (reg2 + offset) 处\n\nadd(reg), add(imm)执行加法运算：\n\nadd reg1, reg2, reg3：reg1 ← reg2 + reg3（带溢出检测）\naddi reg1, reg2, imm：reg1 ← reg2 + imm（立即数加法，带溢出检测）\naddu / addiu：同上，但不检查溢出，更加常用\n\n\nsub(reg), sub(imm)执行减法运算：\n\nsub reg1, reg2, reg3：reg1 ← reg2 - reg3（带溢出检测）\nsubi 不存在，通常用 addi reg1, reg2, -imm 代替\nsubu reg1, reg2, reg3：无溢出检测的减法，推荐使用\n\n\nmove reg1, reg2将寄存器 reg2 的值复制到 reg1 中（伪指令，等价于 add reg1, reg2, $zero）\n\njal label跳转到标签 label 处执行，并将返回地址（下一条指令地址）保存到 $ra 寄存器中，用于函数调用\n\njalr $rs跳转到寄存器 $rs 中存储的地址处执行，并将返回地址（下一条指令地址）保存到 $ra 寄存器中，用于间接函数调用或跳转到动态计算的地址。  \n\njr reg将 PC 设置为寄存器 reg 中的地址，实现跳转；常用于函数返回（如 jr $ra）\n\nb label无条件跳转到标签 label 处执行（不保存返回地址）\n\nbeq reg1, reg2, label如果 reg1 等于 reg2，则跳转到 label；否则继续执行下一条指令\n\nbne reg1, reg2, label如果 reg1 不等于 reg2，则跳转到 label\n\n\n算术表达式的代码生成算术表达式的代码生成就是将表达式的结构直接映射为指令的执行序列。由于栈机依赖隐式操作数栈，计算一个算术表达式只需依次生成其子表达式的求值代码，再追加对应的操作指令。例如，表达式 $e_1 + e_2$ 的代码并非独立存在，而是由 $e_1$ 的代码、$e_2$ 的代码和一条 add 指令拼接而成——这本质上是一个递归构造过程。我们可以把每一个运算符看作一个“模板”，用其操作数的代码递归填充“空位”，不难想到利用 AST 递归下降遍历即可：遇到叶子节点（如常量或变量）时生成 push 指令；遇到内部节点（如二元运算）时，先递归生成左右子树的代码，再输出操作指令。\n在此过程中只需使用寄存器 $a_0,t_1,sp$，它们均为 Caller-Saved 寄存器，因此除要求 $sp 在表达式求值前后保持不变外，不得依赖这些寄存器的值，其保存与恢复责任由调用者承担。也就是说，计算结果会在寄存器 $a_0$ 中，但如果需要保存，需要压入栈中。\n控制流的代码生成控制流语句（如 if、while）的代码生成不再局限于表达式的递归拼接，而是需要引入标签和条件跳转来构造程序的执行路径。其核心思想是将控制结构“展平”为带跳转的线性指令序列，利用条件判断引导执行流走向不同的代码块，用到的多是无条件跳转。\n以 if (e) S1 else S2 为例，其代码结构如下：\n\n生成 e 的求值代码，结果保存在 $a_0$ 中；\n添加条件跳转指令 beq $a0 $zero else_label，若条件为假则跳转至 else 分支，否则按顺序继续执行；\n生成 S1 的代码；\n添加无条件跳转 b end_label，避免执行 S2；\n插入 else_label: 标签，生成 S2 的代码；\n插入 end_label: 标签，作为后续代码起点。\n\n循环结构（如 while）类似，但我们需要反向跳转，这样就可以构成一个循环结构。例如 while (e) S 的代码：\n\n插入 loop_start: 标签；\n生成 e 的求值代码；\n添加 beq $a0 $zero loop_end，若条件为假则退出循环；\n生成 S 的代码；\n添加 j loop_start，跳回循环头部；\n插入 loop_end: 标签。\n\n在此过程中，必须确保标签的唯一性（我们通过计数器生成全局唯一标签），并正确管理控制流的汇合点。由于跳转指令只能基于寄存器进行判断，因此在生成条件代码时，必须确保条件表达式的求值结果最终存放在某个寄存器中，以便用于跳转判断。\n函数的代码生成函数的代码生成涉及跳转和栈帧管理等内容，是代码生成中最复杂的部分之一。为了尽可能地简单，我们用栈传递所有参数（实际我们一般会将前4-8个参数用寄存器传递）。函数的调用通过 jal 指令实现，返回则通过 jr $ra 完成。\n函数调用 $f(e_1, e_2, \\cdots, e_n)$ 的代码生成步骤如下：\n1. Caller 端：参数压栈与跳转\n按顺序生成每个参数表达式 $e_i$ 的计算代码。\n将每个参数依次 压入栈（$sp 向低地址移动）。\n调用 jal f，返回地址自动保存到 $ra。\n\n栈顶顺序如下（刚压完参数）：\n高地址-----------------...-----------------参数 e1参数 e2...参数 en----------------- ← $sp低地址\n2. Callee 端：建立栈帧函数 f 入口执行以下操作：\n\n为将要保存的寄存器分配空间：\n\naddiu $sp, $sp, -16\n\n保存 $fp\n保存 Callee-saved 寄存器（$s0、$s1）到栈中。\n保存 $ra\n更新 $fp，固定指向栈帧基址：\n\naddiu $fp, $sp, 4\n此时栈结构（高地址在上，低地址在下）：\n高地址-----------------参数 e1参数 e2...参数 en----------------- ← $sp 原位置（调用 f 后）保存的 $fp             ← $fp + 3保存的 $s1             ← $fp + 2self (对象指针)        ← $fp + 1 保存的 $ra             ← $fp + 0  ← $fp 指向这里-----------------局部变量 / let 临时区----------------- ← $sp 新位置低地址\n\n正偏移 $fp + offset * size → 访问参数（如 $fp + 2 * 4 是 e2）\n负偏移 $fp - offset * size → 访问局部变量 / 保存的寄存器\n\n3. 函数返回\n将返回值写入 $a0。\n恢复栈帧：\n\nmove $sp, $fplw   $ra, offset($sp)lw   $fp, offset($sp)\n\n执行 jr $ra，返回到 caller 位置。\n\n变量引用的代码生成在这个简单的语言中，我们只有 临时变量、参数 和 属性。\n所有参数都通过栈进行传递，因此参数的引用可以直接通过 fp` 查找。假设 `$x_i 是当前正在生成代码的函数的第 $i$ 个形式参数（$i = 1,\\cdots,n$），则生成的代码为：\ncgen(x_i) = lw $a0 z($fp)    （z = 4*i）\n也就是说，通过帧指针 $fp 加上偏移 $4*i$ 来访问第 $i$ 个参数，并将其加载到寄存器 $a0 中。\n临时变量同样存放在帧指针 $fp 下方，通过相应偏移访问。对于属性，它们属于对象本身，因此通过 SELF（当前对象寄存器）加上偏移来访问，并将其加载到寄存器 $a0 中。\n在更加复杂的语言中，变量引用也会变得相当复杂。全局变量储存在栈与代码之间，可以通过静态地址访问；局部变量则储存在栈帧上，其位置在语义分析时通过符号表确定，在符号表中查找该变量的记录后通过 $fp 的偏移访问。\n优化栈操作表达式求值会产生大量中间结果，如果每次压栈弹栈效率相当低。一个解决方法是在函数分析阶段静态计算最大临时变量数量 NT(e)，并在栈帧中为其预留固定栈空间。临时变量像局部变量一样通过固定偏移访问，减少栈操作，提高效率。\n示例：\ndef fib(x) =     if x = 1 then 0     else if x = 2 then 1     else fib(x-1) + fib(x-2)\n\nfib(x-1) + fib(x-2) 最多需要 2 个临时变量\n编译器在栈帧中为其预留槽位（如 0($sp)、4($sp)）\n函数调用的返回值通常通过寄存器（如 $a0）传递，其计算过程在被调用者的栈帧内完成，无需在调用者的栈帧中预留存储空间。\n\n不难发现临时变量个数有简洁的计算公式：\nNT(e1 + e2) = max(NT(e1), 1 + NT(e2))NT(e1 - e2) = max(NT(e1), 1 + NT(e2))NT(if e1 = e2 then e3 else e4) = max(NT(e1), NT(e2), NT(e3), NT(e4))NT(id(e1,..,en)) = max(NT(e1),.., NT(en))NT(int) = 0NT(id) = 0\n这样一来，我们的栈帧布局就可以修改为：参数区、返回地址、帧指针，以及 NT(e) 个临时变量槽位（没有局部变量、数组就是简洁）。临时变量区域如同一个小型栈缓冲区，代码生成时通过固定偏移量访问，避免了频繁的 push/pop 操作，有效减少了冗余栈指令。\n对象的代码生成之前我们解决了简单的编程语言的代码生成方法，现在我们要来处理一个较为高级的特性——对象。对象与其他编程方式的主要区别在于继承，这意味着如果类 B 继承自类 A，那么所有对类 A 的对象可以正确执行的代码能够不经修改地适用于类 B 的对象。为此，我们需要解决两个问题：\n\n对象在内存中被如何表示\n动态分配是如何实现的\n\n内存表示我们自然想到在内存中用连续一块内存区域来储存对象，这样既能保证继承兼容性，也能简化内存管理。根据其类型不同，对象可能在栈上、堆上，也可能在静态存储区，但无论如何都是占用的一块连续内存空间。在 Cool 语言中，对象的基本内存布局如下：\n\n  \n  对象内存布局\n\n\n类编号是一个整数，用作类的唯一标识符，用于区分不同的类。对象大小同样是一个整数，表示该对象在内存中占用的空间。调度指针则指向方法表 vtable，其中保存了该类的所有方法，方法调用通过调度指针完成。其余部分依次存放对象的各个属性，排列顺序由编译器决定。\n在确定了类 A 的对象布局后，其子类 B 的布局可以很容易地在 A 的基础上扩展——只需在 A 的布局末尾追加 B 新增的属性，并修改方法表。这样既保持了 A 的布局不变，又保证了 B 是 A 的扩展，从而实现子类与父类的兼容性。\n原型对象为了高效生成对象，编译器会为每个类创建一个 原型对象，作为该类的“样板对象”，同时该类的类信息（类编号、对象大小、方法表指针等）也被储存在其中：\n\n内容：原型对象包含类编号、对象大小、方法表指针，以及每个属性的默认值。\n用途：运行时调用 new ClassName 时，直接复制原型对象到堆上，得到一个新的实例，而不需要重复初始化每个字段。\n位置：原型对象通常存放在静态存储区，供程序运行时快速复制。\n\n这样，生成对象时只需复制原型对象，保持了对象布局的一致性，同时节省了初始化开销。\n动态分配方法表本质上是一个函数指针数组，用于支持面向对象语言中的动态分派。每个类都有一张方法表，存储该类所有可调用方法的入口地址。关键在于：同一个方法 f 在该类及其所有子类的方法表中始终位于固定偏移位置。\n这一约定使运行时无需知道对象的具体类型，就能高效调用方法：\n\n从对象的调度指针获取其类型的方法表地址；\n根据方法名（如 f）找到在表中的固定偏移量；\n跳转到 method_table[offset_f] 所指向的函数入口。\n\n例如，调用 obj-&gt;draw() 时，编译器生成的代码通过固定偏移访问方法表，运行时自动跳转到该对象实际类型的 draw 实现，从而实现“同一接口，不同行为”。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","代码生成"]},{"title":"UCAS-nlp-Week1：Python 语言和 Pytorch 介绍","url":"/2025/09/23/UCAS-nlp-Week1%EF%BC%9APython-%E8%AF%AD%E8%A8%80%E5%92%8C-Pytorch-%E4%BB%8B%E7%BB%8D/","content":"Python 简介果然野路子选手还是有些知识点不晓得……\nPython 模块（Module）模块类似于 C 语言中的头文件和 Java 中的包，其实质是 Python 程序，事实上任何 Python 程序都可以作为模块使用。\nPython 的模块分为标准库的模块、第三方模块和自定义模块，有两种方式导入：\n\nimport 模块名1 [as 别名1], 模块名2 [as 别名2]  \nfrom 模块名 import 成员名1 [as 别名1], 成员名2 [as 别名2]\n\n\n\n  \n  `test_module.py` 作为模块\n\n\n\n  \n  `test_module_main.py` 能够导入并使用\n\n\n\nPython 包（Package）包其实就是一个文件夹，但该文件夹下必须存在 __init__.py 文件，用于标识当前文件夹是一个Python包，这个文件的内容可以为空。\n\n  \n    \n    test-package 作为包\n  \n\n  \n    \n    test_module_main.py 能够导入包内的模块并使用\n  \n\n\n\nPytorch 简介好的，这个我是真没用过（笑\nPyTorch 是由 Facebook 开发的开源深度学习框架，可以自动并行加速和自动求导。其核心数据结构是 Tensor，类似于 NumPy 的 ndarray，但可在 GPU 上加速计算。\nTensorTensor（张量） 是一个多维数组，可以表示标量、向量、矩阵等，其创建方式有：\n\ntorch.tensor(data)：由已有数据创建\ntorch.zeros(size)：全 0 张量  \ntorch.ones(size)：全 1 张量  \ntorch.randn(size)：随机正态分布  \n\nTensor 作为张量，可以轻松地改变形状，常用函数包括：\n\nx.shape：查看形状  \nx.view(new_shape)：改变形状（共享内存）  \nx.reshape(new_shape)：改变形状（可能复制数据）  \nx.unsqueeze(dim)：增加维度  \nx.squeeze(dim)：去掉维度  \n\nTensor 可以通过索引与切片来查看其中一部分数据，常用方式包括：\n\nx[i]：取第 i 行  \nx[:, j]：取第 j 列  \nx[1:3, :]：切片  \n\nTensor 可以进行数学运算，常用方式包括：\n\nx + y，x - y，x * y，x / y：逐元素数学运算  \ntorch.matmul(x, y) 或 x @ y：矩阵乘法  \nx.T：转置  \n\nTensor 也可以进行统计运算，常用函数包括：\n\nx.sum()：求和  \nx.mean()：均值  \nx.max() / x.min()：最大/最小值  \nx.argmax() / x.argmin()：最大/最小值索引  \n\n自动求导（Autograd）PyTorch 的 autograd 能自动计算模型参数的梯度，不需要手动推导。\n\nloss.backward()：执行反向传播，计算所有参数的梯度\nx.grad：访问张量的梯度值\noptimizer.zero_grad()：清空参数梯度，防止累积\nwith torch.no_grad():：上下文中不记录梯度，用于推理\nx.detach()：返回不参与梯度计算的张量副本\n\n神经网络（torch.nn）torch.nn 是用来构建神经网络模型的模块，提供了常用层和损失函数。\n常用层\nnn.Linear(in_features, out_features)：全连接层\nnn.Conv2d(in_channels, out_channels, kernel_size)：二维卷积层\nnn.BatchNorm2d(num_features)：批归一化层\nnn.Dropout(p)：Dropout 层，防止过拟合\n\n激活函数\nnn.ReLU()：ReLU 函数\nnn.Sigmoid()：Sigmoid 函数\nnn.Softmax(dim)：Softmax 函数\n\n损失函数\nnn.MSELoss()：均方误差，用于回归\nnn.CrossEntropyLoss()：交叉熵损失，用于多分类\nnn.BCELoss()：二分类交叉熵损失\n\n优化器（torch.optim）torch.optim 被用于更新模型参数，实现梯度下降。\n\noptim.SGD(params, lr)：随机梯度下降优化器\noptim.Adam(params, lr)：Adam 优化器，常用且收敛快\noptimizer.step()：根据梯度更新参数\noptimizer.zero_grad()：清空参数梯度，防止梯度累积\n\n设备管理Pytorch 可以控制模型和数据在 CPU 或 GPU 上运行。\n\ntorch.device(&quot;cuda&quot;) 或 torch.device(&quot;cpu&quot;)：指定设备\nx.to(device)：将张量移动到指定设备\ntorch.cuda.is_available()：检查 GPU 是否可用\n\n模型保存与加载Pytorch 同样支持保存和加载训练好的模型。\n\ntorch.save(model.state_dict(), path)：保存模型参数\nmodel.load_state_dict(torch.load(path))：加载模型参数\nmodel.train()：切换为训练模式\nmodel.eval()：切换为评估模式，停止训练\n\n","categories":["UCAS-nlp"],"tags":["Python","自然语言处理","Pytorch"]},{"title":"CS143-Week8：Optimization","url":"/2025/09/28/CS143-Week8%EF%BC%9AOptimization/","content":"编译原理的最后一个部分——编译器优化。编译器优化是编译器的核心，是最富有深度的一个部分，所以尽管没有对应的 PA，我们也来了解一下这个博大精深的部分。\n中间表示（Intermediate Representation, IR）IR 是一种介于源语言和目标语言之间的抽象代码形式。它既不像目标语言（如机器码）那样依赖具体硬件，也不像高级源语言（如 C、C++ 或 Rust）那样高度抽象，而是在两者之间提供了一个恰到好处的中间层次：既保留了足够的语义细节以支持深入分析，又具备良好的通用性和简洁性。\n正因为这种特性，IR 非常适合用于编译过程中的代码优化。同时，它还能有效解耦编译器的前端与后端：前端负责将不同高级语言统一翻译为同一种 IR，后端就可以专注于将该 IR 转换为多种目标平台的机器码。这样一来，同一份 IR 可被不同架构的后端编译生成对应的可执行代码，真正实现“一次编译，多处生成”。\n我们将要讨论的 IR 是一种高级汇编语言，主要特点包括：\n\n无限寄存器：使用寄存器名称，但寄存器数量理论上不受物理限制；  \n汇编式控制结构：具备跳转、标签等类似汇编的控制流机制；  \n操作码抽象：采用操作码表示操作，其中部分具有更高层次的语义。  \n例如，一条 push 指令在 IR 中可能对应多条底层汇编指令；  \n大多数操作码仍与目标平台的汇编指令保持一一对应，便于后续翻译与优化。\n\n\n\n事实上，每条指令都是一元或二元运算，并且右侧的参数始终是寄存器或常量。由于每条指令至多包含三个地址，因此被称作“三地址码”。通过将高级表达式分解成三地址码，我们实际上为每条指令都赋予了一个唯一的名称，也就是其目标地址。\n然而，在标准三地址码中，同一个变量名仍可能被多次赋值（如 x := y; x := x + 1），这会模糊数据的来源，给优化带来困难。为此，现代编译器进一步采用静态单赋值形式（Static Single Assignment, SSA）对三地址码进行规范化：\n\n在 SSA 形式中，每个变量在其整个作用域内仅被赋值一次，并且不会在定义前被使用。  \n每当一个变量在程序中被重新定义时，就引入一个新的“版本”（通常通过下标区分，如 $x_1$, $x_2$），从而确保每个名字有且仅有一个定义点。\n\n由于我们拥有无限的寄存器，生成中间代码的过程会变得非常简单。我们无需像生成 MIPS 指令那样用不止一条指令来推送结果、调整栈指针以及各式各样繁琐的操作，只需要将后续要用到的的结果保存在一个寄存器中，之后需要再直接取出即可。\n基础优化概念优化目标编译器优化的目标是提升生成代码的质量，主要体现在以下几个方面：\n\n执行速度：通过减少指令数量、优化控制流等手段，提高程序的运行效率。  \n内存使用：优化数据布局、减少内存访问次数，降低内存占用。  \n代码大小：通过消除冗余代码、合并相似代码等方式，减小生成代码的体积。\n\n在实践中，编译器开发者通常会意放弃实现某些已知的“高级”优化，原因往往在于实现复杂度高、编译开销大、实际收益有限等等。而许多所谓的“炫技式”优化，甚至同时具备这三个缺点，自然不被采用。因此，编译器优化的核心原则是：  \n\n以最小的代价，获取最大的收益。\n\n所以说，一项优化只有在能带来显著且可衡量的性能提升时，才值得引入——微不足道的改进不仅无益，反而可能增加系统复杂性与维护成本。\n优化时机不难猜到我们确实会在中间表示上进行优化，但为什么选择在此层次优化的确值得思考。事实上这与不同表示形式的优缺点密切相关：\n\n抽象语法树（AST）  \n优点：完全与具体机器无关  \n缺点：抽象层次过高，难以直接支撑底层优化  \n\n\n汇编语言  \n优点：能充分暴露底层优化机会  \n缺点：高度依赖具体机器架构；若切换目标平台，则所有优化必须重新实现  \n\n\n中间语言（IR）  \n优点：既与机器无关，又保留足够的细节，能够暴露和支撑多种优化\n\n\n\n优化分类编译器的优化从作用范围上可以分为三类：\n\n局部优化局部优化仅针对单个基本块进行，不考虑块之间的控制流关系。\n全局优化全局优化作用于整个控制流图，通常对应一个方法（或函数）的全部代码，能够跨基本块进行分析与优化。\n过程间优化过程间优化跨越方法（或函数）边界，在多个过程之间进行分析与优化，例如内联、跨函数常量传播等。\n\n目前而言，大多数编译器实现了局部优化，有很多编译器实现了全局优化，但仅有极少数的编译器实现了过程间的优化。\n语句组合基本块基本块是一段极大化的代码序列，满足以下条件：\n\n除第一条指令外，内部不含任何标签；  \n除最后一条指令外，内部不含任何跳转或分支指令。\n\n在一个基本块中，程序流是直线型的：它只能从块的开头进入，不能中途跳转；执行也只能从块的末尾退出，不允许中途跳出。基本块是一个典型的单入口、单出口代码序列，它没有控制流，可以假定块内的指令按顺序执行，这使得我们可以比较方便地分析能否进行折叠。\n控制流图控制流图是一种有向图，用于抽象地表示程序的执行路径和控制结构。在我们的代码生成任务中，其定义如下：\n\n节点：图中的每个节点对应程序中的一个基本块。  \n边：若程序执行过程中可能从基本块 A 的最后一条指令直接转移到基本块 B 的第一条指令，则图中存在一条从 A 指向 B 的有向边（记作 $ A \\rightarrow B $）。\n\n控制流转移（即边的来源）主要包括以下两种类型：\n\n显式跳转基本块 A 的最后一条指令是一条条件或无条件跳转指令（如 jump Lb），而目标标签 Lb 恰好位于基本块 B 的起始位置。\n\n顺序执行基本块 A 的末尾没有跳转指令，因此程序会自然地继续执行紧随其后的基本块 B，此时也需要存在一条从 A 指向 B 的边。\n\n\n局部优化正如之前所提到的，局部优化专注于单个基本块的优化，无需担心复杂的控制流问题。局部优化通常包括代数化简、强度削弱等技术，这些技术能够在不影响程序整体逻辑的前提下，显著提升代码性能。\n代数化简代数化简是通过应用数学恒等式来简化表达式的优化技术。其核心思想是利用数学中的基本运算规则，消除冗余计算，从而减少指令数量，提高执行效率。例如：\n\nx * 1 → x  \nx + 0 → x  \nx - x → 0\n\n强度削弱强度削弱是将代价较高的操作替换为等价但计算成本较低的操作。例如：\n\n将平方替换为乘法：x ** 2 → x * x  \n左移代替乘法：x * 2 → x &lt;&lt; 1\n\n常量折叠常量折叠是指在编译时就对表达式中的常量进行计算，将复杂的表达式简化为一个单一的常量值。这种优化不仅减少了运行时的计算负担，还能显著提升代码的执行效率。例如：\n\nx = 3 + 5 → x = 8\nif 2 &gt; 0 jump L → jump L\n\n需要注意的是，在交叉编译时，常量折叠可能会引入一些问题。例如，在不同架构上，浮点数的表示方法可能不同，导致某些计算结果在一个架构上有效，而在另一个架构上则可能溢出或产生未定义行为。因此，在进行常量折叠时，编译器需要确保所做的优化在所有目标架构上都是安全且正确的。\n死代码消除有些代码是无法到达的，通过识别并移除这些冗余代码，可以进一步优化程序的性能。例如：if (DEBUG) &#123;    // 这段代码永远不会被执行    x = x + 1;&#125;在这个例子中，当不开启调试模式时，DEBUG 恒为假，因此 x = x + 1; 这行代码永远不会被执行，可以安全地将其移除。\n另外，尽管我们或许认为程序员不会写出类似 if(false) &#123; ... &#125; 这样冗余代码，但它很可能以隐式的方式存在，是编译器或其他优化过程的结果。因此，实际上死代码消除是非常常见且重要的优化手段。\n公共子表达式消除在同一个基本块内，若某表达式已计算过且操作数未变，那么其结果可以复用。在 SSA 约束下，这种优化变得尤为简单，因为每个变量仅被赋值一次，确保了操作数的唯一性和不变性，所以只要表达式相同即可复用其结果。例如：a = b * c;d = b * c;→t = b * c;a = t;d = t;\n无用赋值消除若 x = y 之后 x 被使用，且 y 未被修改，可直接用 y 替代 x；若 x 之后未被使用，则可删除赋值。\n这一优化策略单独来看似乎没有什么意义，但其真正价值在于能够与其他优化技术（如常量传播）协同工作，从而进一步提升代码质量。\n窥孔优化窥孔优化是一种轻量级的局部优化技术，其核心思想是通过一个滑动的“窥孔”窗口（通常覆盖连续的几条指令），扫描生成的低级代码，识别其中低效、冗余或可简化的指令序列，并用更优的等价形式进行替换\n由于作用范围极小（仅限局部指令序列），窥孔优化的实现开销很低，通常在代码生成阶段之后、目标代码输出之前进行——此时的中间表示已非常接近目标汇编语言，便于利用具体机器的指令特性进行微调。\n这类优化虽不改变程序的整体结构，却能有效提升执行效率、减少代码体积，是编译器后端常用的“收尾”优化手段。\n不难看出，许多局部优化技术同样可以转化为窥孔优化。例如，代数化简、强度削弱、常量折叠等，都可以通过扫描局部指令序列来识别并应用相应的替换规则。\n全局优化数据流分析基本概念数据流分析是一种静态分析技术，用于在编译时推断程序中变量在各程序点的可能取值或属性（如是否为常量、是否被使用等）。\n\n分析对象：控制流图（CFG）\n分析目标：为每个基本块计算 in 和 out 状态（即进入/离开该块时的程序状态）\n核心思想：通过传递规则和合并操作在 CFG 上迭代传播信息\n\n前向/后向分析\n\n\n\n方向\n描述\n\n\n\n\n前向分析\n从入口开始，根据 in 推导 out（如常量传播、可用表达式分析）\n\n\n后向分析\n从出口开始，根据 out 推导 in（如活跃变量分析、可达定义分析）\n\n\n\n\n常量传播常量传播是一种经典的前向数据流分析技术，旨在识别程序执行过程中变量的恒定取值，并据此在编译时用常量替换变量引用，从而实现代码优化。其核心目标是确定在程序的每一个点上，哪些变量持有已知的常量值。为实现这一目标，分析时必须考虑所有可能的执行路径：\n\n条件分支（if/else）\n循环（while/for）\n多个赋值路径汇聚（$\\phi$ 函数，尤其在 SSA 形式中）\n\n符号定义为支持精确分析，常量传播通常定义一个值格：\n\n⊥：表示”未定义”或”不可达”，用于初始化，与非常量区分开\nC：具体常量，如 5, -1, true 等\n⊤：表示”非常量”或”未知值”\n\n代码分析的本质数据流分析本质上是一组规则的迭代应用，每条规则都描述了相邻语句之间的信息是如何变化的。通过不断应用这些规则，直到所有变量的状态不再变化（达到固定点），我们就能得出程序中每个点的变量取值信息。对每个语句，需两类规则：\n\n前向规则：给定 in 状态，计算 out 状态\n后向规则：给定 out 状态，反推 in 状态（较少用于常量传播，但存在于某些分析中）\n\n完整算法流程初始化\n对所有基本块，初始化 in[B] = ⊥（或根据入口块设为初始状态）\n对入口块，in[entry] = 初始环境（如所有变量为 ⊥）\n\n迭代固定点算法repeat  for each basic block B in CFG (in some order):    in[B] = meet(out[P] for all predecessors P of B)    out[B] = transfer(B, in[B])until no changes occur\n主要用到的就两个操作：\n\nmeet 操作：对前驱块的 out 状态进行合并（如取交集或格上的下确界）\ntransfer 函数：根据块内语句应用规则，从 in 计算 out\n\n示例简单分支if (cond)    x = 5;else    x = 10;y = x + 1;  // x is ⊤ → y = ⊤\n由于在合并点，变量 x 的值从前驱路径分别接收了常量 5 和 10，其状态被合并为 ⊤（非常量）。因此，在后续语句 y = x + 1 中，无法对表达式进行常量折叠优化。\n循环示例x = 0;while (i &lt; n)&#123;    x = x + 1;    i++;&#125;// x = ⊤\n由于变量 x 的最终值依赖于循环的执行次数，这在编译时是无法确定的，故而其值被推断为 ⊤（非常量）。在此场景下，底值 ⊥ 至关重要：若没有 ⊥ 来表示“未初始化”的初始状态，数据流分析在循环头节点将无法启动迭代过程。\n收敛性保证在数据流分析中，值格的信息密度上具有偏序关系：\n\n基本顺序：⊥ ≤ C ≤ ⊤\n单调性：每次应用传递函数，信息密度只能沿格上升（即信息保持不变或变得更精确）\n有界性：值格的高度和基本块个数是有限的\n\n基于上述偏序关系，迭代算法必然在有限步内收敛到不动点，即所有 in 和 out 状态不再变化。\n","categories":["CS143"],"tags":["Linux","编译原理","CS143","编译器优化"]},{"title":"UCAS-nlp-Week2：文本爬取和处理","url":"/2025/09/30/UCAS-nlp-Week2%EF%BC%9A%E6%96%87%E6%9C%AC%E7%88%AC%E5%8F%96%E5%92%8C%E5%A4%84%E7%90%86/","content":"文本爬取和处理网络爬虫是一种按照一定的规则，自动地抓取网络中信息的程序，其基本流程为：\n\n发送请求使用 HTTP 客户端库（如 requests）向目标网站发起 HTTP 请求。\n获取响应内容若请求的资源存在于服务器上，服务器将返回响应数据，响应内容通常包括 HTML 文档、图片、视频等资源。\n内容解析对返回的 HTML 数据进行解析，从中提取所需的目标信息。常用方法包括：\n自行寻找规律使用正则表达式进行模式匹配；\n借助专业的 HTML 解析库如 Beautiful Soup，可以更可靠、高效地定位和提取结构化数据。\n\n\n保存数据将解析得到的结构化数据存储到本地。\n\n发送请求和获取响应对于单个网站，我们可以直接调用 requests 库来发送 HTTP 请求并获取响应内容：import requestsdef getHTMLText(url):    try:        response = requests.get(url)        response.encoding = response.apparent_encoding  # 自动识别并设置正确编码        return response.text    except:        print(&quot;爬取失败&quot;)\n如果需要获取的数据比较多，我们一是可以利用 URL 的规律，二是可以以某个网页为种子，找到该网站所有的超链接，再去爬取每个网页：import requestsfrom bs4 import BeautifulSoupdef getHTML(url):    try:        news_list = []  # 空列表        r = requests.get(url)  # 发送请求        r.encoding = r.apparent_encoding  # 获取相应内容编码        soup = BeautifulSoup(r.text, &quot;html.parser&quot;)        tags = soup.find_all(&#x27;a&#x27;)  # 找到所有锚/超链接        for tag in tags:            href = tag.get(&#x27;href&#x27;)            if href:                news_list.append(str(href).strip())  # 得到href        return news_list    except:        print(&quot;爬取失败&quot;)\n解析 HTML 内容分词是自然语言处理中最基础的步骤，其核心任务是将原始文本切分为一个有意义的词序列。事实上，不同语言在词边界标记上存在显著差异：\n\n屈折语（如英语、法语、德语等）：词与词之间通常由空格等显式分隔符明确界定，分词比较直接。\n孤立语与黏着语（如汉语、日语、越南语等）：词与词之间没有天然的分隔符，词边界需依赖语言学规则或统计模型进行推断，分词难度显著更高。\n\n中文分词我们采用的工具是 jieba，它是一个基于前缀词典实现的高效中文分词工具，支持四种分词模式：\n\n精确模式  \n目标是将句子最精确地切分，尽可能避免歧义。\n\n\n全模式  \n扫描句子中所有可能成词的词语组合，穷举所有匹配项。  \n速度快，但无法解决歧义问题，可能产生大量冗余或不合理切分。\n\n\n搜索引擎模式  \n在精确模式的基础上，对较长的词语进一步细粒度切分，以提升召回率。  \n专为搜索引擎设计，兼顾准确性和覆盖度，便于后续关键词匹配与索引。\n\n\nPaddle 模式  \n基于 PaddlePaddle 深度学习框架，利用大规模语料训练，分词准确率更高。\n\n\n\n","categories":["UCAS-nlp"],"tags":["自然语言处理","爬虫","分词"]},{"title":"CS143总结","url":"/2025/10/01/CS143%E6%80%BB%E7%BB%93/","content":"CS143 是斯坦福大学经典的编译原理课程，系统性地讲解了从源代码到可执行程序的完整编译流程。课程以编译器的构建为主线，围绕五个核心阶段展开：词法分析、语法分析、语义分析、代码生成与优化，并通过实现一个完整的 COOL 编译器作为贯穿始终的实践项目。\n通过视频讲解以及分阶段、循序渐进的编程作业，我们能够一步步理解现代编译器的内部机制。即使没有编译器背景，只要认真理解课程内容和参考资料，也能在项目实践中逐步掌握 AST、CFG、MIPS 汇编等比较核心的概念和技术。这篇 blog 作为我学习 CS143 的总结，整理了我个人的笔记和比较好用的一些参考资料，如果有有缘人看到可供参考~\n课程资源课程主页：https://web.stanford.edu/class/cs143/课程视频：https://www.bilibili.com/video/BV1Mb42177J7/?vd_source=1a299e3348e61897568d41d158a28571csdiy：https://csdiy.wiki/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/CS143/\n参考博客编译原理的参考博客少得可怜，而且基本上只有前面几个实验有比较详细的博客……PA4，PA5 我的可能写的比他们都详细，不过确实不容易……PA1：anarionPA2：anarionPA3：一粟PA4,5：看我的吧\nPA 指引\nPA1 - Cool Language｜Cool 语言目标简述：实现 Cool 语言的一个栈机器，熟悉 Cool 语言的基本语法和结构。事实上可以不做，根据我的经验对后面没什么影响。博客链接：CS143-PA1：Cool-Language\n\nPA2 - Lexical Analysis｜词法分析目标简述：实现 Cool 语言的词法分析器，理解词法分析的基本过程。博客链接：CS143-PA2：Lexical Analysis\n\nPA3 - Syntax Analysis｜语法分析目标简述：实现 Cool 语言的语法分析器，将词法单元转换为抽象语法树。博客链接：CS143-PA3：Syntax Analysis\n\nPA4 - Semantic Analysis｜语义分析目标简述：实现 Cool 语言的语义分析器，构建继承树，进行类型检查，添加类型注释。博客链接：CS143-PA4：Semantic Analysis\n\nPA5 - Code Generation｜代码生成与优化目标简述：实现 Cool 语言的代码生成器，将抽象语法树转换为 MIPS 汇编代码。博客链接：CS143-PA5：Code Generation\n\n\n知识点总结\nWeek0 - 实验环境配置内容简述：配置各种环境，资源还蛮难找的。博客链接：CS143-Week0：实验环境配置\n\nWeek1 - Introduction｜基本介绍内容简述：编译器的基本概念、编译过程的各个阶段、编译器的结构和组件。博客链接：CS143-Week1：Introduction\n\nWeek2 - Lexical Analysis Finite Automata｜词法分析与有限自动机内容简述：介绍了正则表达式、有限自动机（DFA 和 NFA）、词法分析器的实现。博客链接：CS143-Week2：Lexical Analysis and Finite Automata\n\nWeek3 - Parsing Top Down Parsing｜自顶向下分析内容简述：主要介绍了上下文无关文法以及自顶向下解析（尤其是递归下降解析）。博客链接：CS143-Week3：Parsing and Top Down Parsing\n\nWeek4 - Bottom Up Parsing｜自底向上分析内容简述：预测解析和自底向上解析的基本概念和实现方法。博客链接：CS143-Week4：Bottom Up Parsing\n\nWeek5 - Semantic Analysis and Type Checking｜语义分析与类型检查内容简述：语义分析的基本概念、类型系统的形式化定义和 Cool 语言的类型环境。博客链接：CS143-Week5：Semantic Analysis and Type Checking\n\nWeek6 - Cool Type Checking Runtime Organization｜Cool 类型检查与运行时组织内容简述：详细介绍了 Cool 语言的类型系统与类型检查方法。博客链接：CS143-Week6：Cool Type Checking and Runtime Organization\n\nWeek7 - Code Generation｜代码生成内容简述：介绍了 MIPS 架构、代码生成的基本概念，还阐述了各种情形的代码生成。博客链接：CS143-Week7：Code Generation\n\nWeek8 - Optimization｜优化内容简述：介绍了基本的编译器优化，包括中间表示、局部优化、窥孔优化和全局优化等内容，但没有深入探讨具体实现。博客链接：CS143-Week8：Optimization\n\n\n总结从 2025/7/26 到 2025/10/1，同样是大概经过了两个月，一边学习一边写博客，还把驾照考了，现在终于把 CS143 这门课学完了。编译原理作为计算机科学的核心领域之一，涵盖了从源代码到可执行程序的完整转换过程。不得不说，相对于 6.s081，CS143 的资源更加匮乏，我想是因为编译原理本身比较深入和困难，能坚持下来的人本来就不多，所以相关的博客和资料也就更少了。不管怎么说，能坚持下来并完成所有实验，还是挺有成就感的。\n封面来自于东放官方的X，好吧我确实不知道画师是谁）\n","categories":["CS143"],"tags":["Linux","编译原理","CS143"]},{"title":"计网学习笔记-1","url":"/2025/10/13/%E8%AE%A1%E7%BD%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","content":"因特网基本概念因特网是一个互联了全世界数十亿计算设备的网络，这些设备包括个人计算机、平板电脑、智能手机、服务器等，他们被称作主机（host）或端系统（end system）。\n主机通过通信链路（communication link）和分组交换机（packet switch）互联。通信链路由不同类型的物理介质（如光纤、铜缆或无线信道）构成，各类链路的数据传输速率各不相同，单位是比特/秒（bps）。当一台主机向另一台主机发送数据时，发送主机会将数据分段并加上首字节，形成一个个分组。分组交换机主要有两种：路由器（router）和链路层交换机（link-layer switch），路由器连接不同的网络，而交换机连接同一网络内的设备。\n主机通过因特网服务提供商（Internet Service Provider, ISP）连接到因特网。每个 ISP 自身就是一个由多台分组交换机和多段通信链路构成的网络，他们为主机提供了各种不同类型的网络接入。ISP 有不同的层级：接入 ISP（如家庭宽带提供商）、区域 ISP（连接多个接入 ISP）和主干 ISP（连接多个区域 ISP）。但无论层级如何，所有 ISP 都是独立管理的，运行着 IP 协议，遵从一定的命名和地址规则。\n主机、分组交换机和其他因特网部件都要运行一系列的协议，这些协议定义了设备间通信的规则。TCP（Transmission Control Protocol, 传输控制协议）和 IP（Internet Protocol, 网际协议）是因特网的核心协议，IP 定义在路由器和主机之间发送和接收的分组格式，而 TCP 则为应用程序提供可靠的端到端通信服务。因特网的主要协议统称为 TCP/IP。\n网络边缘如前所述，我们把与因特网相连的计算机和其他设备称作端系统，因为他们位于因特网的边缘。端系统也称主机，因为他们容纳（运行）应用程序。主机有时候被进一步分为两类：客户和服务器。客户通常是桌面 PC、移动 PC 和智能手机等，而服务器通常更加强大，运行着 Web 服务器、文件服务器、电子邮件服务器等。\n接入网接入网是指将终端主机物理连接到其边缘路由器的网络，常见的接入网类型包括：\n\n数字用户线（DSL, Digital Subscriber Line）：利用现有电话线提供高速互联网接入，由本地电话公司作为 ISP。DSL 通过频分复用技术，在同一对电话线上同时传输语音（低频）和数据（高频）。其典型特征是下行速率高于上行速率。\n电缆调制解调器（Cable Modem）：基于有线电视同轴电缆网络提供互联网接入。调制解调器将数字信号调制为适合电缆传输的射频信号。与 DSL 类似，下行带宽通常远大于上行带宽，且带宽在用户间共享。\n光纤到户（FTTH, Fiber to the Home）：通过光纤直接连接用户家庭，可以提供极高的上下行速率，延迟低、稳定性好，但初期部署成本较高。\n无线接入：无线接入主要包括局域范围的 Wi-Fi 和广域覆盖的蜂窝网络（如 4G、5G、LTE）。无线接入具有部署灵活、移动性强的优点，但其速率、延迟和可靠性易受距离、障碍物和干扰等因素影响。\n\n物理媒体物理媒体是指用于传输信号的物理介质，分为导引型媒体和非导引型媒体两大类，导引型媒体包括双绞铜线、同轴电缆和光纤，非导引型媒体主要是无线信道（包括陆地无线电和卫星无线电）。\n网络核心分组交换在各类网络应用中，主机之间需要相互交换报文，报文其实是一种特殊的位于应用层的信息分组。在多种通信方式中，分组交换是实现报文传输的主要方式之一。报文既可以携带数据，也可以用于执行控制功能。当发送主机传输报文时，会将其划分为若干较小的数据单元，称为分组。每个分组通过通信链路和分组交换机，从源主机逐跳转发至目的主机。因此，若一个长度为 $L$ 比特的分组在速率为 $R$ 比特/秒（bps）的链路上传输，则其发送时延为 $\\frac{L}{R}$ 秒。\n储存转发多数分组交换机采用储存转发机制，即在转发分组之前，交换机必须先将整个分组接收完毕并存储在缓冲区中。\n这种方式可确保分组完整性并支持差错检测，但会引入额外的处理时延——每个分组至少需经历一次完整的接收过程后才能被转发。\n排队时延和分组丢失当分组到达交换机时，若输出链路正被其他分组占用，该分组便需在缓冲区中排队等待。\n排队时延取决于当前队列长度、分组到达速率及链路处理能力，具有高度动态性，可能在毫秒到秒级之间波动，是网络时延中最不可预测的部分。\n若分组到达速率持续超过链路处理能力，缓冲区可能会溢出，导致新到达的分组被丢弃，这种现象称为分组丢失。分组丢失会引发重传机制，进而影响整体网络性能。\n转发表和路由选择协议路由器会通过转发表决定如何转发每个到达的分组。转发表通常基于分组的目的地的 IP 地址，指示分组应通过哪个输出链路转发。转发表依赖于路由选择协议来自动设置和维护，这些协议允许路由器动态地交换信息，更新其转发表以反映网络拓扑的变化。\n电路交换电路交换是与分组交换相对应的另一种通信方式。它通过在通信双方之间建立一条专用的通信路径来实现数据传输。所有通信所需的资源（如缓存、带宽）都会在连接建立时被预留，该路径在整个通信过程中保持不变。这种方式适用于需要持续、稳定连接的应用，如传统电话通信。然而，由于资源在连接期间被独占，电路交换在资源利用率和灵活性方面不如分组交换。\n链路中的电路是通过频分复用（FDM）或时分复用（TDM）技术实现的。FDM 将链路的频谱划分为多个频段，每个频段用于不同的通信会话，该频段的宽度被称作带宽；TDM 则将时间划分为固定时长的帧，每个帧又被划分为固定数量的时隙，网络会在每个帧中为连接指定一个时隙。\n\n  \n  FDM 和 TDM\n\n\n对比来看，电路交换在通信前需建立专用的物理连接，通信期间独占链路资源，因此传输时延稳定，适合实时业务（如传统电话通信），但其资源利用率低、连接建立耗时且灵活性较差。相较之下，分组交换将数据拆分为分组，动态共享网络资源，无需预先建立连接，因而具有更高的资源利用率、更好的突发流量适应性和更强的扩展性。然而，分组交换存在排队时延和时延抖动，不适用于对时延敏感的实时应用。尽管如此，分组交换在总体性能上明显优于电路交换，也成为当今网络通信的主流发展方向。\n网络的网络当今的互联网是一个由众多网络互联而成的“网络的网络”，其结构庞大且层次分明。除最底层外，各级 ISP（互联网服务提供商）通常都设有存在点（PoP）作为接入节点，并可与不同层次的网络建立连接。任何 ISP 都可以选择多宿（multihoming），即同时连接两个或多个上级 ISP 以提高可靠性和冗余性。处于相同层级的 ISP 之间还可以建立对等连接，直接交换彼此的流量。基于此机制形成了互联网交换点（IXP），作为多个 ISP 的汇聚节点，使其能够高效地实现对等互联。除网络运营商外，互联网还包括内容提供商（CDN）和数据中心（Data Center），它们通过部署服务器和缓存节点，为用户提供高效的数据访问与内容分发服务。\n大致的网络结构图如下：\n\n  \n  网络结构图\n\n\n时延、丢包、吞吐量时延概述一个路由器的节点时延大致包含四部分：处理时延、排队时延、传输时延、传播时延。首先，路由器需要检查一个分组的首部并且据此决定将该分组导向何处，这导致了处理时延；其次，分组在链路上等待传输时，会有排队时延；再然后，将分组的每个比特推向链路也需要耗时，因此有微小的传输时延；最后，每个比特传到另一个路由器毫无疑问需要耗时，从而还要考虑传播时延。\n排队时延和丢包之所以我们反复强调排队时延，是因为它是节点时延中最为复杂的一部分。我们不难注意到排队时延与分组有关，因此我们往往会采用统计量来度量它。一个很重要的指标是流量强度，通常用符号 $\\rho$ 表示，被用来衡量网络中业务负载程度。其定义公式为：\n\n\\rho = \\frac{L \\cdot a}{R}其中 $L$ 为平均分组长度，$a$ 是平均分组到达率（分组/秒），$R$ 则是链路传输速率（bit/秒）。$\\rho$ 表示链路在平均意义下被占用的比例，即平均到达速率与服务速率的比值。当 $\\rho &lt; 1$ 时，系统能稳定运行；当 $\\rho \\ge 1$ 时，链路将趋于过载，队列长度会不断增长。因此实际设计系统时一定会保证流量强度不大于1。\n下面来考虑流量强度不大于1的情况，此时到达流量的性质将决定排队时延。比如如果分组按 $\\frac{L}{R}$ 的速度周期性到达，那么就不会有排队时延；但如果所有分组同一时刻到来，那么排队时延毫无疑问将会非常大。\n通常来说，分组到达队列的过程是随机的。此时无法定量计算，但毋庸置疑的一点是，随着流量强度接近1，平均排队长度会越来越长，平均排队时延也会迅速增加。在实际情况中，因为队列是有限的，所以时延会有上限，但会出现丢包的问题。\n吞吐量吞吐量用于衡量数据在网络中传输的速率，是评估网络性能的重要指标。瞬时吞吐量表示主机在某一时刻接收数据的速率，而平均吞吐量则是指在较长时间内的平均接收速率。吞吐量受到多种因素影响，包括链路带宽、网络拥塞程度、协议开销以及端到端路径中的瓶颈带宽等。在端到端通信中，实际吞吐量通常受限于路径中最小带宽的链路，因此常用“瓶颈链路”来描述整个传输速率的上限。\n协议层次因特网协议栈因特网的协议栈由五个层次组成：物理层、链路层、网络层、运输层、应用层。这本书就是自顶向下进行讲解的，从应用层开始，一步步向下处理。\n\n应用层应用层是用户直接交互的层面，运行各种网络应用程序及其协议（如 HTTP 用于 Web 访问、SMTP 用于电子邮件、FTP 用于文件传输、DNS 用于域名解析）。这些协议定义了端系统之间交换应用层报文的格式与规则，所有通信最终都源于或服务于应用层需求。\n\n运输层运输层为运行在不同主机上的应用进程提供端到端通信服务。因特网提供两种主要协议：TCP（传输控制协议）提供可靠的、面向连接的服务，包括顺序交付、流量控制和拥塞控制；UDP（用户数据报协议）则提供轻量级、无连接、不可靠但低开销的传输。运输层将应用层报文封装成报文段，并添加端口号等信息，以实现多应用复用与分发。\n\n网络层网络层负责将数据报从源主机跨越多个网络传送到目的主机，核心协议是IP（网际协议），它定义了统一的地址格式和数据报结构，使异构网络能够互联。网络层依赖各种路由选择协议（如 OSPF、BGP）动态计算路径，是实现“网络的网络”——即因特网——互联互通的关键。\n\n链路层链路层在相邻网络节点（如主机与路由器、路由器之间）之间可靠或尽力而为地传输数据。它将网络层数据报封装成帧，并根据底层技术（如以太网、Wi-Fi、DOCSIS）添加链路首部（和尾部），处理物理地址（如 MAC 地址）、差错检测甚至重传。值得注意的是，一个端到端的数据报在穿越网络时，可能被不同链路上的不同链路层协议依次封装与解封装。\n\n物理层物理层负责在实际传输介质（如双绞线、同轴电缆、光纤或无线电波）上逐比特地传送帧的内容。它定义了信号的电气、时序、速率和物理接口等特性。虽然对上层透明，但物理层的性能（如带宽、误码率）直接影响整个网络的效率与可靠性。\n\n\n封装如图所示，路由器实现了协议栈的下三层（物理层、链路层和网络层），因此能够处理并转发 IP 数据报，是 IP 协议的核心执行者；而链路层交换机仅实现最底层的两层（物理层和链路层），负责在局域网内基于 MAC 地址转发帧，不参与 IP 路由，因而不实现 IP 协议。相比之下，主机（如个人电脑、服务器）完整实现了全部五层协议，既能生成和解析应用层报文，也能处理端到端传输、IP 寻址、链路帧封装及物理信号收发。这种设计体现了“智能在边缘、简单在网络核心”的因特网架构原则——复杂的功能（如应用逻辑、可靠传输）由终端主机承担，而网络内部设备（如路由器、交换机）则专注于高效转发，从而提升整体可扩展性与灵活性。\n\n  \n  物理路径\n\n\n这张图也清晰地展示了网络通信中的核心机制——封装。在发送端，应用层生成的报文（M）首先被传递给运输层，运输层为其添加首部（$H_t$），形成报文段，其中包含端口号、差错检测等信息，用于在接收端正确交付给目标应用。该报文段作为有效载荷被交给网络层，网络层加上包含源和目的 IP 地址的网络层首部（$H_n$），封装成数据报。随后，链路层再添加自己的首部（可能还有尾部，如帧校验序列），构成帧，以便在物理链路上传输。每一层都将上层的整个分组作为本层的有效载荷，并附加上本层所需的控制信息（首部），从而实现逐层封装。接收端则执行相反的解封装过程，逐层剥离首部，最终将原始应用层报文交付给目标应用程序。\n","categories":["计网"],"tags":["计算机网络","因特网"]},{"title":"UCAS-nlp-Week3：词向量","url":"/2025/10/14/UCAS-nlp-Week3%EF%BC%9A%E8%AF%8D%E5%90%91%E9%87%8F/","content":"词向量文本表示文本由文字和标点构成，是一种字符串形式的信息载体。它可以按不同粒度划分为词、短语、句子、段落乃至篇章。要让计算机“理解”文本，首先必须将其转化为一种形式化的数值表示，以便反映内容特征并区分不同文本。最简单的方式是 One-hot（独热）表示。\n\nOne-hot 表示 是一种基础的文本向量化方法：为每个词（或字符）分配一个唯一的索引，并构建一个与词汇表等长的向量——在该词对应的索引位置取值为 1，其余位置为 0。\n\n不难看出， One-hot 表示存在以下两个主要问题：\n\n维度灾难随着词汇表规模增大，向量维度会急剧上升，带来存储与计算的高开销。同时，这种表示极度稀疏（大部分元素为 0），计算效率低下。\n语义鸿沟One-hot 向量无法体现词与词之间的语义关系。任意两个不同词的向量都是正交的（欧氏距离恒为 √2），即使语义相近（如“猫”和“狗”），模型也无法感知它们的相似性。\n\n相比于稀疏的 One-hot 表示，更加有效的做法是使用低维实值向量表示。  \n这种方法将每个单词表示为一个 D 维的稠密向量（其中 D 远小于词汇表的大小）。向量中的每个维度不再只是占位符，而是用于刻画该词的某种语义或语法特征。通过学习得到的这些向量可以使语义相近的词在向量空间中彼此靠近，从而在一定程度上捕捉词语间的语义关联。\n实现这种表示的常用模型之一是 连续词袋模型（Continuous Bag-of-Words, CBOW）。\nCBOWCBOW 是一种典型的词向量学习方法。该模型忽略词序，只关注上下文中出现的词，通过利用上下文词语来预测目标（中心）词，从而在训练过程中逐渐学习出词语之间的语义关系。其整个训练过程可以概括为以下几个步骤：\n\n初始化词向量矩阵 L\n 词汇表可以根据语料确定，可选取出现频率最高的 N 个单词，或频数超过某一阈值 K 的单词作为收录对象。词向量维度 D 是一个超参数，由实验者自行设定，通常远小于词汇表的规模。词向量矩阵 L 的形状如下：\n\n L \\in \\mathbb{R}^{|V| \\times D} 其中 $|V|$ 表示词汇表大小，每一行对应一个词的 D 维向量。\n\n计算上下文向量的均值向量 h\n 对于一个目标中心词 $w_i$，设它的上下文窗口大小为 C（即左边 C 个词和右边 C 个词），记上下文词为 \nw_{i-C}, \\dots, w_{i-1}, w_{i+1}, \\dots, w_{i+C} CBOW 模型将这些上下文词的向量取平均，得到上下文的语义表示向量 $h$：\n\n h = \\frac{1}{2C} \\sum_{k=i-C, k \\ne i}^{i+C} e_{w_k} 其中 $e_{w_k}$ 表示词 $w_k$ 的词向量。\n\n使用 Softmax 函数计算中心词的概率\n CBOW 使用 Softmax 层来计算在给定上下文向量 $h$ 的情况下，每个词作为中心词的概率。对于目标词 $w_i$：\n\n P(w_i|WC) = \\frac{\\exp(h \\cdot e_{w_i})}{\\sum_{k=1}^{|V|} \\exp(h \\cdot e_{w_k})} 其中分子表示目标词与上下文的相似度，分母为对整个词表的归一化， $WC$ 是上下文窗口内的所有词。\n\n最大化目标函数\n 模型通过最大化整个语料中所有目标词的条件概率来训练：\n\n L = \\sum_{w_i \\in D} \\log P(w_i | WC) 训练完成后，词向量矩阵中的每一行即为学习得到的词向量，它能在语义空间中反映词语间的相似关系。\n\n\n关键技术批处理一种常用的技术是批处理，我们将整个训练数据集划分为多个较小的数据子集，以便于模型的训练和优化。每个批次的数据可以独立处理，从而提高计算效率和模型收敛速度。\n模型会使用每个批次的数据来计算梯度，并更新模型参数。通过这种方式，模型能够更快地学习到数据中的模式和特征。\n负采样当词汇表非常大时，计算 Softmax 函数的分母会变得非常复杂，因为它需要对整个词汇表进行归一化。为了解决这个问题，我们可以使用负采样技术。负采样通过只更新一小部分负样本来简化计算，从而提高训练效率。具体来说，对于每个正样本（即目标词），我们随机选择一些负样本（即非目标词）进行训练。这样，模型只需要计算这些样本的概率，而不是整个词汇表的概率，从而大大减少了计算量。\n负样本通常是从词汇表中随机选择的，我们毫无疑问的可能会选择到正样本。无论是忽略这些样本还是重新采样，都是可以的，大概结果差别不大吧。\n","categories":["UCAS-nlp"],"tags":["自然语言处理","词向量"]},{"title":"计网学习笔记-2","url":"/2025/10/19/%E8%AE%A1%E7%BD%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/","content":"应用层应用层协议如前所述，应用软件的运行被限制在主机中，因此，我们只需专注于开发能够在不同端系统上运行并通过网络实现相互通信的程序，而无需关心网络核心设备的实现细节或兼容性问题。\n应用程序体系结构对于一个应用程序而言，网络的体系结构是固定的，它只是为应用提供了特定的服务集合，或者说接口。但应用程序自身的体系结构则是由研发者自己设计的，规定了如何在各个主机上组织该应用程序。现代网络应用程序有两种主流体系结构：客户——服务器体系结构、对等（P2P）体系结构。\n在客户——服务器体系结构中，有一台始终处于开启状态的主机被称作服务器，它为许多其他被称作客户的主机提供服务。在这个体系结构中，客户相互之间并不通信，而服务器具有固定的 IP 地址，且始终保持打开，因此客户总是能够通过向该服务器的 IP 地址发送分组来与其建立联系。典型的基于该架构的应用包括 Web 浏览和电子邮件等。\n而在 P2P 体系结构中，应用程序几乎不依赖（甚至完全不依赖）专用服务器，而是由间歇性连接的主机之间直接通信，这些主机被称为对等方。典型的 P2P 应用包括 BitTorrent（文件共享）、Bitcoin（去中心化数字货币）和 Skype（早期的语音通话），它们都依靠对等节点直接通信，无需依赖中心服务器。P2P 的最大优势之一在于其自扩展性，尽管每个对等方都由于请求文件产生负载，但他们本身向其它对等方分发文件也为系统增加了服务能力。然而，由于高度非集中式结构，P2P 结构也会面临安全性、性能等挑战。\n进程通信我们知道，进行通信的实际上是各个主机上的进程，他们通过交换报文来相互通信。为了方便叙述，我们称发起通信的进程为客户，等待联系的进程为服务器。\n进程通过被称作套接字的软件接口向网络发送和接收报文。套接字位于同一台主机内应用层与运输层之间，本质上是应用程序与网络之间的 API。应用程序对其在应用层一侧的套接字拥有完全控制权，但在运输层一侧的控制非常有限：通常只能选择运输层协议（如 TCP 或 UDP），并设置少数参数（如最大缓存大小、最大报文段长度等）。一旦选定协议，应用程序便运行在该协议所提供的运输层服务之上，无法再干预其内部机制（如拥塞控制或重传策略）。大致流程如图：\n\n  \n  套接字\n\n\n为了向服务器发送分组，我们需要服务器的地址和指定接收进程的标识符。在因特网中，主机由其 IP 地址唯一标识，而接收进程则通过目的端口号来指定。端口号的相关内容将在第 3 章介绍，IP 协议的细节则在第 4 章展开。\n运输服务我们会从四个方面来评估运输层协议能够提供的服务：可靠数据传输、吞吐量、定时和安全性。\n\n可靠数据传输指的是协议能够确保发送方发出的数据被接收方正确、完整且按序地交付，即使底层网络可能丢包、损坏或乱序。例如，TCP 通过确认、重传和校验机制实现可靠性，而 UDP 不提供此类保障。\n吞吐量指协议能为应用提供的可用带宽或数据传输速率。某些协议或网络环境可提供高吞吐量（如视频流所需的稳定带宽），而另一些则仅提供“尽力而为”的服务，实际吞吐量受网络拥塞等因素影响。具有吞吐量要求的应用被称作“带宽敏感的应用”，而没有要求的一般被称作弹性应用。\n定时涉及数据交付的延迟特性，如端到端时延、抖动或是否满足实时性要求。这对交互式应用（如语音通话、在线游戏）至关重要，但标准 TCP/UDP 本身不保证定时性能，需结合其他机制（如 QoS 或应用层优化）。\n安全性包括数据的机密性、完整性和端点认证。基础的运输层协议（如 TCP/UDP）不内置加密或认证，但可通过扩展（如 TLS/SSL）或使用安全协议（如 DTLS、QUIC 内置加密）来提供保护。\n\n这四个维度共同决定了运输层协议是否适合特定应用的需求。在因特网中，主要提供两种运输层协议：TCP 和 UDP。\nTCP 协议提供面向连接的服务和可靠数据传输服务。所谓面向连接，是指在应用层数据开始传输之前，TCP 要求客户和服务器先通过交换运输层控制信息完成三次握手，从而建立一条 TCP 连接；连接建立后，双方进程即可同时收发数据。通信结束后，还需通过四次挥手显式地拆除连接。而“可靠”如前所述，意味着 TCP 能确保所有数据被正确、完整且按序地交付给接收方。\n需要说明的是，TCP 本身不提供安全性。为了实现加密、身份认证和数据完整性保护，通常会在 TCP 之上叠加 SSL/TLS（安全套接层/传输层安全）协议。SSL/TLS 并非独立的运输层协议，而是位于应用层与 TCP 之间的一层安全增强机制——应用数据先由 SSL/TLS 加密封装，再交由 TCP 传输。因此，像 HTTPS、安全邮件等，本质上是“应用层 + SSL/TLS + TCP”的组合，既保留了 TCP 的可靠性，又获得了端到端的安全保障。\nUDP 协议则是一种轻量级、无连接的运输层协议，仅提供最小限度的传输服务。它在发送数据前无需建立连接，也不保证数据的可靠交付——既不重传丢失的报文，也不确保顺序或完整性。此外，UDP 没有流量控制和拥塞控制机制，发送方可以以任意速率发送数据，即使网络已拥塞。这种“尽力而为”的设计使其开销极低、延迟小，适用于对实时性要求高、能容忍少量丢包的应用，如视频会议、在线游戏和 DNS 查询。\n应用层协议终于，我们来谈到这一节的标题了。应用层协议定义了运行在不同端系统上的应用程序进程之间如何交换报文。具体而言，它规定了以下内容：  \n\n报文类型，例如请求报文与响应报文；  \n报文的语法，即报文的结构、包含哪些字段以及各字段的格式；  \n字段的语义，也就是每个字段所表达的具体含义；  \n通信规则，包括一个进程在何种条件下发送报文，以及如何对收到的报文进行响应。  \n\n有些应用层协议是由 RFC 文档定义的，属于公开标准，任何人都可以自由实现和使用；而另一些则是专有协议，由特定公司或组织私有控制，通常不公开细节或限制使用。需要注意的是，应用层协议本质上是应用程序的一部分，而非整个应用程序本身。\nWeb 和 HTTPHTTP 概况Web 的应用层协议是超文本传输协议（HyperText Transfer Protocol, HTTP），它是客户——服务器架构的。Web 页面由多个对象组成，每个对象是一个可通过 URL（统一资源定位符）寻址的文件。大多数 Web 页面包含一个 HTML 基础文件以及若干被引用的对象（如图片、样式表、脚本等），HTML 文件通过这些对象的 URL 在页面中引用它们。Web 服务器实现了 HTTP 协议的服务器端，负责存储这些 Web 对象，并响应客户端的请求。\nHTTP 定义了 Web 客户端向服务器请求 Web 页面的方式，以及服务器向客户端传送页面的规则。当用户请求一个页面时，浏览器（作为 HTTP 客户端）会向目标服务器发送一个 HTTP 请求报文，指定所需资源的 URL；服务器随后处理该请求，并返回相应的 HTTP 响应报文，其中包含所请求的 Web 对象（如 HTML 文件或其他资源）。\nHTTP 采用 TCP 作为运输协议，客户端与服务器在传输数据前先建立 TCP 连接，之后就可以通过套接字接口访问 TCP。\n事实上，HTTP 是一个无状态协议，因为它不会保存关于客户的任何信息。正因如此，即使客户短时间内多次请求同一个对象，服务器也总会做出相同的反应。\n持续/非持续连接在许多因特网应用程序中，客户和服务器需要在较长时间内进行多次交互，客户会发送一系列请求，服务器也需要对每个请求作出响应。这种交互是通过 TCP 进行的，因此，是所有请求——响应对共同使用一个 TCP 还是每个请求——响应对使用单独的 TCP 会是相当重要的一个设计选择。我们将前一种称之为持续连接，后一种则称作非持续连接。HTTP 默认采用持续连接以提升效率，但也可配置为非持续连接。\n为了对比两者的时间差异，我们需要引入往返时间（Round-Trip Time, RTT）。RTT 是指一个小数据包从发送方发出，到达接收方后立即返回确认，再回到发送方所经历的总时间。它反映了网络链路的延迟特性，包含了传播时延、排队时延、处理时延等，但通常不包括数据传输时延（因为使用的是小探测包）。\n在非持续连接模式下，每次请求一个 Web 对象都需要经历完整的 TCP 三次握手和一次 HTTP 请求——响应交互。具体过程如下：\n\nTCP 三次握手：客户端发送 SYN（第 1 步），服务器回复 SYN-ACK（第 2 步），客户端再发送 ACK（第 3 步）。前两步构成 1 个 RTT，第 3 步的 ACK 通常与后续的 HTTP 请求合并发送，因此握手阶段至少消耗 1 个 RTT。\nHTTP 请求与响应：客户端发送 HTTP 请求，服务器返回响应对象，这一来一回再消耗1个 RTT以及传输 HTML 文件的时间。\n\n因此，获取一个 Web 对象在非持续连接下总共需要约 2 个 RTT + 传输 HTML 文件的时间。相比之下，在持续连接下，TCP 连接在多个请求之间复用，理论上可以节省“对象数 - 1”个 RTT 的时间。\n此外，非持续连接需要为每个请求单独建立和维护一个 TCP 连接，而每个连接都需分配独立的 TCP 缓冲区并维护相应的状态变量，这无疑会给客户端和服务器带来显著的资源开销和管理负担，也是非持续连接明显的缺陷之一。\nHTTP 报文格式HTTP 报文分为请求报文和响应报文。\n\n请求报文下图是一个典型的 HTTP 请求报文：\n\n \n\n\n我们可以看到，报文是用 ASCII 文本书写的，每行以回车换行符结束。HTTP 报文的第一行是请求行，其后继的行叫首部行。请求行有三个字段：方法字段、URL 字段、HTTP 版本字段。方法字段可以取几种不同的值，包括 GET, POST, HEAD, PUT 和 DELETE，绝大部分使用 GET 方法。\n首部行中的 Host: www.someschool.edu 指明了所请求对象所在的主机。尽管客户端已经与该主机建立了 TCP 连接，这一行仍是必要的。实际上，Host 首部是 HTTP/1.1 的强制要求，我们将在之后说明这一点。\n通过包含 Connection: close 首部，浏览器明确告知服务器：不要使用持续连接，在发送完所请求的对象后立即关闭该 TCP 连接。\nUser-Agent 首部用于标识发起请求的客户端类型，例子中的 Mozilla/5.0 通常表示 Firefox 浏览器。服务器可利用这一信息，为不同用户代理提供同一资源的适配版本（尽管这些版本共享相同的 URL）。\n最后，Accept-Language: fr 表示用户偏好法语版本的内容（如果服务器支持）；否则，服务器将返回默认语言版本。这类首部属于 HTTP 的内容协商机制，Accept-Language 仅是其中一种，其他还包括 Accept、Accept-Encoding 等，用于实现更智能、个性化的资源交付。\n然后我们来看请求报文的通用格式：\n\n \n 通用格式\n\n\n多出的一个部分是实体体，它位于一个空行后面，使用 GET 方法时该实体体为空，当使用 POST 方法时才被使用。当用户提交表单时，HTTP 客户常使用 POST 方法，如使用搜索引擎时。此时 Web 页面内容依赖于表单内容，因此实体体包含的就是表单的输入值。\n当然，用表单生成的请求报文并不一定使用 POST 方法，也常常使用 GET 方法。当 HTML 表单的 method 属性设为 GET（或未指定，默认为 GET）时，浏览器会将表单字段及其值编码为查询字符串，并附加在请求 URL 的 ? 之后，然后通过 HTTP GET 请求发送给服务器。例如，一个包含用户名和密码的登录表单若使用 GET，可能会生成如下 URL：\nhttps://example.com/login?username=alice&amp;password=secret\n这种方式简单直观，适用于无副作用的查询操作（如搜索、筛选），但不适合传输敏感信息（因参数会暴露在 URL 中，可能被日志、浏览器历史记录泄露）或大量数据（受 URL 长度限制）。相比之下，POST 方法将表单数据放在 HTTP 报文的请求体（body）中，更安全、容量更大，常用于提交、上传等操作。因此，选择 GET 还是 POST，不仅影响报文结构，也关乎安全性与语义正确性。\nHEAD 方法与 GET 类似，但服务器在响应中只返回首部，常被用于调试跟踪。PUT 用于向指定的 URL 上传或替换资源。DELETE 方法允许用户或程序删除 Web 服务器上的对象。\n\n响应报文下图是一个典型的 HTTP 响应报文：\n\n \n\n\n了解过请求报文，响应报文的结构也明显了许多。这个报文包含三部分：状态行、首部行、实体体。这里的实体体是报文的主要部分，包含了所请求的对象本身。状态行有三个字段协议版本字段、状态码和相应状态信息。这个例子中，状态行说明了服务器正在使用 HTTP/1.1，并且服务器成功找到了并正在发送所请求的对象。\n首部行中的 Connection: close 表示服务器在发送完该响应后将关闭当前 TCP 连接，不再复用该连接处理后续请求。\nDate 首部指示的是服务器生成并发送该响应报文的日期和时间，而非对象本身的创建或最后修改时间——它记录的是服务器从文件系统检索对象、封装进响应并发出的确切时刻。\nServer 首部用于标识生成响应的服务器软件类型（如 Apache/2.4.1），其作用类似于请求中的 User-Agent 首部，帮助客户端了解服务器环境。\nLast-Modified 首部给出了对象在服务器上最后被创建或修改的时间，这对缓存机制至关重要：无论是浏览器本地缓存还是网络中的代理缓存，都依赖该字段判断缓存副本是否仍然有效。\nContent-Length 指明了响应实体体（即实际对象内容）的字节长度，使客户端能准确识别报文边界并高效处理数据。\nContent-Type 则声明了实体体中数据的 MIME 类型（如 text/html）。对象的类型应由该首部字段正式指定，而非依赖文件扩展名，这是 Web 内容正确解析的基础。\n然后我们来看响应报文的通用格式：\n\n \n 通用格式\n\n\n我们补充说明一下状态码和对应的短语：\n\n200 OK：请求成功，所请求的对象包含在响应报文中。  \n301 Moved Permanently：请求的对象已被永久移至新位置，新的 URL 会在响应的 Location 首部中给出；客户端通常会自动跳转到该新地址。  \n400 Bad Request：通用的客户端错误，表示服务器无法理解该请求（如语法错误）。  \n404 Not Found：服务器找不到所请求的资源（例如文件或页面不存在）。  \n502 Bad Gateway：作为网关或代理的服务器从上游服务器收到无效响应。\n505 HTTP Version Not Supported：服务器不支持请求中使用的 HTTP 协议版本。\n\n\n\nHTTP 扩展机制cookie我们知道 HTTP 服务器是无状态的，但一个 Web 站点通常希望能识别客户。为此，HTTP 使用 cookie，它允许站点对用户进行跟踪。cookie 技术包含四个组件：\n\nHTTP 响应报文的一个 cookie 首部行\nHTTP 请求报文的一个 cookie 首部行\n用户主机保留有一个 cookie 文件，并由用户的浏览器进行管理\nWeb 站点有一个后端数据库\n\n具体流程可以参考下图，画的还是蛮明显的：\n\n  \n  cookie 跟踪流程\n\n\nWeb 缓存Web 缓存器（也称为代理服务器）位于客户端与源服务器之间，用于临时存储用户最近请求过的 Web 对象副本。它通常配备专用的磁盘存储空间，并可被配置为接收用户浏览器发出的所有 HTTP 请求——即浏览器将请求首先发送给缓存器，而非直接访问源服务器。\nWeb 缓存器通常由 ISP、企业或学校等机构部署，其部署主要有两个原因：\n首先，能够显著降低用户请求的响应时间。当用户与源服务器之间的链路带宽受限（即存在瓶颈），而用户与缓存器之间拥有高速连接（这在局域网或本地网络中很常见）时，若所请求的对象已在缓存中，缓存器便可立即返回该对象，无需等待远端服务器响应。\n其次，还可以大幅减少机构接入链路的互联网流量。通过在本地满足大量重复请求，缓存器有效降低了对外带宽消耗。这使得机构（如公司或大学）无需频繁升级网络带宽，从而节省成本。此外，大规模部署 Web 缓存还能从整体上减轻因特网的 Web 流量负载，提升全网应用的性能和可扩展性。\n条件 GET 方法尽管高速缓存能够显著减少用户的响应时间，但也引入了一个新的问题，就是缓存器中的对象副本可能已经过时。解决这个方法的一种机制是利用 HTTP 协议的条件 GET 方法，它允许缓存器证实它的对象是最新的。当请求报文使用 GET 方法并且包含一个If-Modified-Since:的首部行，它就是一个条件 GET 请求报文。\n具体操作如下：\n\n缓存器发起条件 GET 请求：当缓存器收到用户对某对象的请求，且该对象在缓存中存在但可能已过期时，缓存器不会直接返回旧副本，而是向源服务器发送一个 条件 GET 请求。该请求使用 GET 方法，并在首部中包含 If-Modified-Since 字段，其值为缓存中该对象的 Last-Modified 时间。\n示例：\nGET /index.html HTTP/1.1Host: www.example.comIf-Modified-Since: Mon, 10 Oct 2025 08:00:00 GMT\n\n服务器判断资源是否更新：源服务器收到该请求后，检查所请求对象的当前 Last-Modified 时间：\n\n如果未修改，服务器返回 304 Not Modified 响应，不携带实体体；\n如果已修改，则返回 200 OK，并在响应体中附上最新的完整对象。\n\n\n缓存器根据响应更新行为：\n\n若收到 304 Not Modified，缓存器知道原有副本仍然有效，可安全地将其返回给用户，并可更新缓存的过期时间；\n若收到 200 OK 和新内容，则用新对象替换缓存中的旧副本，再返回给用户。\n\n\n\n电子邮件因特网电子邮件系统包含三个部分：用户代理、邮件服务器和简单邮件传输协议（Simple Mail Transfer Protocol, SMTP）。用户代理是用户与邮件系统交互的界面，用于撰写、发送、阅读、回复和转发邮件。每位用户都在某个邮件服务器上拥有一个邮箱，用于存储发给该用户的邮件，由邮件服务器负责管理和维护。典型的流程是：发送方通过其用户代理撰写邮件，提交给发送方的邮件服务器；该服务器使用 SMTP 将邮件传送到接收方的邮件服务器；最后，接收方的邮件服务器将邮件存入收件人的邮箱中，等待用户通过其用户代理读取。如果发送方的服务器无法将邮件交付给接收方的服务器，它就会在报文队列中保持该报文并且以后再尝试发送，通常每半个小时尝试一次，如果一段时间后仍不成功，就删除该文件并用邮件通知发送方。\n具体流程可以参考下图：\n\n  \n  报文发送流程\n\n\nSMTP电子邮件系统主要使用的应用层协议是 SMTP，它使用 TCP 运输服务。同 HTTP 一样，SMTP 也包含客户端和服务器端两个部分。下面是一个典型的客户（C）和服务器（S）之间交换报文文本的例子：\n\n  \n  客户——服务器对话\n\n\n可以看到，在建立了 TCP 连接之后，服务器会主动发送 220 响应，表示服务已准备好。在交代基本信息后（服务器回复 250 表示请求的操作已完成），客户发送 DATA 表示将要发送邮件，服务器如果准备好接收邮件内容，就会回复 354，客户的邮件发送以 . 结束，然后服务器回复 250。最后，客户会发送 QUIT，服务器回应 221，表示 SMTP 会话结束，即将关闭 TCP 连接。整个流程相当清晰。\n对比 HTTP，可以发现，HTTP 主要是一个拉协议，客户端主动发起请求（“拉取”数据），服务器被动响应；而像 SMTP 这样的邮件传输协议则更接近推协议——发送方主动将数据“推送”给接收方服务器。也就是说，HTTP 是一个同步的、请求驱动的协议，SMTP 是一个异步的、消息推送式的协议。另外，受限于其设计年代，SMTP 要求邮件内容必须使用 7 位 ASCII 字符，无法直接传输二进制数据（如图片、音频等），必须依赖 MIME 等扩展机制进行编码；而 HTTP 从一开始就支持任意类型的数据，无此限制。最后，在处理包含文本和图像等多部分内容的文档时，HTTP 采用分离对象的方式：HTML 文件与图像、样式表等分别作为独立资源，通过多个请求获取；而 SMTP 将所有内容（包括附件）打包在单一邮件报文中，作为一个整体传输。\n邮件报文格式发送电子邮件时，邮件报文必须包含一个首部，其中包含描述邮件环境的元信息（如发件人、收件人、主题等），首部与报文体之间用一个空行分隔。首部中的每一行由关键字、冒号和对应的值组成（例如 From: alice@example.com），这与 HTTP 报文的首部格式类似。其中一些首部字段是必需的（如 From、To、Date），而另一些则是可选的（如 Subject、Reply-To等）。\n\n注意：SMTP 并不是根据邮件首部中的信息来进行对话的。它在传输过程中通过 MAIL FROM 和 RCPT TO 等命令交换控制信息，完成路由和投递决策。这些命令完全由用户代理决定并生成，邮件内容会被完整地作为数据传递过去。邮件首部中的信息主要是供用户代理显示和使用，SMTP 服务器在传输时并不依赖这些字段。\n\n邮件访问协议我们会发现整个邮件发送流程中还缺失了一环，也就是接收方从用户代理获得邮件服务器上面的邮件。因为取报文是一个拉操作，但 SMTP 是一个推协议。为此需要引入特殊的邮件访问协议来解决这个问题，包括第三版的邮局协议（Post Office Protocol-Version 3, POP3）、因特网访问协议（Internet Mail Access Protocol, IMAP）、HTTP。\n\nPOP3POP3 是一个极其简单的邮件访问协议。建立 TCP 连接后，POP3 会按照三个阶段进行工作：特许、事务处理及更新。在特许阶段，用户代理以明文形式发送用户名和密码，供服务器对用户进行身份验证。在事务处理阶段，用户代理从服务器取回报文，同时，用户代理还能对报文做或取消删除标记，以及获取邮件的统计信息。在客户发出了 quit 命令后的更新阶段，用户代理将删除被标记为删除的报文，然后结束会话。\n在 POP3 的工作过程中，用户代理发出一些命令，服务器会对每个命令作出回答，+OK (可能的数据) 表示命令正常，- ERR 则表示命令出现了差错。\n特许阶段主要的命令是 user &lt;user name&gt; 和 pass &lt;password&gt;，用于向服务器提供用户名和密码，以完成身份验证。\n事务处理阶段有四个命令：list 用于要求服务器列出所有储存的报文的长度，retr 用于获取报文内容，dele 用于标记删除，quit 用于退出。如果用户选择下载并保留，那么不会发送 dele 命令，此时从其它机器仍能下载；如果下载并删除，就无法再下载。\n可以看到，POP3 期间，服务器临时保存了要被删除的报文的状态信息，但并不会在会话过程中携带状态信息，这极大地简化了 POP3 的实现。\n\nIMAP在 POP3 协议下，用户无法在服务器上创建远程文件夹或将邮件在文件夹之间移动，这严重限制了邮件管理的灵活性，而 IMAP 协议则有效解决了这一问题。\nIMAP 将每封邮件与一个文件夹关联：当邮件首次到达服务器时，默认归属于收件人的 INBOX 文件夹。用户随后可以将邮件移动到自己创建的新文件夹中，进行阅读、删除、归档等操作。IMAP 提供了专门的命令，支持用户创建文件夹、在文件夹间移动邮件，以及在远程文件夹中按指定条件（如发件人、主题、日期等）查询匹配的邮件。\n值得注意的是，与无状态的 POP3 不同，IMAP 服务器会维护用户的会话状态信息，包括文件夹名称、各邮件与文件夹的关联关系等，从而实现跨设备一致的邮件管理体验。\nIMAP 的另一个重要特性是支持部分获取邮件内容。例如，用户代理可以仅获取某封邮件的首部，或只下载一个多部分 MIME 邮件中的特定部分（如文本正文，而不下载附件）。这一功能在用户代理与邮件服务器之间使用低带宽连接（如早期的拨号调制解调器）时尤为有用：用户无需下载整封邮件，尤其可以避免传输可能包含音频、视频等大体积附件的邮件，从而节省时间和带宽。\n\n基于 Web 的电子邮件此时，用户代理就是普通的 Web 浏览器，用户与远程邮箱之间的通信完全通过 HTTP 进行。在这种模式下，用户撰写并发送的邮件也是通过 HTTP 请求提交给邮件服务器，而非直接使用 SMTP 协议。邮件服务器在接收到 HTTP 请求后，再在后端通过 SMTP 将邮件转发至目标服务器。\n\n\nDNS主机的标识方式有多种。一种是使用便于人类记忆的主机名（如 www.baidu.com），但它几乎不包含主机在因特网中位置的信息，且长度不固定、由字母和数字混合组成，难以被路由器高效处理。  \n另一种是使用 IP 地址 进行标识。以 IPv4 为例，它由 4 个字节（32 位）组成，每个字节用 0 到 255 之间的十进制数表示，并用句点分隔，例如 192.168.1.1。这种格式不仅便于阅读，还体现了层次化的网络结构：从左到右，地址的范围由宽泛逐渐细化，前几位通常表示网络部分，后几位标识该网络中的具体主机，从而支持高效路由与寻址。\nDNS 服务如前所述，主机名有两种标识方式，人类倾向于便于记忆的主机名，但路由器倾向于结构化的 IP 地址。为此我们需要能够进行主机名到 IP 地址转换的目录服务，这就是域名服务（Domain Name System, DNS）的主要任务。DNS 是一个分布式、分层的数据库系统，由全球范围内的 DNS 服务器协同实现；同时，它也是一套应用层协议，允许主机通过标准查询机制访问该数据库。DNS 服务器通常运行在 Unix 系统上，使用如 BIND（Berkeley Internet Name Domain）等软件。DNS 协议主要运行在 UDP 之上，使用 53 号端口。\nDNS 通常是其他应用层协议所使用的，包括我们之前了解了的 HTTP 和 SMTP。可以预想到的是，DNS 不止可以提供从主机名到 IP 地址的转换服务。事实上，DNS 还提供多种关键服务，包括：  \n\n主机别名：允许为同一主机设置易记或用途明确的别名；  \n邮件服务器别名：指定接收某域名邮件的邮件服务器；  \n负载分配：通过返回多个 IP 地址实现简单的轮询式负载均衡，将用户请求分散到多个服务器，提升系统可扩展性与可靠性。  \n\n这些功能使 DNS 成为互联网基础设施中不可或缺的组成部分，远超一个简单的“名字到地址”的映射工具。\nDNS 工作原理当主机上的某个应用程序需要将主机名解析为 IP 地址时，它会调用本地的 DNS 客户端（通常通过操作系统提供的解析库），并传入待查询的主机名。随后，本地 DNS 解析器会向网络中的 DNS 服务器发送一个 DNS 查询报文。经过一段时间，它会收到一个包含所请求映射关系的 DNS 响应报文。最终，解析结果会被返回给最初发起请求的应用程序，供其建立网络连接使用。\n最容易想到的一种设计是使用单一的 DNS 服务器来存储所有主机名与 IP 地址的映射，但这种集中式架构显然无法满足当今因特网的需求。它存在单点故障、通信容量、时延、维护困难等诸多致命缺陷。因此，现代 DNS 采用了分布式数据库架构，通过分层、分布在全球的 DNS 服务器协同工作，既提升了系统的可靠性与可扩展性，又有效降低了查询时延和管理开销。\n分布式、层次数据库DNS 服务器大致分为三种：根 DNS 服务器、顶级域（Top-Level Domain, TLD）DNS 服务器和权威 DNS 服务器。这些服务器按如图所示的方式组织起来：\n\n  \n  DNS 服务器层次\n\n\n\n根 DNS 服务器全球共有 13 组逻辑根服务器，它们提供 TLD 服务器的 IP 地址，引导解析过程进入下一阶段。\nTLD 服务器对于每个通用顶级域（如 .com、.org、.net、.edu、.gov）以及国家代码顶级域（如 .uk、.fr、.ca、.jp），都设有对应的 TLD 服务器。支撑这些 TLD 的网络基础设施通常规模庞大且高度复杂，其核心作用是当收到域名查询时，返回负责该域名的权威 DNS 服务器的 IP 地址，引导解析过程进入再下一阶段。\n权威 DNS 服务器权威 DNS 服务器储存了将主机名字映射为 IP 地址的具体 DNS 记录。\n\n除此之外，还有一种相当重要的 DNS 服务器，它被称作本地 DNS 服务器。它并不属于 DNS 服务器的官方层次结构中，但在实际解析过程中相当重要。它通常由 ISP 提供，并通过 DHCP 自动配置到主机。用户主机发起域名解析时，首先联系的就是这台本地 DNS 服务器，然后本地 DNS 服务器会代表用户递归地遍历 DNS 层次结构完成查询，并将结果缓存，以加速后续相同请求。由于它通常部署在用户附近，不仅能显著降低解析延迟，还能有效减轻全球 DNS 服务器的负载。\n因此，真实的 DNS 服务器的交互应该是如下图所示的：\n\n  \n  DNS 服务器交互\n\n\n事实上，权威 DNS 服务器可以进一步将子域的解析权委派出去，从而形成比“根 → TLD → 权威”更复杂的多级 DNS 结构。通常，TLD 服务器并不直接知道某主机的最终权威服务器，而仅知道该域名的父级 DNS 服务器；随后，该父级服务器再指向更具体的子域权威服务器。因此，一次完整的 DNS 查询往往需要跨越三层以上的服务器，而非简单的三层结构。\nDNS 查询分为递归查询和迭代查询两种方式。  \n\n在递归查询中，DNS 服务器收到请求后，会代表客户端全程完成解析，最终直接返回最终结果（或错误），客户端只需等待即可；  \n在迭代查询中，DNS 服务器若无法直接回答，会返回下一个应查询的服务器地址，由客户端（或上一级服务器）自行继续查询。\n\n在实际的 DNS 解析过程中，一般主机向本地 DNS 服务器发起的是递归查询，而本地 DNS 服务器向根、TLD、权威等服务器发起的则是迭代查询。这种混合模式兼顾了用户体验（客户端只需发一次请求）和系统可扩展性（避免根服务器等承担递归负担）。\nDNS 缓存DNS 系统另一个非常重要的特性是缓存机制，其原理就是本地 DNS 服务器会将先前查询到的主机名与 IP 地址的映射关系临时存储在缓存中。当后续收到相同查询时，可直接返回缓存结果，无需再次遍历整个 DNS 层次结构。为保证数据的时效性，每条缓存记录都附带一个生存时间（Time To Live, TTL），通常为数小时至两天，超时后即被自动丢弃，以确保解析结果不会长期滞后于实际变更。\n另外，本地 DNS 服务器不止可以储存主机名的映射，它同样能够缓存 TLD 服务器的 IP 地址。因此，绝大多数情况下，根服务器都被跳过了。\nDNS 记录和报文资源记录所有共同构成 DNS 分布式数据库的 DNS 服务器都存储着资源记录（Resource Record, RR），这些记录提供了主机名到 IP 地址的映射等信息。每条 DNS 响应报文通常包含一条或多条资源记录。\nRR 是一个包含了下列字段的四元组：\n(Name, Value, Type, TTL)TTL 如前所述是生存时间，而 Name 和 Value 的值取决于 Type：\n\nA 记录（Address）：将主机名映射到 IPv4 地址。格式：(Name=主机名, Value=IP地址, Type=A)示例：(relay1.bar.foo.com, 145.37.93.126, A)\n\nNS 记录（Name Server）：指定负责某域名的权威 DNS 服务器。格式：(Name=域名, Value=权威 DNS 服务器主机名, Type=NS)示例：(foo.com, dns.foo.com, NS)用于在 DNS 查询链中引导解析过程。\n\nCNAME 记录（Canonical Name）：为主机名定义一个别名，指向其规范（真实）主机名。格式：(Name=别名, Value=规范主机名, Type=CNAME)示例：(foo.com, relay1.bar.foo.com, CNAME)\n\nMX 记录（Mail eXchanger）：指定接收某域名邮件的邮件服务器的规范主机名。格式：(Name=域名, Value=邮件服务器主机名, Type=MX)示例：(foo.com, mail.bar.foo.com, MX)允许邮件服务器使用与 Web 服务器等相同的别名；要获取邮件服务器地址，应查询 MX 记录；获取其他服务地址，则应查询 CNAME 或 A 记录。\n\n\n可以看到，前文提到的 DNS 的其他功能（主机别名和邮件服务器别名）正是通过 CNAME 和 MX 记录来实现的。\nDNS 报文DNS 报文格式如图所示：\n\n  \n  DNS 报文格式\n\n\n\n首部区域DNS 报文的前 12 个字节为首部区域，包含 6 个字段，用于描述报文的基本信息。第一个字段是标识符，用于匹配查询请求与对应的响应。随后是标志字段，包含多个关键标志位：  \n\nQR（Query/Response）：指示报文类型，0 表示查询，1 表示回答；  \nAA（Authoritative Answer）：仅在回答报文中有效，置位时表示该服务器是所查询域名的权威 DNS 服务器；  \nRD（Recursion Desired）：由客户端设置，表示希望服务器执行递归查询；  \nRA（Recursion Available）：由服务器在回答中设置，表示自身支持递归查询。  \n\n首部最后四个字段为数量字段，分别指明问题数、回答资源记录数、权威资源记录数和附加资源记录数，其含义不言自明。\n\n问题区域问题区域包含本次 DNS 查询的具体信息，包含正在被查询的主机名和问题类型。\n\n回答区域回答区域包含一条或多条 RR，用于响应查询请求。例如，若查询类型为 A，则回答中会包含对应的 IP 地址记录。\n\n权威区域权威区域包含了其他权威服务器的记录。\n\n附加区域附加区域包含与查询相关的额外资源记录，用于提供辅助信息。例如，当响应中包含一条 MX 记录时，通常会在此区域附带该邮件服务器对应的 A 记录（即其 IP 地址），以避免客户端再次发起查询，从而提高解析效率。\n\n\nDNS 记录的添加当一个组织获得域名的管理权后，它并不会直接向全球 DNS 数据库写入数据，而是通过权威 DNS 服务器间接完成这一过程。具体来说，组织会在自己的权威服务器上维护一个区域文件，其中包含该域名下的各种资源记录。这些记录定义了域名与其对应 IP 地址或服务的映射关系。对于公共域名，域名注册商或 DNS 托管服务商通常提供可视化的管理界面，用户在其中添加或修改记录后，系统会自动更新相应的区域文件，并在权威 DNS 服务器上生效。随后，这些更新会通过 DNS 层级体系被逐级缓存和传播，从而成为全球可查询的 DNS 数据。\nP2P 文件分发之前的三个应用均采用客户端—服务器架构，高度依赖始终在线的基础设施服务器。而接下来要介绍的 P2P 架构则几乎不依赖此类中心化服务器。\n一个典型的 P2P 应用是用于文件分发的 BitTorrent。在 BitTorrent 的术语中，参与某一特定文件分发的所有对等方组成的集合被称为一个“洪流”（torrent）。在该洪流中，对等方彼此交换等长的文件块（chunk），典型块大小为 256 KB。当一个对等方首次加入洪流时，它尚未拥有任何文件块。随着时间推移，它逐步下载并累积越来越多的块；与此同时，它也会将已获得的块上传给其他对等方。一旦某个对等方完整获取了整个文件，它可以选择立即离开洪流，也可以继续留在洪流中，为其他对等方上传数据。此外，任何对等方都可能在仅持有部分文件块时中途离开洪流，并在之后重新加入。\n我们可以看出，相比传统的客户端—服务器架构，P2P 架构能显著缩短文件分发所需的时间。\nBitTorrent 工作原理在每个洪流中，都有一个基础设施节点，一般称作追踪器。当一个对等方加入洪流时，它会向追踪器注册自己，并且周期性地通知追踪器它仍在洪流中。通过这样的方式，追踪器可以实时了解洪流中对等方的状况。\n当一个新的对等方加入洪流时，追踪器会随机选取当前仍在该洪流中的一组对等方，并将其 IP 地址返回给新加入者。随后，该对等方会尝试与这些节点建立并行的 TCP 连接。随着时间推移，部分连接的对等方可能离开洪流，同时也会有其他新的对等方主动尝试与它建立连接。\n在任意给定时刻，每个对等方都持有该文件的块的一个子集，且不同对等方所拥有的子集通常各不相同。此时，每个对等方会通过 TCP 向其相邻对等方查询对方所拥有的块列表，并针对自身尚未获取的块发起请求。\n此时，对等方面临两个决策，一是选择请求哪些块，二是决定向哪些发出请求的邻居发送自己拥有的块。在选择请求块时，通常采用“最稀缺优先”策略——即优先下载当前洪流中最稀有的块。这种策略有助于均衡各块在洪流中的分布，防止某些块因数量过少而成为分发瓶颈，从而提升整体传输效率。在决定响应哪些请求时，对等方通常会优先向那些能最快为其提供数据的邻居发送块，这些被选中的高速邻居被称为“疏通”节点。此外，每隔 30 秒，每个对等方还会强制选择一个未被疏通的邻居进行“乐观疏通”，向其发送数据块。这一机制有助于发现潜在的高速对等方、鼓励合作，并提升整个洪流的分发效率和鲁棒性。\n除了上述机制外，BitTorrent 实际上还包含许多其他精巧的设计，但受限于学习目标和篇幅，此处不再展开讨论。\n","categories":["计网"],"tags":["计算机网络","应用层"]},{"title":"计网学习笔记-3","url":"/2025/10/22/%E8%AE%A1%E7%BD%91%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/","content":"运输层运输层概述运输层协议为运行在不同主机上的应用进程之间提供了逻辑通信功能，使它们能够透明地交换报文，而无需关心底层通信的复杂细节。运输层协议在主机上实现：在发送端，运输层将从发送应用进程接收到的报文封装成运输层分组，称为报文段，随后，这些报文段被传递给网络层。网络层为其添加网络层首部得到数据报，并负责将其发送至目的地。在接收端，网络层从数据报中提取运输层报文段，并且上交给运输层。运输层则处理接收到的报文段，使得数据可以被接收的应用进程使用。\n运输层和网络层网络层提供了主机间的逻辑通信，而运输层则为运行在不同主机上的进程提供了逻辑通信。在整个数据传输过程中，网络中的路由器仅处理网络层的首部信息，对运输层报文段的内容既不检查也不修改，完全透明地转发。\n计算机网络中可以支持多种运输层协议，每种协议为上层应用提供不同的服务模型。虽然运输层所能提供的服务在一定程度上受限于底层网络层的服务能力，但它并非完全被动依赖。例如，即使底层网络协议是不可靠的，或者说可能出现分组丢失、乱序甚至内容损坏等情况，运输层仍可通过自身机制（如确认、重传、校验等）向上层提供可靠的数据传输服务。同样，尽管运输层通常无法保证通信的机密性（这通常由应用层或安全协议如 TLS 处理），但它可以通过差错检查机制在一定程度上防止报文在传输过程中被未授权方窃取或篡改。因此，运输层在弥补网络层不足、提升通信质量方面发挥着关键作用。\n因特网运输层如前所述，运输层有两种协议：TCP 和 UDP。为了理解为什么它们会有区别，我们有必要先了解一些网络层的基础知识，尤其是关于 IP 地址更深入的一些内容。事实上，IP 协议是网络层的核心协议之一，它为主机之间提供了逻辑通信。IP 协议是尽力而为交付协议，这意味着它不确保报文段的交付，也不确保顺序和完整性。正因如此，IP 协议被视为一种不可靠的服务。每台主机至少有一个网络层地址，即 IP 地址。我们将在 4、5 章中更加详细地了解 IP 地址的相关内容。\nTCP 和 UDP 最基本的责任是将两台主机间 IP 的交付服务扩展为运行在两台主机上的两个进程间的交付服务，这被称作运输层的多路复用与多路分解。TCP 和 UDP 还可以通过在其报文段首部中包括差错检查字段来提供完整性检查。进程到进程的数据交付和差错检查是两种最低限度的运输层服务，也是 UDP 所能提供的仅有的两种服务。另外，与 IP 一样，UDP 也是不可靠的服务。虽然其包含差错检查机制，但它不会重传，也不确认，更不保证顺序或完整性。因此，尽管 UDP 有差错检查能力，它仍然被归类为不可靠的传输协议。\n另一方面，TCP 为应用程序提供了几种附加服务。首先，TCP 提供可靠数据传输服务。通过序号、确认、定时器和流量控制等机制，TCP 可以确保数据能够无差错、不丢失、不重复且按序地从发送进程交付到接收进程。其次，TCP 还实现了拥塞控制，用于防止某条 TCP 连接因发送过多数据而使网络过载；它通过动态调节发送速率，来适应当前网络的拥塞状况，从而提升整体网络的稳定性和效率。\n多路复用和多路分解在目的主机，运输层从网络层接收报文段，并负责将其中的数据交付给主机上相应的应用进程。我们知道，每个进程通常关联一个或多个套接字。因此，运输层实际上并不是直接将数据交给进程，而是交付给对应的套接字。因为套接字不唯一，所以每个套接字都有一个唯一的标识符，该标识符的具体格式取决于套接字所使用的运输层协议，TCP 套接字和 UDP 套接字的标识方式有所不同。\n为了准确地定位目标套接字，运输层报文段包含几个关键字段，其中最重要的是源端口号和目的端口号（TCP 和 UDP 各自特有的其他首部字段将在后续介绍）。端口号是一个 16 位的无符号整数，取值范围为 0 到 65535。其中，0 到 1023 被称为周知端口号，被保留给常用的应用层协议使用，例如 HTTP 默认使用 80，HTTPS 使用 443，这些端口通常需要特权权限才能绑定。当开发新的应用程序时，必须为其分配一个未被占用的端口号。通常会使用 1024 到 65535 范围内的端口，以避免与系统服务冲突。\n所以多路分解其实也很简单，就是报文段到达主机时运输层检查其目的端口号并定向到相应的套接字，然后数据就会通过套接字进入其所连接的进程。UDP 实际上大概也就是这么做的。然而，如我们所想，TCP 中的多路复用和多路分解实际上会更加复杂。\n无连接的多路复用和多路分解以 Python 代码为例，当执行 clientSocket = socket(AF_INET, SOCK_DGRAM) 创建一个 UDP 套接字时，运输层会为其自动分配一个未被使用的临时端口号，通常位于 1024 至 65535 的范围内。若需显式指定端口，则可调用 clientSocket.bind((&#39;&#39;, 19157)) 将该套接字绑定到指定端口（例如 19157）。\n而在实现周知协议的服务器端时，必须将套接字绑定到对应的周知端口号，以便客户端能够按照约定访问服务。一般而言，客户端端口可由系统自动分配，而服务器端则必须显式绑定到固定端口，从而确保服务能够被正确寻址与访问。\n实际上，一个 UDP 套接字由目的 IP 地址和目的端口号组成的二元组唯一标识，这里的 IP 地址是运输层处理数据报时得到的。无论报文段来自哪个源 IP 地址或源端口号，只要其目的 IP 地址和目的端口号相同，运输层就会将其交付给同一个套接字，进而传递给对应的目标进程。源 IP 地址和源端口号并不参与套接字的标识，它们的主要作用是为接收方提供返回地址，便于回复数据。\n有连接的多路复用和多路分解与 UDP 套接字不同，一个 TCP 套接字由一个四元组（源 IP 地址、源端口号、目的 IP 地址、目的端口号）来标识。因此，当 TCP 报文段从网络到达一台主机时，主机会使用全部四个值来定向到相应的套接字。两个源 IP 地址或源端口号不同的 TCP 报文段将被定位到两个不同的套接字，除非它携带了初始创建连接的请求。携带初始连接请求的报文段仅使用目的 IP 地址和目的端口号来定位套接字，这样可以确保多个客户能够同时连接到同一个服务器套接字，而不会发生冲突。\n下图是一个比较复杂的通信例子，其中主机 C 与 主机 B 有两个 HTTP 会话，主机 A 和 主机 B 有一个 HTTP 会话，主机 A 和主机 C 的一个会话有相同的源端口号。但此时服务器 B 仍然可以正确地分解连接，因为它们有不同的源 IP 地址。\n\n  \n  通信例子\n\n\nUDPUDP 看似不可靠，但其实际上也有许多优势，因此被保留至今。首先因为没有拥塞控制，所以对发送数据内容和发送时间的控制更加精细，适合一些实时应用；其次因为无需连接建立，所以没有额外时延，对服务器负担也小，可以提供更快更多的服务；最后因为其首部仅有 8 字节，所以开销也小。\n还有一点需要再次强调，就是使用 UDP 的应用是可以实现可靠数据传输的。通过在应用层实现确认和重传机制，UDP 也能提供可靠的数据传输服务。例如，DNS 协议虽然基于 UDP，但它通过应用层的重传机制确保查询结果的可靠交付。因此，UDP 的不可靠性并不意味着应用层无法实现可靠通信，是否需要可靠通信、以及是否在应用层实现可靠性仍然取决于具体的应用需求和设计。\nUDP 报文结构UDP 报文结构如下所示，其首部仅有四个字段。除了我们之前讨论过的源端口号和目的端口号，还有用于指示 UDP 报文段总字节数的长度字段和用于进行差错检验的检验和字段。\n\n  \n  UDP 报文格式\n\n\nUDP 检验和UDP 检验和提供了差错检测功能，用于检测其中的比特是否发生改变。发送方的 UDP 对报文段的所有 16 比特字的和进行反码加法，求和时遇到的所有溢出都被回卷，得到的结果取反码放在检验和字段。例如，假定发送方的 UDP 报文段包含下面三个 16 比特字：\n\n\\begin{aligned}\n1101\\ 1010\\ 1010\\ 1010 \\\\\n0110\\ 0110\\ 0110\\ 0110 \\\\\n0001\\ 0001\\ 0001\\ 0001\n\\end{aligned}那么发送方会如下计算它们的和：\n\n\\begin{array}{r}\n  1101\\ 1010\\ 1010\\ 1010 \\\\\n+ \\ 0110\\ 0110\\ 0110\\ 0110 \\\\\n\\hline\n1\\ 0100\\ 0001\\ 0001\\ 0000 \\\\\n\\text{(回卷进位)}\\quad\\quad\\quad +\\ 1 \\\\\n\\hline\n  0100\\ 0001\\ 0001\\ 0001 \\\\\n+ \\ 0001\\ 0001\\ 0001\\ 0001 \\\\\n\\hline\n  0101\\ 0010\\ 0010\\ 0010 \\\\\n\\text{(取反得校验和)}\\quad\\quad\\quad \\\\\n\\hline\n  1010\\ 1101\\ 1101\\ 1101 \\\\\n\\end{array}之所以在运输层提供差错检测，正是基于端到端原则。尽管许多链路层协议确实具备差错检测能力，但我们无法保证网络中所有链路都提供此类保护；更重要的是，即使数据在每一段链路上都正确传输，仍可能在中间节点（如路由器）或端系统的内存中因硬件故障、软件错误等原因发生比特翻转等损坏。\n因此，端到端原则指出：若某项功能（如数据完整性）必须由通信的两端才能完整、可靠地实现，那么将其置于高层（如运输层）比依赖底层更有效；相比之下，在底层实现这类功能可能是冗余的，甚至毫无价值的。\nUDP 虽然提供了差错检测（通过校验和），但其对错误几乎不进行恢复。一旦检测到损坏，UDP 通常只会静默丢弃该报文段，或在某些实现中将数据连同错误提示一并交给应用程序。它不重传、不确认，也不保证交付，因此仍被视为不可靠协议。\n可靠数据传输原理可靠数据传输（reliable data transfer）的服务模型旨在提供一条可靠的逻辑信道，确保数据能够完整、无差错、按序地从发送方交付至接收方。值得注意的是，这一可靠服务实际上是构建在底层不可靠的信道之上的，如下图所示：\n\n  \n  可靠数据传输\n\n\n这种服务抽象是可靠数据传输协议的责任，因为其下层协议可能不可靠，所以这项任务相当困难。在本节中，我们首先聚焦于单向数据传输，双向并没有本质差异。需要注意的是，即便数据只在一个方向流动，控制分组等仍需在反方向传输，因此协议的发送端和接收端都必须具备发送和接收分组的能力。\n构造可靠数据传输协议我们一步步添加噪声，使得协议一步步臻于完善。\n\n经完全可靠信道的可靠数据传输：rdt1.0最简单的情况显然是底层信道完全可靠，发送方和接收方的有限状态机（Finite-State Machine, FSM）如图所示，横线上方代表事件，下方代表动作。在 rdt1.0 中，发送端只需执行 packet = make_pkt(data) 将数据封装成分组，然后通过 udt_send(packet) 经由底层信道发送即可，接收端也只需要从收到的分组中提取数据（extract(packet, data)），并调用 deliver_data(data) 将其交付给上层应用：\n\n \n rdt1.0\n\n\n此时无需任何反馈信息，因为信道本身是可靠的；同时，由于我们假设接收方的处理速率与发送方完全匹配，因此也无需进行流量控制或减速。\n\n经具有比特差错信道的可靠数据传输：rdt2.0稍微实际一点的模型是分组中的比特可能在传输过程中受损的模型，我们采用自动重传请求（Automatic Repeat reQuest, ARQ）协议解决这个问题。ARQ 协议还依赖以下三种关键机制来解决存在比特差错的情况：\n\n差错检测。首先，需要一种机制来让接收方能够检测何时出现了比特差错，UDP 的检验和字段一定程度上提供了这种能力。更具体的解决方案我们会在第 5 章中了解到，目前我们只需要知道实现差错检测通常需要在报文中引入额外的字段。\n接收方反馈。其次，为了让发送方获知接收方是否正确收到数据，接收方必须提供明确的反馈。通常采用发送 ACK（确认）或 NAK（否定确认）分组的方式。从理论上讲，这种反馈信息仅需 1 比特即可区分两种状态。\n重传。最后，当发送方得知接收方收到了有差错的分组，它将重传该报文。\n\n利用了这三种机制的 FSM 如图所示，其中 $\\Lambda$ 代表缺少动作或事件：\n\n \n rdt2.0\n\n\n可以看到，当发送方处于等待 ACK 或 NAK 状态时，它不能从上方获得更多数据，更无法发送新数据。换而言之，发送方只有确信接收方已正确接收当前分组才会发送新数据，这被称为停等协议。\n然而，上面的 FSM 很显然有一个严重的问题，就是 ACK 或 NAK 本身也可能在传输过程中发生比特错误或丢失。一旦反馈信息受损，发送方将无法准确判断接收方是否成功收到了数据。为解决这一问题，最直接且有效的方法是在分组首部中引入一个序号字段，对每个发送的数据分组进行编号。在停等协议中，仅需 1 位序号（交替使用 0 和 1）即可有效区分当前分组是新数据还是重传数据。这样，接收方在处理分组时，会检查其序号；发送方在收到反馈时，也能依据序号判断当前应发送的是新数据还是重传旧数据。\n具体而言，即使 ACK/NAK 因损坏而无法被正确解析，发送方重传的仍是带有相同序号的原分组。接收方通过比对当前分组的序号与最近成功接收的分组序号，即可识别该分组是否为重复——若是重复，则丢弃数据但依然发送确认；若是新分组，则正常接收并交付给上层。这种机制确保了即使在控制分组不可靠的情况下，双方仍能最终就“哪些数据已被可靠接收”达成一致，从而有效避免状态混淆、数据重复或遗漏。FSM 如图所示：\n\n \n rdt2.1\n\n\n我们还可以发现，如果不发送 NAK，而是对上一个正确接收的分组发送一个 ACK，也能实现同样的效果。因此，可以实现无 NAK 的可靠数据传输协议：\n\n \n rdt2.2\n\n\n经具有比特差错的丢包信道的可靠数据传输：rdt3.0现在假定除了比特受损外，底层信道还会丢包，那么现在面临的问题就是如何检测丢包以及丢包后应该这么处理。对于第二个问题，我们利用已有的包括差错检测、接收方反馈、序号以及重传等机制已能有效应对。然而，检测丢包本身需要一种新的机制，因为与比特错误不同，丢包意味着接收方根本不会收到任何数据，也就无法主动反馈 NAK 或 ACK。因此，必须引入一种主动判断“未收到即丢失”的方法。\n假定发送方传输了一个数据分组，该分组和接收方的 ACK 分组都有可能丢失。那么，如果发送方等待了足够长的时间，它就能大概确定分组已经丢失，此时它需要重传该分组。现在的关键是发送方需要等待多长时间才能确定分组丢失。最短的时间是往返时延 + 接收方处理分组的时间 + 一定的裕度，但最坏情况下的延迟难以准确预估。另一方面，协议必须尽快从丢包中恢复，以维持传输效率。因此，实践中通常选择一个经验上合理且保守的超时阈值，一旦超时即认为分组丢失并立即重传。这种策略可能导致冗余数据分组的出现，但正如我们在 rdt2.2 协议中所设计的那样，通过序号机制，接收方能够识别并正确处理重复分组，从而确保数据的可靠性和一致性。\n为了实现重传机制，需要一个倒计数定时器，当发送方发送一个分组时启动该定时器。如果在定时器到期前收到相应的 ACK，则停止定时器并继续发送下一个分组；如果定时器到期且未收到 ACK，则重传该分组并重新启动定时器。这样，发送方就能在检测到丢包后及时重传数据，确保可靠传输。最终的发送方 FSM 如图所示，接收方的 FSM 不变：\n\n\nrdt3.0\n\n\n此时，超时重传机制取代了对 ACK 损坏的即时响应，协议不再将重复 ACK 视为需要立即处理的信号，而是统一通过定时器超时来触发重传。也就是说，无论 ACK 是损坏、丢失，还是网络延迟，都统一重传来解决。这一统一对接收方的行为没有影响，因为其功能保持不变：当接收到正确的分组时，发送对应的 ACK；当接收到错误的分组时，重传上一个已成功接收分组的 ACK，通知发送方自己的接收进度。\n至此我们得到了一个可靠数据传输协议，我们一般称其为比特交替协议，它完整地实现了可靠数据传输的服务模型。尽管如此，仍有许多人对它的性能并不满意，特别是在今天的高速网络中，其核心原因在于它是一个停等协议。由于在实际网络中，传播时延往往远大于发送时延，因此大量时间都被浪费到等待 ACK 上面了。为克服这一瓶颈，流水线协议应运而生，旨在通过允许多个分组同时处于传输过程中，从而有效利用网络带宽，显著提升吞吐量。\n\n\n流水线可靠数据运输协议如前所述，我们允许发送方在未收到确认的情况下连续发送多个分组。由于从发送方到接收方传输的多个分组可以看作填充在一条流水线中，这种技术被称为流水线技术。流水线技术对可靠数据传输协议的设计带来了以下几方面的重要影响：\n\n序号空间必须扩大：由于多个分组可能同时在途，仅用 1 位序号已无法区分新分组与重传分组，因此需要更大的序号范围以避免歧义。\n\n发送方和接收方必须缓存多个分组：发送方需保存已发送但尚未确认的分组，以便在丢包时重传；接收方则可能需要缓存乱序到达的分组，等待缺失的分组到达后再按序交付。\n\n上述两点的具体设计，取决于协议如何处理丢失、损坏或严重延迟的分组。例如，是采用回退 N 步还是选择重传，将直接影响所需的序号范围和缓存策略。\n\n\n回退 N 步在 回退 N 步（Go-Back-N, GBN）协议中，发送方被允许连续发送多个分组而无需等待每个分组的确认，但流水线中未被确认的分组数量不得超过一个预设的最大值 $N$。\n为管理这些分组，协议引入两个关键变量：\n\n基序号（base）：表示最早尚未被确认的分组的序号；\n下一个序号（nextseqnum）：表示下一个可分配的最小未使用序号。\n\n基于这两个变量，整个序号空间可划分为以下四个逻辑区间（假设序号空间足够大，暂不考虑回绕）：\n\n$[0,\\ \\text{base} - 1]$：已发送且已被确认的分组；\n$[\\text{base},\\ \\text{nextseqnum} - 1]$：已发送但尚未确认的分组；\n$[\\text{nextseqnum},\\ \\text{base} + N - 1]$：允许发送但尚未发送的分组（位于发送窗口内）；\n$[\\text{base} + N,\\ \\infty]$：当前不允许使用的序号（超出窗口范围）。\n\n我们可以把允许使用的序号范围看成一个长度为 $N$ 的滑动窗口，正因如此，$N$ 也被称作窗口长度，GBN 协议也常被称作滑动窗口协议。至于为何要限制允许使用的序号范围，主要是出于流量控制和拥塞控制两方面的考虑，兼顾接收端能力和网络整体稳定性。\n在实现中，我们会用一个 $k$ 比特的字段储存分组序号，显然序号范围为 $[0,\\ 2^k]$，因此所有涉及到序号的运算都默认模 $2^k$。\n下面两张图展示了基于 ACK 机制（不使用 NAK）的 GBN 协议在发送方和接收方的扩展有限状态机。之所以称为“扩展”，是因为该 FSM 不仅包含状态和转移，还引入了变量：\n\n\nGBN 协议发送方扩展 FSM\n\nGBN 协议接收方扩展 FSM\n\n\n可以看到，发送方为整个发送窗口仅维护一个定时器。该定时器在发送第一个尚未确认的分组时启动；此后，每当收到一个累积确认（ACK），若窗口中仍有未确认的分组，则重启定时器；若所有分组均已确认（窗口为空），则停止定时器。一旦定时器超时，发送方将重传窗口内所有未确认的分组。接收方的行为则依旧很简单，仅当正确接收到序号为 $n$ 的分组，且上一个接收的分组序号为 $n-1$ 时，才接收分组并为分组 $n$ 发送 ACK；否则，接收方将丢弃该分组（即使其本身无差错）并向发送方同步自己的接收进度。由于收到了分组 $n$ 的 ACK 说明序号 $n$ 及之前的所有分组均已正确接收”，因此在 GBN 中自然地采用累积确认机制，这样可以简化情况。\n在 GBN 协议中，接收方会丢弃所有失序的分组。这种做法看似浪费，实则有其合理性，因为它使得接收方只需维护下一个期望接收的分组序号，从而显著简化了接收端的实现。\n选择重传GBN 协议虽然允许多个分组在流水线中并发传输，从而提升了带宽利用率，但仍存在明显的性能缺陷：当窗口较大且网络时延带宽积较高时，单个分组的差错会触发对整个未确认窗口的重传。这种“回退 N 步”的机制显然效率低下，会导致大量已正确到达的分组被不必要地重复发送。正因如此，随着信道差错率的上升，往往会导致流水线中充斥着这些本无需重传的冗余分组，不仅浪费带宽，还可能加剧网络拥塞，反而抵消了流水线带来的性能优势。\n选择重传（Selective Repeat, SR）协议通过仅重传那些被怀疑丢失或受损的分组，避免了 GBN 中重传整个窗口的低效行为。为此，接收方需要逐个确认每个正确接收的分组，即使它们是乱序到达的。此时发送方和接收方看到的序号空间如图所示，非常混乱：\n\n\nSR 序号空间\n\n\n在 SR 协议中，发送方需要为每个分组单独维护一个定时器（实际实现中可通过单个硬件定时器配合软件逻辑模拟）。当收到一个 ACK 时，若其序号位于当前发送窗口内，发送方会将对应分组标记为“已确认”。特别地，如果该 ACK 的序号恰好等于当前窗口的基序号 send_base，则窗口将向前滑动，send_base 被更新为最小的未确认分组的序号。窗口滑动后，若出现了尚未发送但序号已落入窗口范围的分组，发送方会立即发送这些分组。\n在 SR 协议中，接收方会确认每一个正确接收到的分组，无论其是否按序到达。接收方此时也需要维护一个大小为 $N$ 的接收窗口，其基序号为 rcv_base，窗口序号范围为 $[\\text{rcv_base},\\ \\text{rcv_base} + N - 1]$。当接收到一个分组时，若其序号落在接收窗口内，接收方会发送一个该序号的 ACK；如果该分组此前未收到，则将其缓存。特别地，如果该分组的序号恰好等于 rcv_base，则接收方将该分组连同所有已缓存且序号连续（从 rcv_base 开始）的分组按序交付给上层，并将 rcv_base 更新为最小的未接收分组的序号。此外，若收到的分组序号属于 $[\\text{rcv_base} - N,\\ \\text{rcv_base} - 1]$ ，接收方也会发送 ACK，向发送方同步进度。如果序号再往前，发送方必然已经得知其已经接收，此时忽略即可。\n\n至此我们或许可以总结出接收方的一点规律，就是无论接收到了什么，只要发送方可能不知道自己接收到了，就要回应自己的接收进度。\n\n尽管我们目前已掌握了实现可靠数据传输的核心方法，但上述讨论均基于无限序号空间的理想假设。在实际系统中，序号字段长度有限，这会引发新的问题：发送方与接收方的窗口可能因序号回绕而失去同步。\n一个极端但典型的情形是：假设序号空间为 ${0,1,2,3}$（即 2 位序号），发送方连续发送了序号为 0、1、2、3 的分组，理想情况下，接收方全部正确接收并发送了对应的 ACK。此时，发送方窗口滑动，下一个要使用的序号回绕为 0；而接收方也已将 rcv_base 更新为 0，准备接收新一轮的分组。\n问题在于，如果 ACK 丢失，发送方可能会重传一个旧的序号 0 分组，而接收方已进入下一轮、正期待新的序号 0 分组，它将无法区分这个重传分组是“上一轮的旧数据”还是“新一轮的新数据”，从而可能导致数据混淆或错误交付。\n","categories":["计网"],"tags":["计算机网络","运输层"]}]