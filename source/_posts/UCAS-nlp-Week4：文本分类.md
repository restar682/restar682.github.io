---
title: UCAS-nlp-Week4：文本分类
date: 2025-10-31 15:46:16
categories: UCAS-nlp
description: 文本分类模型的实现基础。
tags: [自然语言处理, 文本分类]
---
# 切片
Python 的大多数序列（如 list、tuple、str、NumPy 数组、PyTorch Tensor）都支持多种索引与切片方式，极大提高了数据操作的灵活性。

- **基础切片**  
  使用冒号 `:` 指定范围，格式为 `x[a:b]`，表示取索引区间 `[a, b)`（左闭右开）。起始或结束位置可省略，用 `x[:]` 表示选取整个轴，没有提到的维度自动理解成这一维保持全部。
- **多维切片**  
  对于多维数组，各维度的切片用逗号分隔，例如 `x[:, 1:5]` 表示在第一个维度取全部，第二个维度取索引 1 到 4。每个维度仍遵循 `[start:stop:step]` 语法。
- **`None` 索引（用于扩充维度）**  
  在索引中插入 `None` 可显式地新增一个维度，效果等同于 `np.expand_dims`。例如 `x[:, None, :]` 会在第二维插入大小为 1 的新轴。
- **省略号 `...`**  
  `...` 代表“所有未显式指定的中间维度”，常用于高维张量操作。例如 `x[..., 0]` 表示保留前面所有维度，仅取最后一维的第 0 个元素。
- **花式索引**  
  使用整数列表或数组作为索引，如 `x[[0, 3, 5]]`，可按指定顺序或位置选取元素。该操作会返回一个新数组，不共享原数据内存。
- **布尔索引**  
  利用布尔数组进行条件筛选，如 `x[x > 0]` 表示提取所有大于 0 的元素。这是数据过滤和条件选择的常用方式。
- **步长切片**  
  切片支持步长参数，格式为 `x[start:stop:step]`。例如 `x[::-1]` 表示以步长 -1 反向遍历整个序列，常用于反转数组。

这些切片方式可以相互组合，尤其在高维张量（如图像、深度学习特征图）处理中非常常见，例如 `x[None, :, ::2, ...]`。

# 广播
Python 的数值计算库（如 NumPy 和 PyTorch）在执行数组或张量的逐元素运算时，支持一种称为**广播**的机制。它能自动对不同形状的操作数进行“逻辑对齐”，无需显式复制或扩展数据即可完成运算。

广播广泛用于加减乘除等逐元素操作，其规则是按维度从**后向前**（即最右维开始）依次比较两个张量的形状，只要在每个对应的维度上满足“大小相同”或“其中之一为 1”即可广播，否则形状不兼容会报错。
1. 两者的维度大小相等；
2. 其中一个维度大小为 1；
3. 若两个张量维度数不同，较短的形状会在**前面补 1**，再进行比较。

只有当**每一维**都满足“要么相等、要么其中之一为 1”时，广播才会成功，并在逻辑上将两个张量扩展为相同的形状；如果在某一维上，两个张量的大小既不相等又都不为 1，则广播无法进行并抛出形状不匹配错误，例如 `(3, 4)` 与 `(2, 4)` 在第一维分别为 3 和 2，既不相等也不是 1，因此无法广播。

广播在语义上等价于将大小为 1 的维度“复制”到目标长度，但**不会真正复制数据**。

# 可变参数与参数解包
Python 支持在函数定义中接收任意数量的位置或关键字参数，并可在调用时对序列或字典进行解包，极大提升了函数的灵活性。

- `*args`：在函数定义中用于接收任意数量的**位置参数**，所有未被显式形参捕获的额外位置参数会被自动打包为一个**元组**。
- `**kwargs`：在函数定义中用于接收任意数量的**关键字参数**，所有未被显式形参声明的关键字参数会被自动打包为一个**字典**。
- `func(*iterable, **dict)`：在函数调用时，`*` 可将序列（如列表、元组）**解包为位置参数**，`**` 可将字典**解包为关键字参数**。  
  例如，若 `nums = (1, 2, 3)`，则 `f(*nums)` 等价于 `f(1, 2, 3)`；若 `params = {'x': 10, 'y': 20}`，则 `f(**params)` 等价于 `f(x=10, y=20)`。

# 命令行解析
虽然 Python 也可通过 `sys.argv` 直接获取命令行参数，但标准库中的 `argparse` 模块提供了更方便的解析方式。其核心类 `argparse.ArgumentParser` 能自动处理参数定义、类型转换等任务，很适合用来配置参数。

- `parser = argparse.ArgumentParser(description)`：创建命令行参数解析器对象，用于管理和解析命令行输入。 `description` 参数用于指定程序的整体说明文字，在执行 `-h` 或 `--help` 时显示在帮助信息顶部，以简要介绍脚本的用途或功能。
- `parser.add_argument(name, **kwargs)`：向解析器添加一个命令行参数，其中 `name` 是参数名（如 `"--lr"` 或 `"-e"`），`**kwargs` 表示一组可选关键字参数，用于设置该参数的行为和属性，例如：
  - `type`：参数类型（如 `int`、`float`、`str`）
  - `default`：参数的默认值
  - `help`：提供参数的说明文本
  - `choices`：限定参数的可选值范围
  - `action`：定义解析行为（如 `"store_true"` 表示布尔开关）
- `arg = parser.parse_args()`：解析运行脚本时实际传入的命令行参数，将每个参数的值按名称存入一个 `Namespace` 对象（通常命名为 `args`）。可以通过 `args.参数名` 的方式访问各参数的值。

# 数据加载
在 PyTorch 中，常用 `torch.utils.data` 中的 `Dataset` 和 `DataLoader` 来处理数据，其中 `Dataset` 用于封装数据及其标签，定义“如何获取单个样本”，而 `DataLoader` 负责批量加载、打乱顺序、并行预取等，定义“如何高效地将数据送入模型”。
- `torch.utils.data.Dataset`类：
  自定义数据集必须继承此类并实现两个方法：  
  - `__len__(self)`：返回数据集总样本数；  
  - `__getitem__(self, idx)`：根据索引 `idx` 返回一个样本（通常为 `(data, label)` 元组）。  
  PyTorch 也提供了内置数据集（如 `torchvision.datasets.MNIST`），可直接使用。
- `dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0, ...)`：  
  将 `Dataset` 对象包装为可迭代的批量数据加载器。常用参数包括：  
  - `batch_size`：每个 batch 的样本数量；  
  - `shuffle`：是否在每个 epoch 开始时打乱数据顺序；  
  - `num_workers`：用于数据加载的子进程数（设为 `0` 表示主进程加载）；  
  - `drop_last`：若最后一批样本数不足 `batch_size`，是否丢弃；
  - `collate_fn`：自定义批处理函数，用于定义如何将单个样本列表组合成一个 batch。
  使用时，可通过 `for data,label in dataloader:` 直接遍历批量数据。