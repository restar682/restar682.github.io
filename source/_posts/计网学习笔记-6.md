---
title: 计网学习笔记-6
date: 2025-11-08 11:51:42
categories: 计网
description: 《计算机网络——自顶向下方法》第六章学习笔记。
tags: [计算机网络, 链路层, 局域网]
---
# 链路层
## 链路层概述
### 链路层服务
链路层的基本服务是将数据报通过单一通信链路从一个节点移动到相邻节点，但所提供的服务细节会随着链路层协议的不同而有所变化。链路层能够提供的可能服务包括：

1. **成帧**
   在网络层数据报通过物理链路传输之前，几乎所有的链路层协议都会将其封装在链路层帧中。一个帧通常由一个数据字段和若干首部字段组成，其中网络层数据报被置于数据字段内，其余结构如首部和可能的尾部则由具体的链路层协议定义。
2. **链路接入**
   链路接入由媒体访问控制（Medium Access Control, MAC）协议规定，用于管理帧在共享链路上的传输规则。
   - 对于点对点链路，即链路一端仅有一个发送方，另一端仅有一个接收方，MAC 协议通常非常简单，甚至可以省略：只要链路空闲，发送方即可立即发送帧。
   - 更复杂的情形出现在多个节点共享同一广播链路的场景，即多路访问问题。此时，MAC 协议的作用是协调多个节点对链路的访问，防止帧冲突并确保有序传输。
3. **可靠交付**
   某些链路层协议提供可靠交付服务，即保证每个网络层数据报都能无差错地通过链路层传输。这与运输层如 TCP 的可靠交付机制类似，通常通过确认 ACK 和重传机制实现。
   链路层的可靠交付主要用于高误码率的链路，如无线链路，其优势在于能够在错误发生的本地链路上及时纠正，避免触发端到端的重传，从而提升效率。
   然而，在误码率极低的有线链路，如光纤、同轴电缆或高质量双绞线，链路层可靠交付往往被视为不必要的开销。因此，许多现代有线链路层协议如以太网并不提供此项服务。
4. **差错检测与纠正**
   由于信号衰减和电磁干扰，帧在传输过程中可能出现比特错误。为了避免转发含错的数据，大多数链路层协议都包含差错检测机制。
   具体实现方式是：发送方在帧中附加差错检测比特，如 CRC 校验码，接收方则利用这些信息验证帧的完整性。与网络层和运输层使用的简单校验和如 IP 或 TCP 校验和相比，链路层的差错检测通常更强大，并由硬件高效实现。
   差错纠正则更进一步，不仅能够检测错误，还能定位并修正帧中的错误比特。不过，差错纠正机制较为复杂，通常仅在特定高误码环境中使用，如卫星或深空通信。

### 主机的网络层和链路层
与路由器不同，主机既不参与分组转发，也不承担网络中继功能，因此其网络层和链路层的实现均围绕“端系统通信”这一目标设计，从而与路由器存在显著差异。

- **网络层**完全由操作系统中的软件实现，运行在主机的主 CPU 上。它仅负责构造或解析本机收发的 IP 数据报，不执行任何转发操作。
- **链路层**则主要实现在**网络适配器**（即网卡）中。适配器的核心是链路层控制器，它通常是一个实现了多种链路层服务的专用芯片，以硬件方式高效完成成帧、链路接入、差错检测等底层操作。不过，链路层并非纯硬件实现，诸如设置帧头地址、触发发送、处理接收中断等高层控制逻辑，仍由运行在主机 CPU 上的驱动程序中完成。

因此，主机的链路层是**硬件与软件的结合体**：硬件处理高频、时序敏感的底层任务，软件则负责与操作系统及上层协议栈的交互。这种协同设计在保证性能的同时，也保留了必要的灵活性。

相比之下，路由器的网络层和链路层都面向转发优化，链路层实现在线路卡的专用硬件中，网络层也常由硬件加速以实现高效转发。而主机的协议栈则专注于端到端通信，网络层纯软件、链路层软硬协同，两者设计目标与实现方式迥然不同。

## 差错检测和纠正技术
为了保护要传输的数据，发送端会在原始数据 $D$（包括网络层数据报和链路层首部中的地址、序号等字段）后附加一组**差错检测与纠正比特**（Error-Detection and Correction, EDC）。整个组合（$D$ 加上 EDC）构成一个完整的帧，被发送到接收端。

在接收端，收到的是可能因传输错误而改变的版本 $D'$ 和 $EDC'$。接收方的任务是根据 $D'$ 和 $EDC'$，判断原始数据 $D$ 是否在传输中发生了差错。

需要特别注意的是：我们关心的是“**是否检测到差错**”，而不是“**是否发生了差错**”。因为差错检测机制并不能保证发现所有错误，即使使用了 EDC，仍可能存在**未检出差错**，即接收方误以为数据正确，并将其交付给上层。为此，我们选择的差错检测方案应使这类事件的概率极低。

通常，差错检测或纠正能力越强（即未检出错误的概率越小），所需的 EDC 比特越多，计算开销也越大。因此，实际设计需在可靠性与效率之间取得平衡。

### 奇偶校验
最简单的检测手段是**奇偶校验**。假设要发送的数据 $D$ 包含 $d$ 个比特。在**偶校验**方案中，发送方附加一个校验比特，使得整个 $d+1$ 比特（数据加校验位）中“1”的总数为偶数；奇校验则使“1”的总数为奇数。接收方只需统计收到的 $d+1$ 比特中“1”的个数即可。如果使用偶校验却得到奇数个“1”，说明传输中发生了奇数个比特错误，差错可被检测到。

但这种方法有一个明显缺陷。如果发生偶数个比特错误，奇偶校验将无法察觉。如果我们假设比特错误概率低且相互独立，那么多比特错误很少见，但实际链路中的错误常以“突发”形式出现（多个相邻比特同时出错），此时单比特奇偶校验的漏检率可能高达 $50\%$。因此，我们需要更可靠的机制。

一种自然的改进是**二维奇偶校验**。通过将数据比特排列成一个$ i$ 行 $j$ 列的矩阵，并且对每一行和每一列分别计算奇偶校验位，可以增强检验能力。这种方案不仅能检测多个比特错误，还能纠正单个比特错误。当某一位出错时，其所在行和列的校验都会失效，接收方通过交叉定位即可确定出错位置并修正。此外，二维奇偶校验还能检测任意两个比特的错误，但不能纠正。

这种在接收端直接纠正错误的能力称为**前向纠错**（Forward Error Correction, FEC）。FEC 的优势在于无需请求重传，避免了等待重传所需的往返时延，特别适用于实时应用或高延迟链路（如卫星通信）。在实际网络中，FEC 既可以单独使用，也可与基于确认/重传的链路层 ARQ 机制（ARQ 机制和可靠数据传输原理类似）结合，以兼顾效率与可靠性。

### 检验和方法
稍微复杂一些的差错检测方法是**检验和技术**。其做法是将数据划分为若干固定长度的整数（如 16 位），发送方对这些整数求和并取反码，将结果作为检验和字段。第三章介绍的 UDP 检验和正是采用这一机制。接收方收到数据后，将所有字段（包含检验和）再次相加并取反码；若结果不是全 1，则说明传输过程中出现了差错。

检验和的计算代价很低，例如 TCP 和 UDP 只使用 16 比特的简单加法反码校验。相比之下，链路层常用的**循环冗余校验**（Cyclic Redundancy Check, CRC）能够提供更强的差错检测能力，但其按位移位和异或的运算模式在通用 CPU 上难以并行加速，软件实现开销明显更高。由于运输层的校验由主机 CPU 的软件执行，必须采用轻量级、易于流水化的操作，因此选择了简单的检验和；而链路层的 CRC 则由网卡内的专用硬件电路完成，几乎不增加额外成本，却能高速处理复杂运算，从而提供更强的保护。

因此，检验和适合软件快速处理，CRC 适合硬件高效实现，两者的选择反映了不同协议层对性能与可靠性的权衡。

### 循环冗余检验
如今在网络中广泛使用的差错检测技术基于 CRC 编码，也被称作多项式编码，因为该编码将要发送的比特串看作系数为 0 和 1 的一个多项式，对比特串的操作被视作多项式算术。

CRC 的基本思想是：发送方将待发送的 $d$ 比特数据 $D$ 附加 $r$ 个校验比特 $R$，使得组合后的 $d+r$ 比特序列能被一个双方预先约定的 $r+1$ 比特生成多项式 $G$（最高位为 1）整除（使用模 2 除法，即无进位、无借位的二进制除法）。

接收方收到数据后，用同样的 $G$ 去除整个 $d+r$ 比特序列。如果余数为 0，认为无差错；否则，判定发生了传输错误。

所有 CRC 运算基于模 2 算术，因此加法和减法等价于按位异或 XOR。例如：

$$1011 \oplus 0101 = 1110$$

校验比特 $R$ 的计算方法很简单：将原始数据 $D$ 左移 $r$ 位，即 $D \cdot 2^r$，再用 $G$ 做模 2 除法，所得余数即为 $R$。

一个广泛使用的标准是 CRC-32，其生成多项式为 32 位，在以太网等 IEEE 链路层协议中被采用。这类 CRC 能检测：

- 所有长度不超过 32 比特的突发差错；
- 所有奇数个比特的错误；
- 更长突发差错的被检出概率也高达 $1 - 0.5^{32}$，几乎可以视为可靠。

由于 CRC 运算规则固定且适合并行处理，现代网卡通常用专用硬件高效实现，因此链路层普遍采用 CRC 而非更简单的检验和。

## 多路链路访问协议
如前所述，网络链路可以分为点对点链路和广播链路。许多链路层协议为点对点链路设计，如点对点协议（point-to-pointprotocol, PPP）和高级数据链路控制（high-level data link control, HDLC）。广播链路则允许多个节点共享同一个通信信道：当任一节点发送一个帧时，该帧会被信道广播，所有其他节点都能接收到。以太网就是一种典型的广播链路技术。

需要注意的是，链路层的广播能力常被上层协议所利用。例如，IP 层的**受限广播**在本地网络中发送时，就依赖链路层广播机制（如以太网的 MAC 广播地址）将数据报送达同一链路上的所有主机。但受限广播属于网络层概念，其作用范围仅限于本地网络，且由路由器阻断，与链路层的广播信道本身属于不同层次。

本节聚焦于广播链路中多个节点对共享信道的协调访问，即**多路访问问题**。由于广播信道广泛用于局域网，我们也将简要探讨多路访问机制在局域网中的实际应用。

由于广播链路上的所有节点都能发送帧，多个节点可能同时传输。当这种情况发生时，这些帧在所有接收方处相互干扰，即发生**碰撞**。碰撞会导致所有相关帧无法被正确接收，信号彼此混叠，造成传输失败。相应地，碰撞期间的信道时间被浪费。如果多个节点频繁发送，碰撞将大量发生，导致信道带宽严重浪费。

因此，当多个节点处于活跃状态时，必须通过某种方式协调它们的传输，以确保信道有效工作。这一任务由**多路访问协议**完成。尽管已提出众多多路访问协议，但基本可归为三类：**信道划分协议**、**随机接入协议**和**轮流协议**。接下来的三小节将分别介绍这三类协议。

理想的多路访问协议应具备以下几个关键特性（假设广播信道速率为 $R$ bps）：

1. **单节点效率**：当只有一个节点发送时，其吞吐量应达到 $R$ bps；  
2. **公平共享**：当有 $M$ 个节点同时发送时，每个节点应获得平均 $\frac{R}{M}$ bps 的吞吐量（不要求瞬时速率恒定，但长期平均应满足）；  
3. **去中心化**：协议不应依赖单一主控节点，避免单点故障导致系统失效；  
4. **实现简单**：协议应结构简洁，便于低成本实现。

### 信道划分协议
在最初讨论网络核心的电路交换时，我们就提到时分多路复用（TDM）和频分多路复用（FDM）这两种用于在所有共享信道的节点之间划分广播信道带宽的技术，现在看来，他们毫无疑问属于信道划分协议。

TDM 将时间划分为周期性的帧，每个帧再分为 $N$ 个时隙，分别分配给 $N$ 个节点。当某个节点有数据要发送时，只能在分配给它的固定时隙内传输。这种方式完全避免了碰撞，并保证每个节点获得平均 $R/N$ bps 的带宽。但其缺点也很明显：即使只有一个节点有数据发送，它仍被限制在 $R/N$ 的速率，并且必须等待轮到自己的时隙，造成带宽浪费和延迟。

FDM 则将信道的总带宽 $R$ 划分为 $N$ 个互不重叠的频段，每个节点独占一个频段。和 TDM 类似，FDM 也消除了碰撞并实现公平分配，但也同样存在带宽僵化的问题：节点无法在空闲时利用其他节点未使用的频段，导致效率低下。

第三种信道划分方式是**码分多址**（Code Division Multiple Access, CDMA）。与 TDM 和 FDM 不同，CDMA 不划分时间或频率，而是为每个节点分配唯一的编码。所有节点可同时使用整个信道带宽，通过编码区分彼此。若编码设计得当，即使其他节点同时在传输，接收方也能从混合信号中正确提取目标发送方的数据。CDMA 具有良好的抗干扰能力，常用于无线通信。由于其与无线信道密切相关，具体细节将在后续章节讨论。

### 随机接入协议
另一类多路链路访问协议是随机接入协议，此时传输节点总是以信道全速率传输数据。当发生碰撞时，节点会等待一个随机时延后重传，直到成功为止。由于各节点独立选择随机时延，某个节点可能选到较小的时延值，从而率先成功传输。最常用的随机接入协议包括 ALOHA 协议和 CSMA 协议，以太网就是一种 CSMA 协议。

1. 时隙 ALOHA
   时隙 ALOHA 是最简单的随机接入协议之一。其基本假设如下：

   - 所有帧长度相同，均为 $L$ 比特；  
   - 时间被划分为固定长度的时隙，每个时隙持续 $L/R$ 秒（即刚好够发送一帧）；  
   - 节点只能在时隙起点开始发送；  
   - 所有节点同步，知道每个时隙的起始时刻；  
   - 若一个时隙中有两个或更多帧同时发送，则发生碰撞，所有节点在该时隙结束前能检测到。

   协议运行规则很简单：  
   - 当节点有帧要发送时，它等到下一个时隙开始并完整发送该帧；  
   - 若未发生碰撞，发送成功；  
   - 若发生碰撞，节点在后续每个时隙以概率 $p$ 重传该帧，直到成功为止。各节点独立决定是否重传。

   时隙 ALOHA 具有若干优点，比如当只有一个活跃节点时，可独占信道，以全速率 $R$ 传输。其次，ALOHA 是完全分布式的，无需中心协调，而且实现非常简单。但它也存在局限，首先需要全局时隙同步，且在多节点活跃时效率受限。

   具体来说，我们将协议的**效率**定义为：在大量节点且每个节点总有帧待发的稳态下，**成功时隙**（恰好一个节点发送）所占的长期比例。可以看出，这种情况下，时隙 ALOHA 的最大效率为 $Np(1-p)^{N-1} \leq (\frac{N-1}{N})^{N-1} \leq \frac{1}{e} \approx 0.37$，即最多只有 37% 的时隙用于有效传输。其余时隙中，约 37% 为空闲，26% 发生碰撞。

   这意味着，即使物理信道速率为 $R$ bps，网络长期能够稳定提供的有效吞吐量最高也只能达到约 $0.37R$ bps。造成这一显著限制的根源在于随机重传机制允许节点在任意时刻独立发送数据导致了帧间高度重叠，从而引发大量冲突，而冲突后的退避以及帧间不受控的空闲时段又进一步拉低了整体利用率。

2. ALOHA
   时隙 ALOHA 要求所有节点在时间上严格同步，只能在时隙起点发送。而最早提出的 ALOHA 协议是**纯 ALOHA**，它完全不需要同步，是一种更简单的分布式方案。

   在纯 ALOHA 中，节点一旦有帧要发送，就立即完整地将其传入信道。如果发生碰撞，节点会在传完该帧后，等待一个帧传输时间，然后以概率 $p$ 重传，否则继续等待并重试。

   由于发送时机不受时隙限制，一个帧的传输可能与前后各一个帧时间内的其他传输发生重叠。因此，成功传输的条件比时隙 ALOHA 更严格。事实上，纯 ALOHA 的最大效率仅为 $Np(1-p)^{2(N-1)} \leq \frac{1}{2e} \approx 18.5\%$，正好是时隙 ALOHA 效率的一半。

   这一性能损失，正是完全去同步化、无需协调所付出的代价。

3. CSMA
   在两种 ALOHA 协议中，节点在发送数据时不会检查信道是否被占用，即使发生碰撞也会将整个帧发送完毕。协议完全依赖事后重传来解决冲突，因此信道利用率受限。如果能让节点在发送前获取信道上的活动信息并依此做出调整，想必整体性能将显著改善。

   相比之下，更高效的多路访问方式遵循两项关键机制：  
   1. **载波侦听**：节点在发送前先监听信道，如果信道处于忙状态，则等待其变为空闲后再开始发送。  
   2. **碰撞检测**：节点在发送期间持续监测信道状态，如果出现干扰并判断发生了碰撞，则立即中止发送，并在等待一个随机退避时间后重新尝试发送。

   这两条规则构成了**载波侦听多路访问**（Carrier Sense Multiple Access, CSMA）和**带碰撞检测的CSMA**（CSMA with Collision Detection, CSMA/CD）协议的基础。

   之所以需要碰撞检测，是因为即使使用载波侦听，碰撞仍可能发生，原因在于信号在信道中传播需要时间。例如，当一个节点开始发送时，远处的节点可能尚未收到该信号，因而误判信道为空闲，也发起传输。这种由**信道传播时延**引起的“侦听盲区”，是 CSMA 类协议无法完全避免碰撞的根本原因。传播时延越长，发生此类碰撞的可能性就越大。

4. CSMA/CD
   在基本的 CSMA 协议中，节点即使发生碰撞也会将整个帧发送完毕。而 **CSMA/CD** 引入了碰撞检测机制，让节点在发送过程中也持续监听信道，一旦发现碰撞就立即终止发送，从而避免继续传输已无效的帧并减少带宽浪费。如图所示，碰撞检测明显可以改善协议的性能：
   <figure style="text-align: center;">
   <img src="/illustrations/计网笔记6/1.png" alt="碰撞检测带来的改善" width="80%">
   <figcaption>碰撞检测带来的改善</figcaption>
   </figure>

   从节点中网络适配器的角度看，CSMA/CD 的工作流程如下：  
   1. 适配器从网络层获取数据报，封装成帧并存入缓存；  
   2. 若侦听到信道空闲，立即开始发送；若信道忙，则等待至空闲；  
   3. 发送过程中持续监测信道是否有其他信号；  
   4. 若完整发送未检测到干扰，则传输成功；若检测到干扰，立即停止发送；  
   5. 停止后，等待一段**随机时间**，再返回步骤 2 重试。

   采用**随机退避**而非固定等待时间，是为了避免碰撞节点反复同步重传。但退避时间的范围需要动态调整：碰撞少时退避短，以减少空闲；碰撞多时退避长，以降低冲突概率。

   为此，协议采用了与 TCP 拥塞控制中指数退避类似的**二进制指数后退算法**。其基本思想是：每发生一次碰撞，重传前的随机等待窗口扩大一倍。具体来说，在第 n 次碰撞后，节点从 0 到 $2^n − 1$ 的范围内随机选取整数 K，再等待 K 个基本时隙后重试。对于以太网，一个节点等待的实际时间是 $K\cdot 512$ 比特时间。当然，为了避免无限重试，还通常会对重试次数设置上限，一般不超过 10 次。

   此外，新帧的发送也总是从零退避开始，不继承之前碰撞的历史。这意味着当多个节点因碰撞而退避时，一个新到达的帧可能立即获得信道，从而提高整体效率。

   通过结合**载波侦听**、**碰撞检测**和**自适应退避**，CSMA/CD 在共享信道上实现了较高的吞吐效率与公平性。

   我们将 **CSMA/CD 效率**定义为：在大量节点且每个节点总有帧待发的稳态下，帧在信道中无碰撞地运输的那部分时间在长期运行时间中所占的比例。令 $d_{prop}$ 表示信号能量在任意两个适配器之间传播所需的最大时间，$d_{trans}$ 表示把一个最大长度的以太网帧“推入”信道所需的时间，经过复杂的推导可以得出效率约为 $\frac{1}{1+\frac{5d_{prop}}{d_{trans}}}$。从中可以看出，当 $d_{prop}$ 接近 0 时，效率接近 1，和我们直觉一致，如果传播时延为 0，碰撞的节点会立刻终止而不会浪费信道。当 $d_{trans}$ 很大时，效率也接近 1，同样符合直觉，当一个帧取得了信道后将占据信道很长时间，因此大多数时间都会有效地工作。

### 轮流协议
前面提到，理想的多路访问协议应满足单节点效率和公平共享两个特性，ALOHA 和 CSMA 满足第一条，但无法保证公平共享，因此不满足第二条。这促使研究者提出了**轮流协议**，通过有序访问避免冲突。

最简单的一类是**轮询协议**。该协议由一个主节点按照固定顺序依次轮询所有节点，询问其是否有数据要发送，并在需要时分配可发送的最大帧数。在这期间，主节点通过检测信道上是否无信号来判断某节点何时完成发送。由于各节点只有在被轮询到时才能发送，本质上不会产生碰撞，也不会出现无谓的空闲时隙，因此信道利用率较高。然而该机制也有两个主要缺点：
- **轮询开销**：即使只有一个活跃节点，它也必须等待主节点轮询完所有其他节点，导致实际吞吐量低于 $R$；  
- **单点故障**：主节点一旦失效，整个信道将无法工作。

另一类是**令牌传递协议**。该协议中，系统中无主节点，而是让一个特殊控制帧——“令牌”——按固定顺序在节点间循环传递。节点只有在持有令牌时才可发送数据，发送完毕后需立即将令牌交给下一个节点。该机制同样实现了无碰撞且高效的通信，并具备去中心化特性；但其缺点是任一节点若发生故障或未按时转交令牌，都可能使令牌链中断，从而导致整个系统停滞，因此必须配套故障检测与恢复策略。

这两类轮流协议通过协调访问顺序，实现了比随机接入更高的信道利用率和公平性，代价则是引入了控制开销或对节点可靠性的更高要求。

### DOCSIS：用于电缆因特网接入的链路层协议
电缆接入网是一个很好的综合案例，因为它在一个系统中同时用到了三类链路访问协议。

电缆接入网通过同轴电缆将大量用户调制解调器连接到一个中心设备，即**电缆调制解调器端接系统**（CMTS）。上下行通信使用 FDM 划分为多个频率信道，上下行通道均为广播信道。

- 下行（CMTS → 用户）虽然是广播式的，但因为只有 CMTS 发送，不存在多路访问问题。  
- 上行（用户 → CMTS）则因为多个调制解调器共享同一频率信道，因此存在典型的多路访问挑战。

为协调上行传输，系统将每个上行信道划分为时间间隔，每个间隔包含若干微时隙。CMTS 通过下行控制消息（称为 MAP 报文）集中分配微时隙，明确指定哪个调制解调器可以在何时发送。这种方式本质上是一种集中式的轮流协议，可完全避免碰撞。

CMTS 通过一组专用的请求时隙获知各调制解调器的发送需求。它要求调制解调器在这些时隙中发送带宽请求，请求采用随机接入方式，因而可能发生碰撞。由于调制解调器既无法侦听上行信道，也无法检测碰撞，它只能通过是否收到 CMTS 的确认来判断请求是否成功；若未收到确认，则视为发生碰撞，并按照二进制指数后退算法在后续机会中重新发送请求。

此外，在网络负载较低时，调制解调器可以在请求时隙中直接发送数据，而无需经过请求——分配过程，从而进一步提升整体效率。这种做法在思想上与某些应用层协议中“在握手阶段提前携带数据以降低延时”的策略类似，尽管二者的底层机制并不相同。

综上，电缆接入网巧妙融合了
- FDM（划分上下行频段） 
- TDM/集中调度（CMTS 分配微时隙）
- 随机接入（用于初始带宽请求）

因此，电缆接入网常被视为多种多路访问机制在同一体系结构中分层配合的代表性案例。

## 交换局域网
本节转向交换式局域网，在这种网络结构中，链路不再由所有节点共享，而是通过交换设备连接成一系列点到点链路。交换机属于链路层设备，其处理与转发的基本单位是链路层帧。与网络层路由器不同，交换机既不识别 IP 地址，也不运行诸如 RIP 或 OSPF 等路由协议，与之对应的是，它们依据链路层地址（即 MAC 地址）来决定帧的转发方向，并通过内部的转发表实现高效交换。

本节将首先介绍链路层的寻址机制，接着讨论当前应用最广泛的以太网协议，随后分析链路层交换机的结构与工作原理，最后说明如何利用交换机构建层次化且可扩展的局域网。

### 链路层寻址和 ARP
#### MAC 地址
链路层地址与 IP 地址一样，也是分配给网络接口的，而不是分配给整台主机或路由器。因此，多接口设备会相应地具有多个链路层地址。但与 IP 地址不同的是，链路层交换机的接口并不配置 MAC 地址。交换机在链路层中以透明方式转发帧，不作为通信端点参与寻址，因此无需拥有自己的链路层地址。

链路层地址有多种叫法：LAN 地址、物理地址或 MAC 地址。其中 **MAC 地址** 是最常用的术语，之后将统一使用这一名称。

在大多数局域网（如以太网和 802.11 无线网）中，MAC 地址长度为 48 比特（即 6 字节），共可分配 $2^{48}$ 个唯一地址。通常以十六进制表示，例如 `5C-66-AB-90-75-B1`。虽然 MAC 地址原本设计为全球唯一且永久固化，但现代操作系统允许通过软件修改（即“MAC 地址伪装”）。不过为便于理解，我们假设每个适配器的 MAC 地址是固定且唯一的。

这种唯一性得以实现，是因为 **IEEE 统一管理 MAC 地址空间**。厂商在生产网卡前，需向 IEEE 申请一个唯一的 24 位组织标识符（OUI），作为 MAC 地址的前半部分，后 24 位由厂商自行分配，确保其生产的每个适配器地址唯一。

与 IP 地址不同，MAC 地址是**扁平的、无层次结构的**，且不会随设备位置变化。例如，无论笔记本电脑接入哪个网络，其以太网接口的 MAC 地址始终不变，智能手机的 Wi-Fi MAC 地址也保持一致（当然现在连 WLAN 一般都是使用随机 MAC 地址了）。相比之下，IP 地址具有明显的网络/主机层次结构，当设备更换网络时，通常需要分配新的 IP 地址。可以将 MAC 地址类比为“身份证号”（固定、唯一、全球有效），而 IP 地址则类似“邮政地址”（随位置变化、具有层级结构）。

当适配器要发送帧时，会将目的适配器的 MAC 地址填入帧头部，并将帧发送到局域网。由于交换机可能广播帧（如 MAC 地址未知时），或无线网络（如 802.11）本身支持广播，适配器可能收到并非发给自己的帧。此时，它会检查帧中的目的 MAC 地址：  
- 若匹配自身地址（或为广播地址），则提取内部的网络层数据报，向上层传递；  
- 否则，直接丢弃该帧，不产生中断或上送。

有时，发送方的确希望局域网上所有设备都接收该帧，此时使用 **MAC 广播地址**：`FF-FF-FF-FF-FF-FF`。所有适配器都会接收并处理此类帧。

综上，MAC 地址是链路层通信的基础，提供本地唯一标识，支持单播与广播，且与上层 IP 地址协同工作，共同实现端到端通信。

#### 地址解析协议
由于网络中同时存在**网络层地址**和**链路层地址**，需要一种机制在二者之间转换。在因特网中，这项任务由**地址解析协议**（Address Resolution Protocol, ARP）完成。

考虑一个简单场景：两台主机位于同一子网内，每台主机和路由器都有一个单一的 IP 地址和单一的 MAC 地址。当主机 A（IP: 222.222.222.220）要向主机 B（IP: 222.222.222.222）发送 IP 数据报时，它必须知道 B 的 MAC 地址，才能构造链路层帧。但 IP 数据报本身只包含 IP 地址，因此需要 ARP 来获取对应的 MAC 地址。

每台主机和路由器都维护一张 **ARP 表**，记录**本子网**内已知的 IP 地址到 MAC 地址的映射，并为每个条目设置一个 TTL（通常约 20 分钟）。如果发送方的 ARP 表中已有目标 IP 的条目，可直接使用；否则，就需发起 ARP 查询。

在同一子网内，ARP 查询过程如下：  
1. 发送方构造一个 **ARP 请求分组**，包含自己的 IP 和 MAC 地址，以及目标 IP 地址；  
2. 该分组被封装在链路层帧中，**目的地址设为 MAC 广播地址**（`FF-FF-FF-FF-FF-FF`）；  
3. 帧被广播到整个子网，所有设备都能收到；  
4. 每台设备将 ARP 分组上交给其 ARP 模块，检查其中的目标 IP 是否与自己匹配；  
5. 匹配的设备会**单播回复一个 ARP 响应分组**，包含自己的 MAC 地址；  
6. 发送方收到响应后，更新 ARP 表，并用该 MAC 地址发送真正的数据帧。

ARP 有两个重要特点：  
- **查询用广播，响应用单播**：广播确保所有设备都能收到请求，而单播响应避免不必要的网络开销；  
- **即插即用**：ARP 表自动建立和维护，无需人工配置，过期条目会自动删除。

同为解析协议，与带缓存的 DNS 类似，ARP 也通过本地表缓存地址映射并设置 TTL 实现自动过期，以减少查询开销；但不同之处在于，ARP 仅在本地子网内将 IP 地址解析为 MAC 地址，查询时使用链路层广播，而 DNS 在全球范围内将域名解析为 IP 地址，通常通过单播向 DNS 服务器发起请求。

最后，我们来讨论一下 ARP 的协议层级。ARP 封装在链路层帧中，但其内容同时包含 IP 地址和 MAC 地址，横跨网络层与链路层。因此，ARP 并不严格属于某一层，这体现了实际网络协议常有的“跨层”特性，现实中的协议往往比理想分层模型更灵活，也更复杂。

#### 发送数据报到子网外
前面我们了解了主机在同一子网内通信时 ARP 的工作方式，现在考虑更常见的主机向不同子网的主机发送数据报的情况。

下图是一个不同子网间发送数据报的例子。假设主机 A（IP: 111.111.111.111）要向主机 B（IP: 222.222.222.222）发送数据报，而两者位于由一台路由器连接的两个不同子网中。此时，主机 A 不能直接将帧发给 B 的 MAC 地址，因为 B 不在本地链路范围内。如果这样做，本地网络中的所有设备都会因 MAC 地址不匹配而丢弃该帧，导致数据报无法送达。
<figure style="text-align: center;">
<img src="/illustrations/计网笔记6/2.png" alt="不同子网间发送数据报的例子" width="80%">
<figcaption>不同子网间发送数据报的例子</figcaption>
</figure>

此时主机 A 正确的做法应当是将数据报发给默认网关，也就是通往外部网络的路由器接口。在本例中，该接口的 IP 地址是 111.111.111.110。因此，主机 A 需要先通过 ARP 查询 111.111.111.110 对应的 MAC 地址（本例中为 E6-E9-00-17-BB-4B），然后将 IP 数据报封装在以该 MAC 地址为目的地址的帧中发送出去。

路由器收到帧后，将其传递给网络层。根据转发表，路由器确定该数据报应从其另一个接口（IP: 222.222.222.220）转发到目标子网。接着，该接口通过 ARP 获取主机 B 的 MAC 地址（49-BD-D2-C7-56-2A），再将数据报封装成新的帧，发送到目标子网。

由此可见，在跨子网通信中，ARP 仅用于解析本地链路上的下一跳地址（通常是路由器），而不是最终目的地的 MAC 地址。每一跳的转发都依赖于本地 ARP 解析，确保帧只在当前链路内有效传输。

### 以太网
以太之所以能成为如今事实上的有线局域网标准，不仅因为它成本低、结构简单、易于扩展，更关键在于其一直在不断提升速率并无缝兼容旧设备。

早期以太网采用同轴电缆总线结构，所有节点共享同一信道，只能依靠 CSMA/CD 来处理竞争与碰撞。后来虽然出现了星形拓扑的集线器，但集线器仅属于物理层设备，只会将接收到的比特放大后广播到所有端口，本质上仍是共享介质网络，无法消除冲突。直到链路层交换机出现后，以太网才迎来真正的转变：交换机在链路层根据 MAC 地址进行转发，将帧精准送往目标端口，还实现了点对点的全双工通信，发送与接收互不干扰，从根本上消除了共享信道带来的碰撞和无效广播。

总体来看，以太网的发展始终沿着“从共享到专用”的方向推进：最初的共享信道到集线器的广播式连接，再到交换机提供的点对点通信，整个体系逐步摆脱冲突和带宽竞争，形成如今高效而可扩展的局域网结构。

#### 以太网帧结构
在同一以太网中，两台主机通信时会通过帧来承载并传递 IP 数据报。以一台主机向另一台主机发送数据为例：发送方网卡（MAC 地址 AA-AA-AA-AA-AA-AA）会将 IP 数据报封装进以太网帧并发送出去；接收方网卡（MAC 地址 BB-BB-BB-BB-BB-BB）在收到帧后，将其中的数据报取出并交给网络层处理。以太网帧如图所示，一共 6 个字段：

<figure style="text-align: center;">
<img src="/illustrations/计网笔记6/2.png" alt="不同子网间发送数据报的例子" width="60%">
<figcaption>不同子网间发送数据报的例子</figcaption>
</figure>

- **前同步码**（8 字节）：帧起始标志。前 7 字节用于帮助接收方同步时钟，第 8 字节标志帧正式开始。
- **目的地址**（6 字节）：目标网卡的 MAC 地址。若为广播地址（FF-FF-FF-FF-FF-FF），所有设备都会接收。
- **源地址**（6 字节）：发送方网卡的 MAC 地址。
- **类型字段**（2 字节）：标识数据字段所承载的上层协议（如 IP、ARP、IPX 等），用于在接收端将数据正确交给对应的网络层协议。
- **数据字段**（46–1500 字节）：承载网络层数据报（如 IP 包）。若数据报小于 46 字节，需填充至 46 字节；若超过 1500 字节（以太网 MTU），则需在网络层分片。接收方通过 IP 首部中的长度字段去除填充。
- **CRC**（4 字节）：用于检测帧在传输中是否出错。若校验失败，帧被丢弃。

如前所述，以太网向网络层提供**无连接、不可靠**的服务：  
- **无连接**：发送前无需建立连接，也不与接收方握手，类似于 IP 和 UDP。  
- **不可靠**：接收方不发送确认（ACK）或否定确认（NAK）。若 CRC 校验失败，帧直接被丢弃，发送方对此毫不知情。

这种设计使以太网简单、高效且成本低，但意味着链路层不保证数据一定到达。是否感知到数据丢失，取决于上层协议：  
- 若使用 **UDP**，应用会直接看到数据缺失；  
- 若使用 **TCP**，传输层会通过重传机制掩盖链路层的丢包，对应用透明。

因此，以太网专注于高效传输，而可靠性由更高层协议按需提供。

#### 以太网技术
虽然我们日常口中的“以太网”常被当作某个具体的协议，但实际上它涵盖了多种物理层和链路层的技术标准，如 10BASE-T、100BASE-T、1000BASE-LX、10GBASE-T 等。这些看似繁杂的名称其实遵循统一的命名规则：
- 开头的数字（10、100、1000、10G）表示速率（单位为 Mbps 或 Gbps）；  
- “BASE”表示**基带传输**（即该链路只承载以太网流量）；  
- 后缀（如 T、LX、FX）表示所用的物理介质，“T”通常指双绞铜线，其他字母代表不同类型的光纤或电缆。

正如之前所说，在当今的交换式以太网中，CSMA/CD 已经不再使用，传统 MAC 协议的大部分机制也随之淡出，只保留了最基本的功能，如帧格式和地址字段。尽管物理介质、传输速率（从 10 Mbps 提升到 100 Gbps 乃至更高）以及网络拓扑经历了巨大变化，以太网的帧格式却始终保持一致。正是这一稳定的核心设计，使得不同代际的以太网设备能够长期兼容并顺利互通。从这个意义上说，帧结构才是以太网真正的“不变量”，只要仍采用这一格式，它就属于以太网。

#### 链路层交换机
到目前为止，我们对交换机的具体功能和工作机制仍缺乏清晰认识。实际上，交换机的核心任务非常明确，即接收链路层帧，并根据目标地址将其转发到合适的输出端口。接下来将对这一转发过程做更具体的说明。

交换机对子网中的主机和路由器是**透明的**。当主机或路由器发送帧时，只需填写目标主机的 MAC 地址，而不会填写交换机的地址；发送方也无需关心帧将如何被交换机转发，整个过程对其而言是不可见的。

由于不同输入端口的帧可能同时被转发到同一输出端口，输出链路的瞬时负载可能会超过其带宽。为了解决这一问题，交换机在每个输出接口都设置了缓存，用于暂存等待发送的帧，这一机制与路由器在网络层为数据报设置缓存的方式类似。

接下来，我们将深入探讨交换机的工作原理。
1. 交换机转发和过滤
   交换机的核心功能包括**过滤**和**转发**：  
   - **过滤**：决定是否丢弃一个帧；  
   - **转发**：决定将帧从哪个接口发出，并执行传输。

   这两项功能依赖于**交换机表**（也称 MAC 地址表）。表中包含部分（不必是全部）局域网内主机和路由器的条目，每个条目包括：  
   - MAC 地址；  
   - 对应的交换机接口；  
   - 条目创建的时间（用于老化过期）。

   当一个目的地址为 `DD-DD-DD-DD-DD-DD` 的帧从接口 $x$ 到达时，交换机会查询表，有三种可能情况：

   1. **表中无此地址**：交换机将帧**广播到除接收接口外的所有其他接口**（即泛洪），以确保帧能到达目标；
   2. **表中地址对应接口 $x$**：说明目标就在该接口连接的网段上，不需要向外转发，交换机**直接丢弃**（过滤）；
   3. **表中地址对应另一接口 $y$**：交换机将帧**转发到接口 $y$** 的输出缓存中。

   由此可见，只要交换机表准确完整，帧就能被精准送达，无需广播，这比集线器高效得多。
2. 自学习
   此前提到的交换机表并不是预先配置好的，而是交换机在运行过程中自行构建的。交换机的一个核心能力是能够**动态、自治地学习并维护这张地址表**，无需管理员手动配置或依赖额外协议。这种机制称为**自学习**，也是交换机高效转发的根本基础。其工作过程如下：

   1. 初始时，交换机表为空。  
   2. 每当从某个接口收到一个帧，交换机会记录：  
      - 帧的**源 MAC 地址**，  
      - 接收该帧的接口，  
      - 当前时间。  
      这样，交换机就知道该 MAC 地址位于哪个网段。随着各主机陆续发送数据，它们的地址会自动被学习并填入表中。  
   3. 老化机制：如果某个 MAC 地址在一段时间（称为老化期，如 60 分钟）内未作为源地址出现，交换机会自动将其从表中删除。这确保了设备更换或移动后，表项能及时更新。

   因此，交换机是真正的**即插即用设备**：管理员只需将主机或网段连接到交换机端口，无需任何配置，交换机就能自动学习网络拓扑并高效转发帧。

   此外，交换机端口支持**全双工通信**，即每个接口可同时发送和接收数据，进一步提升了性能。
3. 链路层交换机的特性
   与传统的总线或集线器式广播局域网相比，基于交换机的网络具有多项显著优势：

   - **消除碰撞**：交换机为每个端口提供独立的通信通道，帧在输出端口缓存后有序发送，**不会发生碰撞**。因此，所有链路带宽均可有效利用，网络总吞吐量可达各接口速率之和，性能远高于共享式广播网络。
   - **支持异构链路**：交换机将各端口隔离，允许不同链路以**不同速率**（如 10 Mbps、100 Mbps、1 Gbps）和**不同介质**（如双绞线、光纤）共存。这使得新旧设备可以无缝混合组网。
   - **便于管理与维护**：  
      - 交换机能检测异常行为（如某网卡持续发送无效帧），并**自动隔离故障端口**，无需人工干预；  
      - 单条链路故障（如网线断开）只影响对应设备，不会导致整个网络瘫痪；  
      - 交换机还可收集流量统计信息（如带宽使用、帧类型等），帮助管理员诊断问题、优化网络规划。

   这些特性使交换机不仅提升了性能，还大幅降低了网络管理的难度，因此成为现代局域网的基础设施。
4. 交换机与路由器的比较
   交换机和路由器都是存储转发设备，其中交换机工作在链路层，根据 MAC 地址转发帧，而路由器工作在网络层，根据 IP 地址转发数据报。尽管现代设备（如支持 OpenFlow 的交换机）能够跨层处理多种信息，但在传统网络架构中，两者仍各自承担不同的功能，并在各自的层面发挥优势。

   交换机和路由器各有优缺点。交换机的优势在于即插即用，不需要额外配置即可自动学习 MAC 地址；它只处理链路层头部，转发速度快、延迟低，并能隔离冲突域，让多个主机成对并行通信，从而显著提升局域网性能。但交换机也有局限，例如会转发所有广播帧，容易导致广播风暴；为了防止广播帧的循环，网络必须依赖生成树协议将拓扑限制为逻辑树形，从而无法充分利用冗余链路；此外，在大规模网络中，ARP 流量和地址表规模都会迅速增加，使扩展性受限。

   相比之下，路由器具有更强的控制能力。它会隔离广播域，不会转发链路层广播，从根本上抑制广播风暴；IP 地址具备层次结构，使路由器能够利用路由协议构建带冗余路径的任意复杂拓扑，并根据网络状态选择更优路径。不过，路由器需要手动配置，无法做到即插即用，而且需要解析网络层头部，处理开销比交换机更大，因此转发速度通常较低。

   在选择网络设备时，小型网络（几十到几百台主机）通常只需交换机即可，部署简单、成本低且性能良好。而在大型网络（如校园网或企业网）中，通常采用**交换机与路由器结合**的方式：交换机负责局域网内部高效通信，路由器用于连接不同子网，实现广播隔离并提供跨网段路由。简而言之，交换机用于“局域高效互联”，路由器用于“跨网智能互联”，两者互补，共同构建现代网络。

### 虚拟局域网
现代机构常采用层级交换结构，将各部门接入各自的交换机，再通过中心交换机互联。这种设计虽简单，但在实际中存在三个主要问题：

1. **缺乏流量隔离**：广播流量（如 ARP、DHCP）会泛洪到整个网络，不仅浪费带宽，还带来安全隐患——例如，敏感部门的通信可能被其他部门的嗅探工具捕获。  
2. **交换机使用效率低**：若部门规模小，单独部署交换机会造成端口浪费；若用一台大交换机集中接入，又无法隔离流量。  
3. **用户移动不便**：员工换部门时需重新布线；若属于多个部门，问题更复杂。

虚拟局域网（Virtual Local Area Network, VLAN）技术正是为解决这些问题而设计的。支持 VLAN 的交换机可以在同一台物理设备上划分**多个逻辑广播域**。例如，将部分端口划为“工程部 VLAN”，另一些划为“研发部 VLAN”。在同一 VLAN 内，主机可以自由通信；而不同 VLAN 之间默认隔离，就好像每个 VLAN 都拥有独立的交换机一样。

这种隔离既提升了性能（限制广播范围），也增强了安全性（阻止跨组监听）。而且，当用户更换部门时，只需在交换机上修改其端口所属的 VLAN，无需改动物理连接。

默认情况下，VLAN 之间不能直接通信。如果需要不同 VLAN 间互通，例如工程部访问研发部的服务器，必须通过三层设备（如路由器）进行转发。常见做法是将路由器连接到交换机端口，并将该端口配置为“VLAN 接口”，或者直接使用支持三层功能的交换机。这样，不同 VLAN 的流量通过路由器转发，在保持隔离的同时实现可控互通，逻辑上看起来是具有分离的经路由器连接的交换机。

当多个交换机都支持 VLAN 时，可以通过 **VLAN 干线**互联。干线端口能够承载多个 VLAN 的流量，并在以太网帧中插入 **802.1Q 标签**来标识帧所属的 VLAN。发送端交换机为帧打标签，接收端交换机去除标签，对终端设备完全透明。802.1Q 帧由标准以太网帧加上 4 字节的 VLAN 标签组成，该标签包含三个部分：**协议标识符**（Tag Protocol Identifier, TPID），固定十六进制值 0x8100；**标签控制信息**（Tag Control Information, TCI），包括 12 位的 VLAN 标识符；以及 **3 位优先权字段**，用于指示帧的优先级。

除了最常见的**基于端口**的 VLAN，还可以按照 **MAC 地址**、**IP 子网**或**协议类型**等方式划分，以适应不同管理需求。总体而言，VLAN 在无需增加物理布线的前提下，实现了逻辑隔离、灵活管理、安全增强和高效资源利用，是现代局域网设计的核心技术之一。

## 链路虚拟化
本章聚焦链路层协议，临近结尾时，值得回顾“链路”这一概念的演变。

起初我们将链路理解为连接两台主机的一段物理线路，但随着学习深入，会发现链路其实是一种更高层次的抽象：多台主机可以共享同一通信信道（如同轴电缆或无线频谱），而在现代以太网中，主机之间的可达性往往要经过多级交换机与 VLAN 等设施共同实现，因此链路不再对应某根具体线缆，而更像是一条由底层网络结构支持的**逻辑通信路径**。

但对主机而言，这些底层结构都是透明的，它始终只看到一个可用的**链路层信道**，并据此与其他主机通信。主机既无法也无需知道自己究竟位于单段局域网、多级交换结构，还是某个 VLAN 之中。这种“无感知”正体现了分层设计的优势，使得上层功能不必依赖底层网络的具体实现。

例如，当两台主机通过拨号调制解调器通信时，底层虽然是庞大而复杂的电话交换网络，但在因特网链路层的视角中，它被抽象成**一条简单的点对点链路**。这种处理方式体现了覆盖网络的思想，即上层将下层网络当作提供连接的“管道”，无需了解其内部结构与运行细节，从而保持体系结构的简洁与模块化。

下面介绍**多协议标签交换**（Multiprotocol Label Switching, MPLS）网络。与电路交换的电话网不同，MPLS 本质上是一种基于分组交换的**虚电路技术**，具有独立的帧格式和标签转发机制。虽然它处于链路层与网络层之间的过渡地带，但从因特网整体视角来看，它与电话网或交换式以太网的角色相似，都是为 IP 设备提供底层的链路层互联服务。因此，可将其理解为一种为上层隐藏内部结构、仅提供连通性的链路层技术。

### 多协议标签交换
MPLS 起源于 20 世纪 90 年代末，其设计目标是在不改变 IP 路由与寻址体系的前提下提升转发效率。它的核心思想是为数据包增加一个固定长度的标签，让中间设备依据标签而非 IP 地址进行快速转发。这样既保留了 IP 网络的灵活性，又获得了类似虚电路网络的高效转发性能。

在支持 MPLS 的网络中，数据帧的结构在链路层（如以太网）和网络层（IP）之间插入一个 4 字节的 **MPLS 标签头**。该标签由入口路由器（称为“标签边缘路由器”）分配，并由中间的“标签交换路由器”用于转发。这些路由器只需查找标签，无需解析 IP 首部或执行最长前缀匹配，从而简化转发过程。

但 MPLS 的真正优势并不在转发加速上（正如前文所说，现代硬件已使 IP 转发相当高效），它的价值体现在所提供的**高级流量管理能力**。通过为数据流分配不同的标签，网络运营者可以灵活控制路径选择、实现流量工程、保障关键业务质量，并在复杂拓扑中构建可控、可预测的转发行为。

- **流量工程**：
  传统 IP 路由通常只选择一条“最优”路径。而 MPLS 允许网络管理员显式指定多条路径。例如，去往同一目的地的流量可被分流到不同链路上，以避开拥塞、满足策略要求或优化资源使用。
- **快速故障恢复**：  
  可预先计算备用路径，当主链路故障时，流量能迅速切换到备份路径，减少中断时间。
- **虚拟专用网**（Virtual Private Network, VPN）：  
   服务提供商可利用 MPLS 在其公共骨干网上为不同客户构建彼此隔离的虚拟专用网。与局域网中的 VLAN 类似，MPLS VPN 让多个客户共享同一套物理基础设施，却拥有独立的逻辑网络环境；但 MPLS 的隔离基于标签与独立的虚拟路由表（VRF），能够跨越大规模的运营商路由器网络，并允许不同客户使用重叠的 IP 地址空间而互不干扰。对于企业而言，MPLS VPN 提供了安全、可控且可按需扩展的跨地域私网互联能力，让分支机构之间能够像处在同一个内网中一样通信。

总而言之，MPLS 可以看作是一种构建在 IP 网络之上的虚电路机制，对终端主机完全透明。IP 设备不需要感知 MPLS 的存在，它们会认为自己只是通过一条普通链路进行通信。从这个意义上说，MPLS 与以太网交换和 ATM 等技术类似，都是为 IP 层提供高效而可控的链路层互联服务。虽然内部机制较为复杂，但 MPLS 的核心思想十分明确，即通过简单的标签交换，让 IP 网络具备更灵活、更智能的转发能力。

## 数据中心网络
近年来，大型互联网公司（如谷歌、微软、亚马逊、Meta 等）构建了规模庞大的数据中心，每个数据中心容纳数万至数十万台服务器，支撑搜索、邮件、社交、电商等各类云服务。这些服务器通过**数据中心网络**相互连接，并与外部互联网互通。

虽然网络在数据中心总体运营成本中所占比例并不高，大约只有 15% 左右，但网络架构的设计与演进依然对整体性能和成本效益有着决定性的影响。

数据中心中的服务器通常采用“刀片”形式，密集安装在机架中，每个机架容纳 20 到 40 台主机。每台机架顶部配有一台 **机架顶部交换机**（Top-of-Rack, TOR），负责连接本机架内所有主机，并通过上行链路与其他 TOR 交换机或核心网络设备互联。目前，主机普遍以高速以太网（如 40 Gbps）接入 TOR 交换机，并分配内部 IP 地址。

数据中心网络需处理两类流量：  
1. **外部流量**：用户与数据中心之间的通信，由**边界路由器**连接公共互联网；  
2. **内部流量**：服务器之间的通信，用于分布式计算、数据同步等，通常占总流量的绝大部分。

因此，数据中心网络设计的核心，就是高效、可扩展地互联所有机架，并将其连接到边界路由器。这一问题已成为现代网络研究的重要方向，推动了从拓扑结构到协议优化的大量创新。

### 负载均衡
大型云数据中心（如谷歌、微软）同时运行搜索、邮件、视频等多种服务。每种服务对外使用一个公共 IP 地址，用户请求首先到达**负载均衡器**。

负载均衡器的作用是：  
- 根据后端主机的当前负载，将请求智能分配给最合适的服务器；  
- 所有响应也经由它返回给用户，形成统一的通信入口。

由于负载均衡器基于**目的 IP 地址和端口号**（即传输层信息）做转发决策，常被称为“**第四层交换机**”。此外，它还提供类似 NAT 的功能：将外部 IP 映射到内部主机的私有地址，既隐藏了数据中心内部结构，也增强了安全性。

### 层级网络架构
小型数据中心（数千台主机）可用简单拓扑：一台边界路由器、一台负载均衡器，以及若干机架通过单台交换机互联。

但大型数据中心（数万至数十万台主机）必须采用**多层交换架构**：  
- 顶层是边界路由器，连接外部互联网；  
- 下层依次为接入路由器、多级交换机（第一层、第二层等）；  
- 每个机架通过 TOR 接入网络；  
- 所有链路普遍采用以太网，介质包括铜缆和光纤。

这种层级设计支持大规模扩展，同时通过**冗余设备和链路**提升可靠性。为减少广播风暴，每个子网还会进一步划分为多个 **VLAN**（通常每 VLAN 数百台主机）。

### 带宽瓶颈问题
尽管层级架构解决了规模问题，但**跨机架通信带宽受限**仍是关键挑战。

假设主机以 1 Gbps 链路接入 TOR 交换机，而交换机之间则通过 10 Gbps 链路互联。那么，当多个跨机架流量同时占用同一条上行链路时，每条流的可用带宽会显著下降，例如有四十条并发流共享一条 10 Gbps 链路时，每条流只能获得约 250 Mbps，远低于主机网卡的能力。这种瓶颈在分布式计算场景中尤其突出，因为搜索引擎和云计算等应用往往依赖跨机架的高带宽通信。虽然提升交换机速率能够缓解问题，但相关成本非常高。

因此，现代数据中心不仅关注拓扑扩展，更追求**高带宽、低阻塞的网络架构**，以支撑灵活、高性能的云服务部署。