---
title: CS143-Week6：Cool Type Checking & Runtime Organization
date: 2025-08-16 12:22:55
categories: CS143
description: 
tags: [编译原理, Linux, CS143, 语义分析, 自类型, 运行时系统]
---
# Cool 的类型检查
## 静态类型与动态类型
**静态类型（Static Typing）** 是一种编译时的类型系统，变量或表达式的类型在编译阶段就已经确定，编译器会在此时进行类型检查，我们之前讲的就是这种类型系统。这种方式能够提前发现错误，但也可能拒绝一些在运行时实际上可以正确执行的程序。换句话说，静态类型刻画的是**变量或表达式在所有可能执行路径下所能具有的类型集合**（编译期约束）。

**动态类型（Dynamic Typing）** 在这里有两层含义：  
1. **静态类型语言中的运行时对象类型**：变量的静态类型固定，但它所引用的对象在运行时可能是静态类型的子类，决定运行时行为，这就是所谓的动态类型。例如在 Java 中：
```java
Animal a = new Dog(); // 变量 a 的静态类型是 Animal，动态类型是 Dog
a = new Cat();        // 动态类型变为 Cat，但静态类型仍是 Animal
```

2. **动态类型语言中的变量绑定类型**：变量本身没有固定类型，运行时绑定什么对象，类型就是什么，类型检查完全在运行时进行。例如 Python：
```python
x = 5      # 运行时类型是 int
x = "hi"   # 运行时类型变为 str
```

**区别**：静态类型语言变量的静态类型固定，也即类型检查时类型固定，但运行时对象类型可变化（向下转型受限）；动态类型语言变量没有固定类型，完全由运行时决定。

类型系统的健全性保证了静态类型与动态类型的一致性：对于任意表达式 $E$，其运行时的动态类型（对象类型）始终是其静态类型的子类型，从而确保编译期推导出的类型在运行时是安全的。子类型安全要求子类只能增加属性或方法，并允许方法重定义，但方法的类型签名必须保持不变。这样，所有对类型 $C$ 对象合法的操作，也同样适用于其子类型 $C' < C$ 的对象，包括属性访问和方法调用，从而保证了子类型的安全性和多态的正确性。

## $SELF\\_TYPE$
$SELF\\_TYPE$ 是一种特殊的类型标记，表示方法或属性的返回类型与调用对象的动态类型一致。  

- **静态视角**：在编译期，SELF_TYPE 是占位类型，用于静态类型检查，表示返回类型依赖于调用对象。  
- **动态视角**：在运行时，SELF_TYPE 的实际类型由调用对象的动态类型决定，从而支持多态行为。

它既保证了类型安全（编译期检查可通过），又允许返回类型根据运行时对象动态变化，类似“动态类型的占位符”。

### 操作规则
#### 1. 替换原则
在类型检查时，$$SELF\_TYPE_C$$ 可以安全地替换为类 $C$。  
- 因为 $$SELF\_TYPE_C$$ 表示“与调用对象动态类型一致的类型”，它必然是类 $C$ 的某个子类型。  
- 所以在静态检查阶段，用 $C$ 来代替 $$SELF\_TYPE_C$$ 可以保证安全。  

#### 2. 子类型关系
设 $T, T'$ 是除 SELF_TYPE 外的任意类型。

1. **同类 SELF_TYPE 比较**
   - $$SELF\_TYPE_C \leq SELF\_TYPE\_C$$
   - 注意：不同类的 $$SELF\_TYPE$$ 不能比较，例如 $$SELF\_TYPE_A$$ 和 $$SELF\_TYPE_B$$ 没有可比关系。

2. **SELF_TYPE 和普通类型比较**
   - $SELF\\_TYPE_C \leq T$ 当且仅当 $C \leq T$
     换句话说，$$SELF\_TYPE_C$$ 可以被看作是 $C$ 的任意子类型，所以它在子类型规则里表现得和 $C$ 一样。

3. **普通类型与 SELF_TYPE 比较**
   - $$T \leq SELF\_TYPE_C$$ 永远为假。  
    因为 $$SELF\_TYPE_C$$ 可能是 $C$ 的任意子类，$T$ 不一定能涵盖所有可能性。

#### 3. 最小上界
当我们在条件表达式 (`if`/`case`) 中需要合并不同分支的类型时，就会用到最小上界。

规则如下：

1. $lub(SELF\\_TYPE\_C, SELF\\_TYPE\_C) = SELF\\_TYPE\_C$  
   - 两个相同类的 SELF_TYPE，lub 还是它本身。

2. $lub(SELF\\_TYPE\_C, T) = lub(T, SELF\\_TYPE\_C) = lub(C, T)$  
   - 把 SELF_TYPE 先替换成 $C$，再做 lub。

3. $lub(T, T')$  
   - 如果没有 SELF_TYPE，照普通的 lub 规则。
### 使用限制
虽然 SELF_TYPE 很有用，但并非所有位置都可以使用。规则如下：

#### 1. 类继承声明
- **不允许**：`class T inherits T' { ... }`
- `T` 和 `T'` 不能是 SELF_TYPE。  
- 因为 SELF_TYPE 不是一个具体类名，它只是一个占位符，不能用来定义类层次结构。

#### 2. 属性声明
- **允许**：`x : SELF_TYPE`
- 属性类型可以是 SELF_TYPE，表示这个属性与当前对象的动态类型一致。

#### 3. let 绑定
- **允许**：`let x : SELF_TYPE in E`
- 局部变量的类型可以是 SELF_TYPE，和属性一样，绑定时类型与 `self` 一致。

#### 4. 对象创建
- **允许**：`new SELF_TYPE`
- 这样创建的对象类型与当前 `self` 的动态类型一致，而不是固定为某个类。  
- 这是 SELF_TYPE 的重要用途之一。

### 5. 静态调用
- **不允许**：`e @ T.m(...)` 中的 `T` 不能是 SELF_TYPE。  
- 静态分派要求编译器在编译时就能确定确切的类，以找到正确的方法实现。  
- SELF_TYPE 在编译时不代表具体类，所以不能出现在这里。

### 6. 方法定义
- **参数类型**：不能用 SELF_TYPE。  
  - 例如：`comp(x : SELF_TYPE) : Bool { ... }` 是非法的。  
  - 原因：如果子类继承这个方法，SELF_TYPE 会指向不同的类，导致参数类型不一致，破坏类型安全。  

- **返回类型**：可以用 SELF_TYPE。  
  - 例如：`clone() : SELF_TYPE { ... }` 是合法的。  
  - 这表示返回值与调用对象的动态类型一致，符合多态的预期。

## 类型检查中的错误恢复

和语法分析一样，类型检查也需要考虑错误恢复。与语法错误不同，类型错误的位置通常更容易定位，而且没有必要跳过大段代码。关键问题是：**当一个表达式没有合法类型时，应该给它什么类型？**

### 1. 最简单的做法：赋予 `Object`
将所有类型错误的表达式临时赋值为 `Object` 类型是一种暴力但好用的方法。
- 好处：因为 `Object` 是所有类的根类型，后续的类型检查仍然可以继续进行。  
- 缺点：可能过于宽松，有时会掩盖错误。

### 2. 更精细的做法：引入 `No_type`
我们可以定义一个特殊的类型 `No_type`，专门表示“类型检查失败”的结果。  

- 规则：`No_type ≤ C` 对所有类型 `C` 都成立。

这样，`No_type` 在需要任何类型的地方都可以暂时充当，所有操作都允许接受 `No_type` 作为输入，但其结果也会是 `No_type`。也就是说，错误会“传播”，不会被掩盖。

示例：
```
let y : Int <- x + 3
```

如果 `x` 未定义，则 `x` 的类型为 `No_type`，因此 `x + 3` 的结果类型也是 `No_type`。编译器会报告错误，但仍能继续分析后续代码。

### 3. 实际实现考虑
如果引入 `No_type`，类层次结构就不再是树，而是一个“几乎全连接”的结构（因为 `No_type` 是所有类的子类型），实现起来会比较复杂。  

因此，在我们做玩具编译器的时候，用 `Object` 作为错误恢复类型已经足够。但在“真实”编译器里，更常见的做法是使用类似 `No_type` 的特殊机制来追踪错误。

# 运行时系统
在完成了词法分析、语法分析、语义分析三大步骤后，我们的前端编译器已经确认了程序的合法性，接下来就是属于后端编译器的内容——优化和代码生成。

在了解代码生成之前，我们需要了解运行时系统……诶，我学过 OS，嘿嘿。所以运行时系统就略过了。

# 代码生成
代码生成的主要难度在于同时满足**正确性**与**效率**。

我们采用 **MIPS 指令集架构**（或其模拟器）作为目标平台，以便在真实环境中运行并验证生成的代码。具体而言，通过 MIPS 指令在寄存器和栈上模拟 1-寄存器栈机的运行：寄存器 $a_0$ 作为累加器，用于保存和更新中间结果，而栈则存储在内存中。累加器在逻辑上相当于栈顶，但为避免混淆，我们仍将其与内存部分区分开来。

## 计算模式的两个基本假设
实际的计算模式相当复杂，为了简化，CS143 有以下两个基本假设：

- **串行计算假设**  
  - 计算按顺序执行，无并发干扰  
  - ❌ 反例：并发（concurrency）、多线程、异步任务

- **控制流可返回假设**  
  - 函数调用后总能返回调用点并继续执行  
  - ❌ 反例：异常（exception）、`call/cc`（续体）、非局部跳转（如 `longjmp`）

## MIPS 架构
在进一步阐述代码生成的内容前，我想我们需要对 MIPS 架构有一个基本的了解。MIPS 属于 RISC 架构，运算主要依赖寄存器，而大量数据（如变量、数组、栈帧）则需存放在内存中。所有算术和逻辑指令都只能作用于寄存器，不能直接操作内存。若要与内存交互，必须先用 `lw` 将数据加载到寄存器中，运算完成后再用 `sw` 写回内存。

### 编译器、操作系统与硬件的关系

为了更好地理解 MIPS 汇编代码的生成过程，我们需要明确**编译器**、**操作系统**和**硬件**在整个过程中各自扮演的角色。

#### 1. 编译器 (Compiler)

编译器的任务是将高级语言代码转换为机器码（汇编或二进制）。在这个过程中，编译器需要：

- **分配寄存器**：决定哪些变量或中间结果应存储在寄存器中。
- **生成内存访问指令**：使用虚拟地址来访问内存中的数据（如变量、数组等）。

##### 视角：
- **程序视角**：程序能直接感知的主要是一块栈，用于存放局部变量和函数调用信息，但它也可能访问全局变量、堆或指定的内存地址。编译器负责生成对寄存器和这些逻辑内存区域的操作指令，而这些内存在物理上的具体位置及其映射由操作系统和硬件管理。

##### 示例：
```mips
lw  $t0, 0x1000  # 假设 0x1000 是变量 b 的虚拟地址
```

#### 2. 操作系统 (OS)

操作系统负责管理多个进程，并提供每个进程独立的虚拟地址空间，以保证隔离和保护。具体职责包括：

- **地址映射**：管理虚拟地址到物理地址的映射（通过页表）。
- **进程隔离**：确保不同进程的虚拟地址空间互不干扰。

##### 视角：
- **裸机/内核程序**：虚拟地址 = 物理地址（无需翻译）。
- **用户程序**：虚拟地址 $\neq$ 物理地址，需要通过页表翻译成物理地址。

#### 3. 硬件 (CPU + MMU + DRAM)

硬件执行实际的指令，操作寄存器，并通过内存管理单元（MMU）查询页表将虚拟地址翻译为物理地址，最终访问实际的物理内存。

##### 具体职责：
- **CPU**：执行指令，操作寄存器。
- **MMU**：将虚拟地址翻译为物理地址。
- **DRAM**：存储实际的数据。

#### 对比总结
编译器、操作系统与硬件在程序执行过程中各司其职：**编译器**负责生成高效的机器代码，重点关注寄存器分配和虚拟地址空间的布局；**操作系统**则管理虚拟地址到物理地址的映射，通过页表和 MMU 实现地址翻译，并提供进程间的隔离与保护；而**硬件**（包括 CPU 和内存系统）只直接识别寄存器和物理地址，最终完成所有数据的存取操作。在无操作系统支持的环境（如裸机或内核代码）中，编译器生成的地址即为物理地址，可直接访问内存；而在有操作系统管理的用户程序中，编译器使用虚拟地址，程序运行时由操作系统配合 MMU 将其动态翻译为物理地址，实现安全、隔离的内存访问。

### 常用 MIPS 指令
- `lw reg1, offset(reg2)`  
  将内存地址 `(reg2 + offset)` 中的 32 位字加载到寄存器 `reg1` 中

- `li reg, imm`  
  将立即数 `imm` 加载到寄存器 `reg` 中（伪指令，通常汇编为 `addiu`）

- `sw reg1, offset(reg2)`  
  将寄存器 `reg1` 中的 32 位字存储到内存地址 `(reg2 + offset)` 处

- `add(reg), add(imm)`  
  执行加法运算：
  - `add reg1, reg2, reg3`：`reg1 ← reg2 + reg3`（带溢出检测）
  - `addi reg1, reg2, imm`：`reg1 ← reg2 + imm`（立即数加法，带溢出检测）
  - `addu` / `addiu`：同上，但**不检查溢出**，实际编程中更常用

- `sub(reg), sub(imm)`  
  执行减法运算：
  - `sub reg1, reg2, reg3`：`reg1 ← reg2 - reg3`（带溢出检测）
  - `subi` 不存在，通常用 `addi reg1, reg2, -imm` 代替
  - `subu reg1, reg2, reg3`：无溢出检测的减法，推荐使用

- `move reg1, reg2`  
  将寄存器 `reg2` 的值复制到 `reg1` 中（伪指令，等价于 `add reg1, reg2, $zero`）

- `jal label`  
  跳转到标签 `label` 处执行，并将返回地址（下一条指令地址）保存到 `$ra` 寄存器中，用于函数调用

- `jr reg`  
  将程序计数器（PC）设置为寄存器 `reg` 中的地址，实现跳转；常用于函数返回（如 `jr $ra`）

- `j label`  
  无条件跳转到标签 `label` 处执行（不保存返回地址）

- `beq reg1, reg2, label`  
  如果 `reg1` 等于 `reg2`，则跳转到 `label`；否则继续执行下一条指令

- `bne reg1, reg2, label`  
  如果 `reg1` 不等于 `reg2`，则跳转到 `label`

## 算术表达式的代码生成
算术表达式的代码生成就是将表达式的结构直接映射为指令的执行序列。由于栈机依赖隐式操作数栈，计算一个算术表达式只需依次生成其子表达式的求值代码，再追加对应的操作指令。例如，表达式 $e_1 + e_2$ 的代码并非独立存在，而是由 $e_1$ 的代码、$e_2$ 的代码和一条 `add` 指令拼接而成——这本质上是一个**递归构造过程**。我们可以把每一个运算符看作一个“模板”，用其操作数的代码递归填充“空位”，不难想到利用 AST 递归下降遍历即可：遇到叶子节点（如常量或变量）时生成 `push` 指令；遇到内部节点（如二元运算）时，先递归生成左右子树的代码，再输出操作指令。

在此过程中只需使用寄存器 $a_0,t_1,sp$，它们均为 Caller-Saved 寄存器，因此除要求 $\\$sp$ 在表达式求值前后保持不变外，不得依赖这些寄存器的值，其保存与恢复责任由调用者承担。也就是说，计算结果会在寄存器 $a_0$ 中，但如果需要保存，需要压入栈中。

## 控制流的代码生成
控制流语句（如 `if`、`while`）的代码生成不再局限于表达式的递归拼接，而是需要引入**标签**和**条件跳转**来构造程序的执行路径。其核心思想是将控制结构“展平”为带跳转的线性指令序列，利用条件判断引导执行流走向不同的代码块，用到的多是无条件跳转。

以 `if (e) S1 else S2` 为例，其代码结构如下：
1. 生成 `e` 的求值代码，结果保存在 $a_0$ 中；
2. 添加条件跳转指令 `beq $a0 $zero else_label`，若条件为假则跳转至 `else` 分支，否则按顺序继续执行；
3. 生成 `S1` 的代码；
4. 添加无条件跳转 `j end_label`，避免执行 `S2`；
5. 插入 `else_label:` 标签，生成 `S2` 的代码；
6. 插入 `end_label:` 标签，作为后续代码起点。

循环结构（如 `while`）类似，但我们需要**反向跳转**，这样就可以构成一个循环结构。例如 `while (e) S` 的代码：
1. 插入 `loop_start:` 标签；
2. 生成 `e` 的求值代码；
3. 添加 `beq $a0 $zero loop_end`，若条件为假则退出循环；
4. 生成 `S` 的代码；
5. 添加 `j loop_start`，跳回循环头部；
6. 插入 `loop_end:` 标签。

在此过程中，必须确保标签的唯一性（可通过计数器生成全局唯一标签），并正确管理控制流的汇合点。由于跳转指令只能基于寄存器进行判断，因此在生成条件代码时，必须确保条件表达式的求值结果最终存放在某个寄存器中，以便用于跳转判断。

## 函数的代码生成

函数的代码生成涉及**调用约定**、**栈帧管理**和**控制转移**，是代码生成中最复杂的部分之一。MIPS 采用典型的**寄存器传参 + 栈帧扩展**模型，函数调用通过 `jal` 指令实现，返回则通过 `jr $ra` 完成。

函数调用 $f(e_1, e_2, ..., e_n)$ 的代码生成步骤如下：
1. 依次生成每个参数表达式 $e_i$ 的代码，结果依次压入操作数栈；
2. 将参数从栈中弹出并加载到参数寄存器 `$a0`, `$a1`, `$a2`, `$a3`（前四个参数），超出部分通过栈传递；
3. 调用 `jal f`，此时返回地址会被自动保存到 `$ra`。

被调用函数 `f` 的入口代码需建立栈帧：
1. 保存 `$ra`（若函数内部会调用其他函数）；
2. 为局部变量和临时数据分配栈空间（`addiu $sp, $sp, -k`）；
3. 可选：保存 `$s0`-`$s7` 等 callee-saved 寄存器。

函数返回时：
1. 将返回值存入 `$v0`；
2. 恢复栈指针和保存的寄存器；
3. 执行 `jr $ra`，跳回调用点。

需要注意的是，`$ra` 是 caller-saved 寄存器，**被调用函数若需调用其他函数，必须在栈中保存 `$ra`**，否则返回地址会被覆盖。此外，栈帧的生命周期与函数调用严格对应，必须保证进入时分配、退出时释放，避免栈失衡。

## 变量引用的代码生成

变量引用的代码生成取决于变量的**存储位置**和**作用域**。在栈机模型中，变量通常存储在**内存**（全局区或栈帧内），因此访问变量必须通过 `lw` 和 `sw` 指令在寄存器与内存之间传输数据。

- **全局变量**：具有静态地址（由链接器确定），可通过标签直接访问。  
  例如，`x = 5` 的代码为：  
  ```mips
  li   $a0, 5
  sw   $a0, x
  ```
  读取 `x` 的代码为：  
  ```mips
  lw   $a0, x
  push $a0
  ```

- **局部变量**：位于当前栈帧中，偏移量在函数分析阶段确定。  
  假设局部变量 `y` 相对于 `$sp` 的偏移为 `8`，则：  
  写入：  
  ```mips
  pop  $a0
  sw   $a0, 8($sp)
  ```
  读取：  
  ```mips
  lw   $a0, 8($sp)
  push $a0
  ```

变量访问不改变栈指针的整体平衡，但每次 `push`/`pop` 都会临时修改 `$sp`。由于 `$a0` 是 caller-saved 寄存器，可用作临时中转，无需保存。在生成变量代码时，必须确保地址计算正确，并在作用域结束时释放栈帧空间。

与算术表达式类似，变量引用的代码生成也依赖递归下降遍历 AST，但需结合**符号表**查询变量的存储位置和偏移，实现静态绑定。